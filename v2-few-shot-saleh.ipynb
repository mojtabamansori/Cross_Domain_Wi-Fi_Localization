{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc36472",
   "metadata": {
    "papermill": {
     "duration": 0.005235,
     "end_time": "2025-11-25T05:39:06.724370",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.719135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 1: Library Imports\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae6bfdd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.734835Z",
     "iopub.status.busy": "2025-11-25T05:39:06.734157Z",
     "iopub.status.idle": "2025-11-25T05:39:06.738282Z",
     "shell.execute_reply": "2025-11-25T05:39:06.737710Z"
    },
    "papermill": {
     "duration": 0.010754,
     "end_time": "2025-11-25T05:39:06.739510",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.728756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Cell 1: Library Imports\n",
    "# import os\n",
    "# import argparse\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import scipy.io as scio\n",
    "# import time\n",
    "# import torch\n",
    "# torch.cuda.empty_cache()\n",
    "# import torch._dynamo\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# # from ptflops import get_model_complexity_info\n",
    "# from sklearn.metrics import classification_report, accuracy_score\n",
    "# from copy import deepcopy\n",
    "# import json\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b37b3b",
   "metadata": {
    "papermill": {
     "duration": 0.003907,
     "end_time": "2025-11-25T05:39:06.747769",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.743862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 2: preset.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d1f5d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.757432Z",
     "iopub.status.busy": "2025-11-25T05:39:06.757195Z",
     "iopub.status.idle": "2025-11-25T05:39:06.761449Z",
     "shell.execute_reply": "2025-11-25T05:39:06.760729Z"
    },
    "papermill": {
     "duration": 0.010643,
     "end_time": "2025-11-25T05:39:06.762624",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.751981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          preset.py\n",
    "# [description]   default settings of WiFi-based models\n",
    "# \"\"\"\n",
    "# minidata_set = 1\n",
    "# preset = {\n",
    "#     # define model\n",
    "#     \"model\": \"LSTM\",  # \"ST-RF\", \"MLP\", \"LSTM\", \"CNN-1D\", \"CNN-2D\", \"CLSTM\", \"ABLSTM\", \"THAT\", \"bi-LSTM\", \"ResNet18\"\n",
    "#     # define task\n",
    "#     \"task\": \"count\",  # \"identity\", \"activity\", \"location\", \"count\"\n",
    "#     # number of repeated experiments\n",
    "#     \"repeat\": 1,\n",
    "#     # path of data\n",
    "#     \"path\": {\n",
    "#         \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   # directory of CSI amplitude files \n",
    "#         \"data_y\": \"/kaggle/input/wimans/annotation.csv\", # path of annotation file\n",
    "#         \"save\": \"result_lstm_epoch=80_batchsize=32_envs=empty_room_wifiband=2.4.json\"               # path to save results\n",
    "#     },\n",
    "#     # data selection for experiments\n",
    "#     \"data\": {\n",
    "#         \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  # select number(s) of users\n",
    "#         \"wifi_band\": [\"2.4\"],                         # select WiFi band(s)\n",
    "#         \"environment\": [\"classroom\"],                 # select environment(s) [\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\n",
    "#         \"length\": 3000,                               # default length of CSI\n",
    "#     },\n",
    "#     # hyperparameters of models\n",
    "#     \"nn\": {\n",
    "#         \"lr\": 1e-3,           # learning rate\n",
    "#         \"epoch\": 300,         # number of epochs\n",
    "#         \"batch_size\": 64,    # batch size\n",
    "#         \"threshold\": 0.5,     # threshold to binarize sigmoid outputs\n",
    "#     },\n",
    "#     # encoding of activities and locations\n",
    "#     \"encoding\": {\n",
    "#         \"activity\": {  # encoding of different activities\n",
    "#             \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#             \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#             \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "#             \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "#             \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "#             \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "#             \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "#             \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "#             \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "#             \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "#         },\n",
    "#         \"location\": {  # encoding of different locations\n",
    "#             \"nan\":  [0, 0, 0, 0, 0],\n",
    "#             \"a\":    [1, 0, 0, 0, 0],\n",
    "#             \"b\":    [0, 1, 0, 0, 0],\n",
    "#             \"c\":    [0, 0, 1, 0, 0],\n",
    "#             \"d\":    [0, 0, 0, 1, 0],\n",
    "#             \"e\":    [0, 0, 0, 0, 1],\n",
    "#         },\n",
    "#     },\n",
    "# }\n",
    "\n",
    "\n",
    "# # Few-shot parameters (manually set)\n",
    "# dest_env = \"empty_room\"       # Destination environment[\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\n",
    "# few_shot_epochs = 100         # Number of epochs for few-shot training\n",
    "# few_shot_num_samples = 5     # Number of samples to use from the destination test data\n",
    "\n",
    "# Confusion_matrix = 1\n",
    "\n",
    "# name_run = \"few={},{},{},m={},t={},epoch={},batch={},environment={}\".format(dest_env, few_shot_epochs, few_shot_num_samples, preset[\"model\"], preset[\"task\"], preset[\"nn\"][\"epoch\"], preset[\"nn\"][\"batch_size\"], preset[\"data\"][\"environment\"])\n",
    "# print(name_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f0df0f",
   "metadata": {
    "papermill": {
     "duration": 0.004044,
     "end_time": "2025-11-25T05:39:06.771061",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.767017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 3: load_data.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce6d08f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.781060Z",
     "iopub.status.busy": "2025-11-25T05:39:06.780790Z",
     "iopub.status.idle": "2025-11-25T05:39:06.786554Z",
     "shell.execute_reply": "2025-11-25T05:39:06.785980Z"
    },
    "papermill": {
     "duration": 0.012168,
     "end_time": "2025-11-25T05:39:06.787630",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.775462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          load_data.py\n",
    "# [description]   load annotation file and CSI amplitude, and encode labels\n",
    "# \"\"\"\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # Note: All necessary libraries (os, numpy, pandas, etc.) are imported in Cell 1.\n",
    "# # from preset import preset   --> preset is already defined in Cell 2.\n",
    "\n",
    "# def load_data_y(var_path_data_y,\n",
    "#                 var_environment=None, \n",
    "#                 var_wifi_band=None, \n",
    "#                 var_num_users=None):\n",
    "#     \"\"\"\n",
    "#     Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n",
    "#     \"\"\"\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list):\n",
    "#     \"\"\"\n",
    "#     Load CSI amplitude (*.npy) files based on a label list.\n",
    "#     \"\"\"\n",
    "#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "#     data_x = []\n",
    "#     for var_path in var_path_list:\n",
    "#         data_csi = np.load(var_path)\n",
    "#         var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n",
    "#         data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n",
    "#         data_x.append(data_csi_pad)\n",
    "#     data_x = np.array(data_x)\n",
    "#     return data_x\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     \"\"\"\n",
    "#     Encode labels according to specific task.\n",
    "#     \"\"\"\n",
    "#     if var_task == \"identity\":\n",
    "#         data_y = encode_identity(data_pd_y)\n",
    "#     elif var_task == \"activity\":\n",
    "#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     elif var_task == \"location\":\n",
    "#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     elif var_task == \"count\":\n",
    "#         data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     return data_y\n",
    "\n",
    "# def encode_identity(data_pd_y):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     return data_identity_onehot_y\n",
    "\n",
    "\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for activity labels.\n",
    "#     \"\"\"\n",
    "#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n",
    "#                                     \"user_3_activity\", \"user_4_activity\", \n",
    "#                                     \"user_5_activity\", \"user_6_activity\"]]\n",
    "#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n",
    "#     return data_activity_onehot_y\n",
    "\n",
    "# def encode_location(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for location labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n",
    "#     return data_location_onehot_y\n",
    "\n",
    "# # Test functions (optional)\n",
    "# def test_load_data_y():\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"classroom\"]).describe())\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"]).describe())\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=[\"1\", \"2\", \"3\"]).describe())\n",
    "\n",
    "# def test_load_data_x():\n",
    "#     data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=None)\n",
    "#     var_label_list = data_pd_y[\"label\"].to_list()\n",
    "#     data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n",
    "#     print(data_x.shape)\n",
    "\n",
    "# def test_encode_identity():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_identity_onehot_y = encode_identity(data_pd_y)\n",
    "#     print(data_identity_onehot_y.shape)\n",
    "#     print(data_identity_onehot_y[2000])\n",
    "\n",
    "# def test_encode_activity():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     print(data_activity_onehot_y.shape)\n",
    "#     print(data_activity_onehot_y[1560])\n",
    "\n",
    "# def test_encode_location():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     print(data_location_onehot_y.shape)\n",
    "#     print(data_location_onehot_y[1560])\n",
    "\n",
    "# def encode_count(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     print(\"data_identity_onehot_y\",data_identity_onehot_y.shape)\n",
    "#     count_data = np.sum(data_identity_onehot_y, axis=1)\n",
    "#     print(\"count_data\",count_data.shape)\n",
    "#     count_data = count_data.reshape(-1, 1)  # shape = (11286, 1)\n",
    "#     encoder = OneHotEncoder(sparse=False)  \n",
    "#     count_data_onehot = encoder.fit_transform(count_data)\n",
    "#     print(count_data_onehot.shape)  \n",
    "#     count_data_onehot = count_data_onehot.astype(\"int8\")\n",
    "\n",
    "#     return count_data_onehot\n",
    "\n",
    "\n",
    "# def test_encode_count():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_count_onehot_y = encode_count(data_pd_y)\n",
    "#     print(data_count_onehot_y.shape)\n",
    "#     print(data_count_onehot_y[20])\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     test_encode_count()\n",
    "# #     test_load_data_y()\n",
    "# #     test_load_data_x()\n",
    "# #     test_encode_identity()\n",
    "# #     test_encode_activity()\n",
    "# #     test_encode_location()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b072cf2b",
   "metadata": {
    "papermill": {
     "duration": 0.004138,
     "end_time": "2025-11-25T05:39:06.796231",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.792093",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 4: preprocess.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40145136",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.806229Z",
     "iopub.status.busy": "2025-11-25T05:39:06.805568Z",
     "iopub.status.idle": "2025-11-25T05:39:06.809595Z",
     "shell.execute_reply": "2025-11-25T05:39:06.808904Z"
    },
    "papermill": {
     "duration": 0.010205,
     "end_time": "2025-11-25T05:39:06.810765",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.800560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          preprocess.py\n",
    "# [description]   preprocess WiFi CSI data\n",
    "# \"\"\"\n",
    "\n",
    "# # All necessary libraries are already imported in Cell 1.\n",
    "\n",
    "# def mat_to_amp(data_mat):\n",
    "#     \"\"\"\n",
    "#     Calculate amplitude of raw WiFi CSI data.\n",
    "#     \"\"\"\n",
    "#     var_length = data_mat[\"trace\"].shape[0]\n",
    "#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n",
    "#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n",
    "#     return data_csi_amp\n",
    "\n",
    "# def extract_csi_amp(var_dir_mat, var_dir_amp):\n",
    "#     \"\"\"\n",
    "#     Read raw WiFi CSI (*.mat) files, calculate CSI amplitude, and save as (*.npy).\n",
    "#     \"\"\"\n",
    "#     var_path_mat = os.listdir(var_dir_mat)\n",
    "#     for var_c, var_path in enumerate(var_path_mat):\n",
    "#         data_mat = scio.loadmat(os.path.join(var_dir_mat, var_path))\n",
    "#         data_csi_amp = mat_to_amp(data_mat)\n",
    "#         # print(var_c, data_csi_amp.shape)\n",
    "#         var_path_save = os.path.join(var_dir_amp, var_path.replace(\".mat\", \".npy\"))\n",
    "#         with open(var_path_save, \"wb\") as var_file:\n",
    "#             np.save(var_file, data_csi_amp)\n",
    "\n",
    "# def parse_args():\n",
    "#     \"\"\"\n",
    "#     Parse arguments from input.\n",
    "#     \"\"\"\n",
    "#     var_args = argparse.ArgumentParser()\n",
    "#     var_args.add_argument(\"--dir_mat\", default=\"/kaggle/input/wimans/wifi_csi/mat\", type=str)\n",
    "#     var_args.add_argument(\"--dir_amp\", default=\"/kaggle/input/wimans/wifi_csi/amp\", type=str)\n",
    "#     return var_args.parse_args()\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     var_args = parse_args()\n",
    "# #     extract_csi_amp(var_dir_mat=var_args.dir_mat, var_dir_amp=var_args.dir_amp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d83e497",
   "metadata": {
    "papermill": {
     "duration": 0.003876,
     "end_time": "2025-11-25T05:39:06.818896",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.815020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdca9817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.828333Z",
     "iopub.status.busy": "2025-11-25T05:39:06.828085Z",
     "iopub.status.idle": "2025-11-25T05:39:06.833439Z",
     "shell.execute_reply": "2025-11-25T05:39:06.832725Z"
    },
    "papermill": {
     "duration": 0.011696,
     "end_time": "2025-11-25T05:39:06.834631",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.822935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import scipy.io as scio\n",
    "# from scipy.interpolate import interp1d\n",
    "# from scipy.signal import butter, filtfilt\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# # ─── CONFIGURATION ───────────────────────────────────────────────────────────────\n",
    "# # Set to 1 to enable, 0 to disable each preprocessing step:\n",
    "# DO_INTERPOLATE       = 1\n",
    "# DO_FILTER            = 1\n",
    "# DO_NORMALIZE         = 1\n",
    "# DO_CALIBRATE_PHASE   = 1\n",
    "# DO_REDUCE_DIM        = 1\n",
    "# DO_EXTRACT_FEATURES  = 1\n",
    "# DO_ALIGN             = 1\n",
    "# DO_AUGMENT           = 1\n",
    "# # ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "# def mat_to_csi(data_mat):\n",
    "#     \"\"\"Return raw complex CSI from the loaded .mat structure.\"\"\"\n",
    "#     num_samples = data_mat[\"trace\"].shape[0]\n",
    "#     return np.array(\n",
    "#         [data_mat[\"trace\"][t][0][0][0][-1] for t in range(num_samples)],\n",
    "#         dtype=np.complex64\n",
    "#     )\n",
    "\n",
    "# def interpolate_missing(x):\n",
    "#     \"\"\"Fill missing values using cubic spline interpolation.\"\"\"\n",
    "#     valid_idx = np.where(~np.isnan(x))[0]\n",
    "#     f = interp1d(valid_idx, x[valid_idx], kind='cubic', fill_value=\"extrapolate\")\n",
    "#     return f(np.arange(len(x)))\n",
    "\n",
    "# def apply_filter(x, fs=1000, cutoff=50, order=4):\n",
    "#     \"\"\"Apply a low-pass Butterworth filter to the signal.\"\"\"\n",
    "#     nyquist = 0.5 * fs\n",
    "#     normal_cutoff = cutoff / nyquist\n",
    "#     b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "#     return filtfilt(b, a, x)\n",
    "\n",
    "# def normalize_amp(x):\n",
    "#     \"\"\"Apply Z-score normalization to the amplitude.\"\"\"\n",
    "#     return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "# def detrend_and_unwrap_phase(phase):\n",
    "#     \"\"\"Remove linear trend from phase and unwrap it to avoid ±π jumps.\"\"\"\n",
    "#     trend = np.poly1d(np.polyfit(np.arange(len(phase)), phase, 1))\n",
    "#     detrended = phase - trend(np.arange(len(phase)))\n",
    "#     return np.unwrap(detrended)\n",
    "\n",
    "# def reduce_dimensionality(X, n_components=3):\n",
    "#     \"\"\"Use PCA to reduce dimensionality of the data.\"\"\"\n",
    "#     pca = PCA(n_components=n_components)\n",
    "#     transformed = pca.fit_transform(X.reshape(-1, 1)).flatten()\n",
    "#     return transformed\n",
    "\n",
    "# def extract_features(x):\n",
    "#     \"\"\"Extract simple features: first and second derivatives alongside the signal.\"\"\"\n",
    "#     first_deriv = np.gradient(x)\n",
    "#     second_deriv = np.gradient(first_deriv)\n",
    "#     return np.vstack([x, first_deriv, second_deriv]).T\n",
    "\n",
    "# def align_csi(X_list):\n",
    "#     \"\"\"Synchronize CSI arrays by truncating to the shortest length.\"\"\"\n",
    "#     min_len = min(map(len, X_list))\n",
    "#     return [X[:min_len] for X in X_list]\n",
    "\n",
    "# def augment_data(x):\n",
    "#     \"\"\"Add small Gaussian noise for data augmentation.\"\"\"\n",
    "#     noise = np.random.normal(0, 0.01, size=x.shape)\n",
    "#     return x + noise\n",
    "\n",
    "# def extract_csi_amp(dir_mat, dir_amp):\n",
    "#     \"\"\"\n",
    "#     Read raw WiFi CSI (.mat) files, compute amplitude & phase,\n",
    "#     apply the enabled preprocessing steps, and save as .npy.\n",
    "#     \"\"\"\n",
    "#     for filename in os.listdir(dir_mat):\n",
    "#         mat = scio.loadmat(os.path.join(dir_mat, filename))\n",
    "#         csi   = mat_to_csi(mat)\n",
    "#         amp   = np.abs(csi)\n",
    "#         phase = np.angle(csi)\n",
    "\n",
    "#         # 1. Interpolation of missing samples\n",
    "#         if DO_INTERPOLATE:\n",
    "#             amp   = interpolate_missing(amp)\n",
    "#             phase = interpolate_missing(phase)\n",
    "\n",
    "#         # 2. Noise filtering\n",
    "#         if DO_FILTER:\n",
    "#             amp   = apply_filter(amp)\n",
    "#             phase = apply_filter(phase)\n",
    "\n",
    "#         # 3. Amplitude normalization\n",
    "#         if DO_NORMALIZE:\n",
    "#             amp = normalize_amp(amp)\n",
    "\n",
    "#         # 4. Phase calibration (detrend + unwrap)\n",
    "#         if DO_CALIBRATE_PHASE:\n",
    "#             phase = detrend_and_unwrap_phase(phase)\n",
    "\n",
    "#         # 5. Dimensionality reduction via PCA\n",
    "#         if DO_REDUCE_DIM:\n",
    "#             amp = reduce_dimensionality(amp)\n",
    "\n",
    "#         # 6. Feature extraction (derivatives)\n",
    "#         if DO_EXTRACT_FEATURES:\n",
    "#             amp = extract_features(amp)\n",
    "\n",
    "#         # 7. CSI alignment across antennas (example for multiple arrays)\n",
    "#         if DO_ALIGN:\n",
    "#             amp = align_csi([amp])[0]\n",
    "\n",
    "#         # 8. Data augmentation (add noise)\n",
    "#         if DO_AUGMENT:\n",
    "#             amp = augment_data(amp)\n",
    "\n",
    "#         # Save the processed array\n",
    "#         save_path = os.path.join(dir_amp, filename.replace(\".mat\", \".npy\"))\n",
    "#         np.save(save_path, amp)\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     import argparse\n",
    "# #     parser = argparse.ArgumentParser(\n",
    "# #         description=\"Preprocess WiFi CSI .mat files into .npy amplitudes\"\n",
    "# #     )\n",
    "# #     parser.add_argument(\"--dir_mat\", type=str, default=\"./mat\",\n",
    "# #                         help=\"Directory containing .mat CSI files\")\n",
    "# #     parser.add_argument(\"--dir_amp\", type=str, default=\"./amp\",\n",
    "# #                         help=\"Directory to save processed .npy files\")\n",
    "# #     args = parser.parse_args()\n",
    "\n",
    "# #     os.makedirs(args.dir_amp, exist_ok=True)\n",
    "# #     extract_csi_amp(args.dir_mat, args.dir_amp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689317a2",
   "metadata": {
    "papermill": {
     "duration": 0.00392,
     "end_time": "2025-11-25T05:39:06.842891",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.838971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 5: that.py (WiFi-based Model THAT)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "928ed0cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.852704Z",
     "iopub.status.busy": "2025-11-25T05:39:06.852447Z",
     "iopub.status.idle": "2025-11-25T05:39:06.859415Z",
     "shell.execute_reply": "2025-11-25T05:39:06.858827Z"
    },
    "papermill": {
     "duration": 0.013396,
     "end_time": "2025-11-25T05:39:06.860487",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.847091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          that.py\n",
    "# [description]   implement and evaluate WiFi-based model THAT\n",
    "#                 https://github.com/windofshadow/THAT\n",
    "# \"\"\"\n",
    "\n",
    "# # All necessary libraries are imported in Cell 1.\n",
    "# # from train import train   --> Defined in Cell 6.\n",
    "# # from preset import preset --> Defined in Cell 2.\n",
    "\n",
    "# class Gaussian_Position(torch.nn.Module):\n",
    "#     def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n",
    "#         super(Gaussian_Position, self).__init__()\n",
    "#         var_embedding = torch.zeros([var_num_gaussian, var_dim_feature], dtype=torch.float)\n",
    "#         self.var_embedding = torch.nn.Parameter(var_embedding, requires_grad=True)\n",
    "#         torch.nn.init.xavier_uniform_(self.var_embedding)\n",
    "#         var_position = torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian)\n",
    "#         self.var_position = torch.nn.Parameter(var_position, requires_grad=False)\n",
    "#         var_mu = torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0)\n",
    "#         self.var_mu = torch.nn.Parameter(var_mu, requires_grad=True)\n",
    "#         var_sigma = torch.tensor([50.0] * var_num_gaussian).unsqueeze(0)\n",
    "#         self.var_sigma = torch.nn.Parameter(var_sigma, requires_grad=True)\n",
    "\n",
    "#     def calculate_pdf(self, var_position, var_mu, var_sigma):\n",
    "#         var_pdf = var_position - var_mu\n",
    "#         var_pdf = - var_pdf * var_pdf\n",
    "#         var_pdf = var_pdf / var_sigma / var_sigma / 2\n",
    "#         var_pdf = var_pdf - torch.log(var_sigma)\n",
    "#         return var_pdf\n",
    "\n",
    "#     def forward(self, var_input):\n",
    "#         var_pdf = self.calculate_pdf(self.var_position, self.var_mu, self.var_sigma)\n",
    "#         var_pdf = torch.softmax(var_pdf, dim=-1)\n",
    "#         var_position_encoding = torch.matmul(var_pdf, self.var_embedding)\n",
    "#         var_output = var_input + var_position_encoding.unsqueeze(0)\n",
    "#         return var_output\n",
    "\n",
    "# class Encoder(torch.nn.Module):\n",
    "#     def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n",
    "#         self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n",
    "#         self.layer_dropout_0 = torch.nn.Dropout(0.1)\n",
    "#         self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n",
    "#         layer_cnn = []\n",
    "#         for var_size in var_size_cnn:\n",
    "#             layer = torch.nn.Sequential(\n",
    "#                 torch.nn.Conv1d(var_dim_feature, var_dim_feature, var_size, padding=\"same\"),\n",
    "#                 torch.nn.BatchNorm1d(var_dim_feature),\n",
    "#                 torch.nn.Dropout(0.1),\n",
    "#                 torch.nn.LeakyReLU()\n",
    "#             )\n",
    "#             layer_cnn.append(layer)\n",
    "#         self.layer_cnn = torch.nn.ModuleList(layer_cnn)\n",
    "#         self.layer_dropout_1 = torch.nn.Dropout(0.1)\n",
    "\n",
    "#     def forward(self, var_input):\n",
    "#         var_t = var_input\n",
    "#         var_t = self.layer_norm_0(var_t)\n",
    "#         var_t, _ = self.layer_attention(var_t, var_t, var_t)\n",
    "#         var_t = self.layer_dropout_0(var_t)\n",
    "#         var_t = var_t + var_input\n",
    "#         var_s = self.layer_norm_1(var_t)\n",
    "#         var_s = torch.permute(var_s, (0, 2, 1))\n",
    "#         var_c = torch.stack([layer(var_s) for layer in self.layer_cnn], dim=0)\n",
    "#         var_s = torch.sum(var_c, dim=0) / len(self.layer_cnn)\n",
    "#         var_s = self.layer_dropout_1(var_s)\n",
    "#         var_s = torch.permute(var_s, (0, 2, 1))\n",
    "#         var_output = var_s + var_t\n",
    "#         return var_output\n",
    "\n",
    "# class THAT(torch.nn.Module):\n",
    "#     def __init__(self, var_x_shape, var_y_shape):\n",
    "#         super(THAT, self).__init__()\n",
    "#         var_dim_feature = var_x_shape[-1]\n",
    "#         var_dim_time = var_x_shape[-2]\n",
    "#         var_dim_output = var_y_shape[-1]\n",
    "#         # Left branch\n",
    "#         self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "#         self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n",
    "#         var_num_left = 4\n",
    "#         var_dim_left = var_dim_feature\n",
    "#         self.layer_left_encoder = torch.nn.ModuleList([\n",
    "#             Encoder(var_dim_feature=var_dim_left, var_num_head=10, var_size_cnn=[1, 3, 5])\n",
    "#             for _ in range(var_num_left)\n",
    "#         ])\n",
    "#         self.layer_left_norm = torch.nn.LayerNorm(var_dim_left, eps=1e-6)\n",
    "#         self.layer_left_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=8)\n",
    "#         self.layer_left_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=16)\n",
    "#         self.layer_left_dropout = torch.nn.Dropout(0.5)\n",
    "#         # Right branch\n",
    "#         self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "#         var_num_right = 1\n",
    "#         var_dim_right = var_dim_time // 20\n",
    "#         self.layer_right_encoder = torch.nn.ModuleList([\n",
    "#             Encoder(var_dim_feature=var_dim_right, var_num_head=10, var_size_cnn=[1, 2, 3])\n",
    "#             for _ in range(var_num_right)\n",
    "#         ])\n",
    "#         self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n",
    "#         self.layer_right_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=2)\n",
    "#         self.layer_right_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=4)\n",
    "#         self.layer_right_dropout = torch.nn.Dropout(0.5)\n",
    "#         self.layer_leakyrelu = torch.nn.LeakyReLU()\n",
    "#         self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n",
    "\n",
    "#     def forward(self, var_input):\n",
    "#         var_t = var_input  # shape: (batch_size, time_steps, features)\n",
    "#         # Left branch\n",
    "#         var_left = torch.permute(var_t, (0, 2, 1))\n",
    "#         var_left = self.layer_left_pooling(var_left)\n",
    "#         var_left = torch.permute(var_left, (0, 2, 1))\n",
    "#         var_left = self.layer_left_gaussian(var_left)\n",
    "#         for layer in self.layer_left_encoder:\n",
    "#             var_left = layer(var_left)\n",
    "#         var_left = self.layer_left_norm(var_left)\n",
    "#         var_left = torch.permute(var_left, (0, 2, 1))\n",
    "#         var_left_0 = self.layer_leakyrelu(self.layer_left_cnn_0(var_left))\n",
    "#         var_left_1 = self.layer_leakyrelu(self.layer_left_cnn_1(var_left))\n",
    "#         var_left_0 = torch.sum(var_left_0, dim=-1)\n",
    "#         var_left_1 = torch.sum(var_left_1, dim=-1)\n",
    "#         var_left = torch.concat([var_left_0, var_left_1], dim=-1)\n",
    "#         var_left = self.layer_left_dropout(var_left)\n",
    "#         # Right branch\n",
    "#         var_right = torch.permute(var_t, (0, 2, 1))\n",
    "#         var_right = self.layer_right_pooling(var_right)\n",
    "#         for layer in self.layer_right_encoder:\n",
    "#             var_right = layer(var_right)\n",
    "#         var_right = self.layer_right_norm(var_right)\n",
    "#         var_right = torch.permute(var_right, (0, 2, 1))\n",
    "#         var_right_0 = self.layer_leakyrelu(self.layer_right_cnn_0(var_right))\n",
    "#         var_right_1 = self.layer_leakyrelu(self.layer_right_cnn_1(var_right))\n",
    "#         var_right_0 = torch.sum(var_right_0, dim=-1)\n",
    "#         var_right_1 = torch.sum(var_right_1, dim=-1)\n",
    "#         var_right = torch.concat([var_right_0, var_right_1], dim=-1)\n",
    "#         var_right = self.layer_right_dropout(var_right)\n",
    "#         # Concatenate branches\n",
    "#         var_t = torch.concat([var_left, var_right], dim=-1)\n",
    "#         var_output = self.layer_output(var_t)\n",
    "#         return var_output\n",
    "\n",
    "# def run_that(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n",
    "#     \"\"\"\n",
    "#     Run WiFi-based model THAT.\n",
    "#     \"\"\"\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     data_train_x = data_train_x.reshape(data_train_x.shape[0], data_train_x.shape[1], -1)\n",
    "#     data_test_x = data_test_x.reshape(data_test_x.shape[0], data_test_x.shape[1], -1)\n",
    "#     var_x_shape, var_y_shape = data_train_x[0].shape, data_train_y[0].reshape(-1).shape\n",
    "#     data_train_set = TensorDataset(torch.from_numpy(data_train_x), torch.from_numpy(data_train_y))\n",
    "#     data_test_set = TensorDataset(torch.from_numpy(data_test_x), torch.from_numpy(data_test_y))\n",
    "    \n",
    "#     result = {}\n",
    "#     result_accuracy = []\n",
    "#     result_time_train = []\n",
    "#     result_time_test = []\n",
    "    \n",
    "#     # var_macs, var_params = get_model_complexity_info(THAT(var_x_shape, var_y_shape), var_x_shape, as_strings=False)\n",
    "#     # print(\"Parameters:\", var_params, \"- FLOPs:\", var_macs * 2)\n",
    "    \n",
    "#     for var_r in range(var_repeat):\n",
    "#         print(\"Repeat\", var_r)\n",
    "#         torch.random.manual_seed(var_r + 39)\n",
    "#         if init_model is not None:\n",
    "#             model_that = init_model\n",
    "#             lr2 = preset[\"nn\"][\"lr\"] /10\n",
    "#         else:\n",
    "#             model_that = THAT(var_x_shape, var_y_shape).to(device)\n",
    "#             lr2 = preset[\"nn\"][\"lr\"]\n",
    "\n",
    "#         optimizer = torch.optim.Adam(model_that.parameters(), lr=lr2, weight_decay=0)\n",
    "#         loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4] * var_y_shape[-1]).to(device))\n",
    "#         var_time_0 = time.time()\n",
    "        \n",
    "#         # Train\n",
    "#         var_best_weight = train(model=model_that, optimizer=optimizer, loss=loss, \n",
    "#                                   data_train_set=data_train_set, data_test_set=data_test_set,\n",
    "#                                   var_threshold=preset[\"nn\"][\"threshold\"],\n",
    "#                                   var_batch_size=preset[\"nn\"][\"batch_size\"],\n",
    "#                                   var_epochs=preset[\"nn\"][\"epoch\"],\n",
    "#                                   device=device)\n",
    "#         var_time_1 = time.time()\n",
    "        \n",
    "#         # Test\n",
    "#         model_that.load_state_dict(var_best_weight)\n",
    "#         with torch.no_grad():\n",
    "#             predict_test_y = model_that(torch.from_numpy(data_test_x).to(device))\n",
    "#         predict_test_y = (torch.sigmoid(predict_test_y) > preset[\"nn\"][\"threshold\"]).float()\n",
    "#         predict_test_y = predict_test_y.detach().cpu().numpy()\n",
    "#         var_time_2 = time.time()\n",
    "        \n",
    "#         # Evaluate\n",
    "#         data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "#         predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "#         result_acc = accuracy_score(data_test_y_c.astype(int), predict_test_y_c.astype(int))\n",
    "#         result_dict = classification_report(data_test_y_c, predict_test_y_c, digits=6, zero_division=0, output_dict=True)\n",
    "#         result[\"repeat_\" + str(var_r)] = result_dict\n",
    "#         result_accuracy.append(result_acc)\n",
    "#         result_time_train.append(var_time_1 - var_time_0)\n",
    "#         result_time_test.append(var_time_2 - var_time_1)\n",
    "#         print(\"repeat_\" + str(var_r), result_accuracy)\n",
    "#         print(result)\n",
    "    \n",
    "#     result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n",
    "#     result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n",
    "#     result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n",
    "#     # result[\"complexity\"] = {\"parameter\": var_params, \"flops\": var_macs * 2}\n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6120c2db",
   "metadata": {
    "papermill": {
     "duration": 0.004051,
     "end_time": "2025-11-25T05:39:06.869114",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.865063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a05ed721",
   "metadata": {
    "papermill": {
     "duration": 0.003988,
     "end_time": "2025-11-25T05:39:06.877476",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.873488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell7: for RESNET18 Model\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a657eec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.887278Z",
     "iopub.status.busy": "2025-11-25T05:39:06.887036Z",
     "iopub.status.idle": "2025-11-25T05:39:06.893663Z",
     "shell.execute_reply": "2025-11-25T05:39:06.893073Z"
    },
    "papermill": {
     "duration": 0.013313,
     "end_time": "2025-11-25T05:39:06.894894",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.881581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "# import time\n",
    "# import torch\n",
    "# torch.cuda.empty_cache()\n",
    "# import numpy as np\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import torchvision.models as models\n",
    "# from copy import deepcopy\n",
    "\n",
    "# torch.set_float32_matmul_precision(\"high\")\n",
    "# torch._dynamo.config.cache_size_limit = 65536\n",
    "\n",
    "# # فرض می‌کنیم preset قبلاً تعریف شده باشه\n",
    "# # preset = { \"nn\": {\"lr\": 1e-3, \"epoch\": 10, \"batch_size\": 4, \"threshold\": 0.5}, ... }\n",
    "\n",
    "# class ResNet18Model(torch.nn.Module):\n",
    "#     def __init__(self, var_x_shape, var_y_shape):\n",
    "#         super(ResNet18Model, self).__init__()\n",
    "#         model_resnet = models.resnet18(weights=None)\n",
    "#         model_resnet.conv1 = torch.nn.Conv2d(1, 64, 7, 3, 2, bias=False)\n",
    "#         in_features_fc = model_resnet.fc.in_features  # معمولاً 512\n",
    "#         out_features_fc = var_y_shape[-1]\n",
    "#         model_resnet.fc = torch.nn.Linear(in_features_fc, out_features_fc)\n",
    "#         self.resnet = model_resnet\n",
    "\n",
    "#     def forward(self, var_input):\n",
    "#         var_input = var_input.reshape(var_input.size(0), 1, 3000, 270)\n",
    "#         return self.resnet(var_input)\n",
    "\n",
    "# def run_resnet(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     var_x_shape = data_train_x[0].shape\n",
    "#     var_y_shape = data_train_y[0].reshape(-1).shape\n",
    "\n",
    "#     # تغییر شکل داده‌ها روی CPU\n",
    "#     data_train_x = data_train_x.reshape(data_train_x.shape[0], 1, data_train_x.shape[1],\n",
    "#                                         data_train_x.shape[2]*data_train_x.shape[3]*data_train_x.shape[4])\n",
    "#     data_test_x  = data_test_x.reshape(data_test_x.shape[0], 1, data_test_x.shape[1],\n",
    "#                                        data_test_x.shape[2]*data_test_x.shape[3]*data_test_x.shape[4])\n",
    "    \n",
    "#     # دیتاست‌ها روی CPU\n",
    "#     data_train_set = TensorDataset(torch.from_numpy(data_train_x).float(),\n",
    "#                                    torch.from_numpy(data_train_y).float())\n",
    "#     data_test_set  = TensorDataset(torch.from_numpy(data_test_x).float(),\n",
    "#                                    torch.from_numpy(data_test_y).float())\n",
    "    \n",
    "#     result = {}\n",
    "#     result_accuracy = []\n",
    "#     result_time_train = []\n",
    "#     result_time_test = []\n",
    "    \n",
    "#     for var_r in range(var_repeat):\n",
    "#         print(\"Repeat\", var_r)\n",
    "#         torch.random.manual_seed(var_r + 39)\n",
    "        \n",
    "#         # ساخت مدل و انتقال به GPU\n",
    "#         if init_model is not None:\n",
    "#             model_resnet = init_model\n",
    "#             lr2 = preset[\"nn\"][\"lr\"] /10\n",
    "            \n",
    "#         else:\n",
    "#             model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n",
    "#             lr2 = preset[\"nn\"][\"lr\"]\n",
    "\n",
    "#         optimizer = torch.optim.Adam(model_resnet.parameters(), lr=lr2, weight_decay=0)\n",
    "#         loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6] * var_y_shape[-1]).to(device))\n",
    "        \n",
    "#         # تابع آموزش داخلی؛ دیتا روی CPU باقی می‌مونه و فقط هنگام محاسبه batch به GPU میره\n",
    "#         def train_inner():\n",
    "#             train_loader = DataLoader(data_train_set, preset[\"nn\"][\"batch_size\"], shuffle=True, pin_memory=False)\n",
    "#             test_loader = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n",
    "#             best_accuracy = 0\n",
    "#             best_weight = None\n",
    "            \n",
    "#             for epoch in range(preset[\"nn\"][\"epoch\"]):\n",
    "#                 t0 = time.time()\n",
    "#                 model_resnet.train()\n",
    "#                 # متغیرهای مربوط به آخرین batch آموزش\n",
    "#                 last_train_loss = None\n",
    "#                 last_train_acc = None\n",
    "#                 for batch in train_loader:\n",
    "#                     batch_x, batch_y = batch\n",
    "#                     batch_x = batch_x.to(device)\n",
    "#                     batch_y = batch_y.to(device)\n",
    "#                     outputs = model_resnet(batch_x)\n",
    "#                     loss_val = loss_func(outputs, batch_y.reshape(batch_y.shape[0], -1).float())\n",
    "#                     optimizer.zero_grad()\n",
    "#                     loss_val.backward()\n",
    "#                     optimizer.step()\n",
    "#                     last_train_loss = loss_val.item()\n",
    "#                     # محاسبه دقت آخرین batch آموزش\n",
    "#                     train_preds = (torch.sigmoid(outputs) > preset[\"nn\"][\"threshold\"]).float()\n",
    "#                     last_train_acc = accuracy_score(batch_y.reshape(batch_y.shape[0], -1).detach().cpu().numpy().astype(int),\n",
    "#                                                     train_preds.detach().cpu().numpy().astype(int))\n",
    "                \n",
    "#                 # ارزیابی روی دیتاست تست به صورت batch به batch\n",
    "#                 model_resnet.eval()\n",
    "#                 all_preds = []\n",
    "#                 all_labels = []\n",
    "#                 test_loss_val = None\n",
    "#                 with torch.no_grad():\n",
    "#                     for t_batch in test_loader:\n",
    "#                         t_x, t_y = t_batch\n",
    "#                         t_x = t_x.to(device)\n",
    "#                         outputs_test = model_resnet(t_x)\n",
    "#                         outputs_test = (torch.sigmoid(outputs_test) > preset[\"nn\"][\"threshold\"]).float()\n",
    "#                         all_preds.append(outputs_test.detach().cpu().numpy())\n",
    "#                         all_labels.append(t_y.cpu().numpy())  # اینجا تغییر دادیم\n",
    "#                 preds_cat = np.vstack(all_preds)\n",
    "#                 labels_cat = np.vstack(all_labels)\n",
    "#                 print(\"preds_cat\",preds_cat.shape)\n",
    "#                 # تبدیل به شکل (n, 6, 5)\n",
    "                \n",
    "#                 # preds_cat = preds_cat.reshape(-1, 6, 5)\n",
    "#                 # labels_cat = labels_cat.reshape(-1, 6, 5)\n",
    "\n",
    "#                 preds_cat = preds_cat.reshape(-1, 6)\n",
    "#                 labels_cat = labels_cat.reshape(-1, 6)\n",
    "                \n",
    "#                 # برای محاسبه دقت، مسطح می‌کنیم\n",
    "#                 test_acc = accuracy_score(labels_cat.reshape(labels_cat.shape[0], -1).astype(int),\n",
    "#                                           preds_cat.reshape(preds_cat.shape[0], -1).astype(int))\n",
    "#                 epoch_time = time.time() - t0\n",
    "#                 print(f\"Epoch {epoch}/{preset['nn']['epoch']} - \"\n",
    "#                       f\"Train Loss: {(last_train_loss if last_train_loss is not None else 0.0):.6f}, \"\n",
    "#                       f\"Train Acc: {(last_train_acc if last_train_acc is not None else 0.0):.6f}, \"\n",
    "#                       f\"Test Loss: {(test_loss_val if test_loss_val is not None else 0.0):.6f}, \"\n",
    "#                       f\"Test Acc: {(test_acc if test_acc is not None else 0.0):.6f} - \"\n",
    "#                       f\"Time: {epoch_time:.4f}s\")\n",
    "\n",
    "#                 if test_acc > best_accuracy:\n",
    "#                     best_accuracy = test_acc\n",
    "#                     print('-----***-----')\n",
    "#                     print(best_accuracy)\n",
    "#                     best_weight = deepcopy(model_resnet.state_dict())\n",
    "#             return best_weight\n",
    "        \n",
    "#         t0_run = time.time()\n",
    "#         best_weight = train_inner()\n",
    "#         t1_run = time.time()\n",
    "        \n",
    "#         torch.save(model_resnet.state_dict(), f\"{name_run}_model_final.pt\")\n",
    "#         model_resnet.load_state_dict(best_weight)\n",
    "#         torch.save(model_resnet.state_dict(), f\"{name_run}_best_model.pt\")\n",
    "\n",
    "#         # bad age niaz bod load koni\n",
    "#         # model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n",
    "#         # model_resnet.load_state_dict(torch.load(\"resnet_model_repeat0.pt\"))\n",
    "#         # model_resnet.eval()\n",
    "\n",
    "        \n",
    "#         # ارزیابی نهایی مدل روی دیتاست تست (استفاده از batchهای کوچک)\n",
    "#         model_resnet.eval()\n",
    "#         all_preds = []\n",
    "#         test_loader_final = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n",
    "#         with torch.no_grad():\n",
    "#             for batch in test_loader_final:\n",
    "#                 batch_x, _ = batch\n",
    "#                 batch_x = batch_x.to(device)\n",
    "#                 all_preds.append(model_resnet(batch_x))\n",
    "#         preds_all = torch.cat(all_preds, dim=0)\n",
    "#         preds_final = (torch.sigmoid(preds_all) > preset[\"nn\"][\"threshold\"]).float().detach().cpu().numpy()\n",
    "#         t2_run = time.time()\n",
    "        \n",
    "#         data_test_y_np = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "#         preds_final = preds_final.reshape(-1, data_test_y.shape[-1])\n",
    "#         acc_final = accuracy_score(data_test_y_np.astype(int), preds_final.astype(int))\n",
    "#         result[f\"repeat_{var_r}\"] = {\"accuracy\": acc_final}\n",
    "#         result_accuracy.append(acc_final)\n",
    "#         result_time_train.append(t1_run - t0_run)\n",
    "#         result_time_test.append(t2_run - t1_run)\n",
    "#         print(\"Repeat\", var_r, \"Final Test Accuracy:\", acc_final)\n",
    "    \n",
    "#     result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n",
    "#     result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n",
    "#     result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23db167",
   "metadata": {
    "papermill": {
     "duration": 0.004038,
     "end_time": "2025-11-25T05:39:06.903478",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.899440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 9: train.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbc4ae38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.913189Z",
     "iopub.status.busy": "2025-11-25T05:39:06.912910Z",
     "iopub.status.idle": "2025-11-25T05:39:06.918293Z",
     "shell.execute_reply": "2025-11-25T05:39:06.917531Z"
    },
    "papermill": {
     "duration": 0.011827,
     "end_time": "2025-11-25T05:39:06.919441",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.907614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          train.py\n",
    "# [description]   function to train WiFi-based models\n",
    "# \"\"\"\n",
    "\n",
    "# # All necessary libraries are imported in Cell 1.\n",
    "\n",
    "# torch.set_float32_matmul_precision(\"high\")\n",
    "# torch._dynamo.config.cache_size_limit = 65536\n",
    "\n",
    "# def train(model, optimizer, loss, data_train_set, data_test_set, var_threshold, var_batch_size, var_epochs, device):\n",
    "#     \"\"\"\n",
    "#     Generic training function for WiFi-based models.\n",
    "#     \"\"\"\n",
    "#     # دیتا رو روی CPU نگه می‌داریم (pin_memory=False)\n",
    "#     data_train_loader = DataLoader(data_train_set, var_batch_size, shuffle=True, pin_memory=False)\n",
    "#     data_test_loader = DataLoader(data_test_set, batch_size=len(data_test_set), shuffle=False, pin_memory=False)\n",
    "    \n",
    "#     var_best_accuracy = -1.0\n",
    "#     var_best_weight   = deepcopy(model.state_dict())\n",
    "    \n",
    "    \n",
    "#     for var_epoch in range(var_epochs):\n",
    "#         var_time_e0 = time.time()\n",
    "#         model.train()\n",
    "#         for data_batch in data_train_loader:\n",
    "#             data_batch_x, data_batch_y = data_batch\n",
    "#             # انتقال موقتی داده به GPU فقط برای forward pass\n",
    "#             data_batch_x = data_batch_x.to(device)\n",
    "#             data_batch_y = data_batch_y.to(device)\n",
    "#             predict_train_y = model(data_batch_x)\n",
    "#             var_loss_train = loss(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n",
    "#             optimizer.zero_grad()\n",
    "#             var_loss_train.backward()\n",
    "#             optimizer.step()\n",
    "        \n",
    "#         # محاسبه دقت روی آخرین batch و انتقال نتایج به CPU\n",
    "#         predict_train_y = (torch.sigmoid(predict_train_y) > var_threshold).float()\n",
    "#         data_batch_y = data_batch_y.detach().cpu().numpy()\n",
    "#         predict_train_y = predict_train_y.detach().cpu().numpy()\n",
    "        \n",
    "#         predict_train_y = predict_train_y.reshape(-1, data_batch_y.shape[-1])\n",
    "#         data_batch_y = data_batch_y.reshape(-1, data_batch_y.shape[-1])\n",
    "#         var_accuracy_train = accuracy_score(data_batch_y.astype(int), predict_train_y.astype(int))\n",
    "        \n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             data_test_x, data_test_y = next(iter(data_test_loader))\n",
    "#             # انتقال موقتی دیتا تست به GPU برای محاسبات\n",
    "#             data_test_x = data_test_x.to(device)\n",
    "#             data_test_y = data_test_y.to(device)\n",
    "            \n",
    "#             predict_test_y = model(data_test_x)\n",
    "#             var_loss_test = loss(predict_test_y, data_test_y.reshape(data_test_y.shape[0], -1).float())\n",
    "            \n",
    "#             predict_test_y = (torch.sigmoid(predict_test_y) > var_threshold).float()\n",
    "            \n",
    "#             # انتقال نتایج به CPU برای ارزیابی\n",
    "#             data_test_y = data_test_y.detach().cpu().numpy()\n",
    "#             predict_test_y = predict_test_y.detach().cpu().numpy()\n",
    "            \n",
    "#             predict_test_y = predict_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "#             data_test_y = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "#             var_accuracy_test = accuracy_score(data_test_y.astype(int), predict_test_y.astype(int))\n",
    "        \n",
    "#         print(f\"Epoch {var_epoch}/{var_epochs}\",\n",
    "#               \"- %.6fs\"%(time.time() - var_time_e0),\n",
    "#               \"- Loss %.6f\"%var_loss_train.cpu(),\n",
    "#               \"- Accuracy %.6f\"%var_accuracy_train,\n",
    "#               \"- Test Loss %.6f\"%var_loss_test.cpu(),\n",
    "#               \"- Test Accuracy %.6f\"%var_accuracy_test)\n",
    "            \n",
    "#         if var_accuracy_test > var_best_accuracy:\n",
    "#             var_best_accuracy = var_accuracy_test\n",
    "#             print('-----***-----')\n",
    "#             print(var_best_accuracy)\n",
    "#             var_best_weight = deepcopy(model.state_dict())\n",
    "\n",
    "#     torch.save(model.state_dict(), f\"{name_run}_model_final.pt\")\n",
    "#     torch.save(var_best_weight, f\"{name_run}_best_model.pt\")\n",
    "\n",
    "    \n",
    "#     return var_best_weight\n",
    "\n",
    "\n",
    "\n",
    "# # === importsِ لازم را یک‌بار بالای فایل اضافه کن ===\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # ---------- تابع کمکی ----------\n",
    "# def save_confusion_matrix(model, data_loader, threshold, device, pdf_path):\n",
    "#     \"\"\"\n",
    "#     Runs the model on `data_loader`, builds a confusion matrix and writes it to `pdf_path`.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     y_true, y_pred = [], []\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in data_loader:\n",
    "#             xb = xb.to(device)\n",
    "#             logits = model(xb)\n",
    "\n",
    "#             preds = (torch.sigmoid(logits) > threshold).float().cpu().numpy().ravel()\n",
    "#             yb    = yb.cpu().numpy().ravel()\n",
    "\n",
    "#             y_true.extend(yb)\n",
    "#             y_pred.extend(preds)\n",
    "\n",
    "#     cm  = confusion_matrix(y_true, y_pred)\n",
    "#     fig, ax = plt.subplots()\n",
    "#     ConfusionMatrixDisplay(cm).plot(ax=ax)\n",
    "#     ax.set_title(\"Confusion Matrix – Test\")\n",
    "\n",
    "#     with PdfPages(pdf_path) as pdf:\n",
    "#         pdf.savefig(fig)\n",
    "#     plt.close(fig)\n",
    "# # ---------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1d808",
   "metadata": {
    "papermill": {
     "duration": 0.004063,
     "end_time": "2025-11-25T05:39:06.927994",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.923931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 11: run.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3983cd2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.937618Z",
     "iopub.status.busy": "2025-11-25T05:39:06.937360Z",
     "iopub.status.idle": "2025-11-25T05:39:06.943416Z",
     "shell.execute_reply": "2025-11-25T05:39:06.942713Z"
    },
    "papermill": {
     "duration": 0.012341,
     "end_time": "2025-11-25T05:39:06.944567",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.932226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import torch\n",
    "# gc.collect()           \n",
    "# torch.cuda.empty_cache()  \n",
    "# torch.cuda.ipc_collect()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \"\"\"\n",
    "# [file]          run.py\n",
    "# [description]   run WiFi-based models and optionally save a multiclass confusion matrix\n",
    "# \"\"\"\n",
    "\n",
    "# import argparse\n",
    "# import json\n",
    "# import torch\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# # from preset import preset, name_run\n",
    "# # from load_data import load_data_x, load_data_y, encode_data_y\n",
    "# # from lstm import run_lstm, LSTMM\n",
    "# # from bilstm import run_bilstm, BiLSTMM\n",
    "# # from that import run_that, THAT\n",
    "# # from resnet import run_resnet, ResNet18Model\n",
    "# # from strf import run_strf  # if you have the ST-RF implementation\n",
    "\n",
    "# def parse_args():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument(\"--model\",   default=preset[\"model\"],  type=str)\n",
    "#     parser.add_argument(\"--task\",    default=preset[\"task\"],   type=str)\n",
    "#     parser.add_argument(\"--repeat\",  default=preset[\"repeat\"], type=int)\n",
    "#     parser.add_argument(\"--save_cm\", action=\"store_true\",\n",
    "#                         help=\"Save a multiclass confusion matrix of the best model to PDF\")\n",
    "#     args, _ = parser.parse_known_args()\n",
    "#     return args\n",
    "\n",
    "# def save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes):\n",
    "#     \"\"\"\n",
    "#     Given a model that outputs one-hot logits for a multiclass task,\n",
    "#     convert to predicted classes via argmax, then plot and save a\n",
    "#     num_classes × num_classes confusion matrix to pdf_path.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     y_true = []\n",
    "#     y_pred = []\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in data_loader:\n",
    "#             xb = xb.to(device)\n",
    "#             logits = model(xb)\n",
    "#             # predicted class is index of max logit\n",
    "#             preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "#             trues = torch.argmax(yb, dim=1).cpu().numpy()\n",
    "#             y_pred.extend(preds.tolist())\n",
    "#             y_true.extend(trues.tolist())\n",
    "\n",
    "#     labels = list(range(num_classes))\n",
    "#     cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "#     disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "#     fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#     disp.plot(ax=ax, xticks_rotation=\"vertical\")\n",
    "#     ax.set_title(\"Confusion Matrix\")\n",
    "#     with PdfPages(pdf_path) as pdf:\n",
    "#         pdf.savefig(fig)\n",
    "#     plt.close(fig)\n",
    "\n",
    "# def run():\n",
    "#     args       = parse_args()\n",
    "#     var_model  = args.model\n",
    "#     var_task   = args.task\n",
    "#     var_repeat = args.repeat\n",
    "\n",
    "#     # --- Load and encode the data ---\n",
    "#     data_pd_y = load_data_y(\n",
    "#         preset[\"path\"][\"data_y\"],\n",
    "#         var_environment=preset[\"data\"][\"environment\"],\n",
    "#         var_wifi_band=preset[\"data\"][\"wifi_band\"],\n",
    "#         var_num_users=preset[\"data\"][\"num_users\"]\n",
    "#     )\n",
    "#     labels = data_pd_y[\"label\"].tolist()\n",
    "#     data_x = load_data_x(preset[\"path\"][\"data_x\"], labels)\n",
    "#     data_y = encode_data_y(data_pd_y, var_task)\n",
    "\n",
    "#     train_x, test_x, train_y, test_y = train_test_split(\n",
    "#         data_x, data_y, test_size=0.2, shuffle=True, random_state=39\n",
    "#     )\n",
    "\n",
    "#     # --- Select which model runner to use ---\n",
    "#     if var_model == \"ST-RF\":\n",
    "#         from strf import run_strf\n",
    "#         run_model = run_strf\n",
    "#     elif var_model == \"LSTM\":\n",
    "#         run_model = run_lstm\n",
    "#     elif var_model == \"bi-LSTM\":\n",
    "#         run_model = run_bilstm\n",
    "#     elif var_model == \"THAT\":\n",
    "#         run_model = run_that\n",
    "#     elif var_model == \"ResNet18\":\n",
    "#         run_model = run_resnet\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown model: {var_model}\")\n",
    "\n",
    "#     # --- Train and evaluate ---\n",
    "#     print(f\"Running model: {var_model}\")\n",
    "#     result = run_model(train_x, train_y, test_x, test_y, var_repeat)\n",
    "#     result[\"model\"] = var_model\n",
    "#     result[\"task\"]  = var_task\n",
    "#     result[\"data\"]  = preset[\"data\"]\n",
    "#     result[\"nn\"]    = preset[\"nn\"]\n",
    "#     print(result)\n",
    "\n",
    "#     # --- Save results to JSON ---\n",
    "#     with open(preset[\"path\"][\"save\"], \"w\") as f:\n",
    "#         json.dump(result, f, indent=4)\n",
    "\n",
    "#     # --- Optionally save a multiclass confusion matrix ---\n",
    "#     # if args.save_cm:\n",
    "#     if Confusion_matrix == 1:\n",
    "#         # 1) completely release GPU memory used for training\n",
    "#         del run_model                      # if 'model' from training is still in scope\n",
    "#         torch.cuda.empty_cache()\n",
    "#         torch.cuda.ipc_collect()\n",
    "    \n",
    "#         # 2) reshape input only if the network is sequence‑based\n",
    "#         if var_model in (\"LSTM\", \"bi-LSTM\", \"THAT\"):\n",
    "#             test_x_cm = test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n",
    "#         else:                           # ResNet18, ST‑RF\n",
    "#             test_x_cm = test_x\n",
    "    \n",
    "#         # 3) build the *same* architecture on CPU and load its weights\n",
    "#         device_cm = torch.device(\"cpu\")\n",
    "#         if var_model == \"LSTM\":\n",
    "#             model_cm = LSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "#         elif var_model == \"bi-LSTM\":\n",
    "#             model_cm = BiLSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "#         elif var_model == \"THAT\":\n",
    "#             model_cm = THAT(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "#         elif var_model == \"ResNet18\":\n",
    "#             model_cm = ResNet18Model(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Confusion matrix not supported for {var_model}\")\n",
    "    \n",
    "#         best_path = f\"/kaggle/working/{name_run}_best_model.pt\"\n",
    "#         model_cm.load_state_dict(torch.load(best_path, map_location=device_cm))\n",
    "#         model_cm.eval()\n",
    "    \n",
    "#         # 4) DataLoader on CPU with a safe batch size\n",
    "#         test_ds = TensorDataset(torch.from_numpy(test_x_cm).float(),\n",
    "#                                 torch.from_numpy(test_y).float())\n",
    "#         test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "    \n",
    "#         # 5) save the confusion matrix PDF\n",
    "#         num_classes = test_y.shape[1]\n",
    "#         pdf_name = f\"{name_run}_confusion_matrix.pdf\"\n",
    "#         save_multiclass_confusion_matrix(model_cm,test_loader,device_cm,pdf_name,num_classes)\n",
    "#         print(f\"✅ Saved confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\n",
    "# if __name__ == \"__main__\":\n",
    "#     print(\"start\")\n",
    "#     run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f719a9f",
   "metadata": {
    "papermill": {
     "duration": 0.004624,
     "end_time": "2025-11-25T05:39:06.953776",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.949152",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 12: Few-shot Learning\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b05ad53b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.963624Z",
     "iopub.status.busy": "2025-11-25T05:39:06.963371Z",
     "iopub.status.idle": "2025-11-25T05:39:06.969035Z",
     "shell.execute_reply": "2025-11-25T05:39:06.968334Z"
    },
    "papermill": {
     "duration": 0.012219,
     "end_time": "2025-11-25T05:39:06.970263",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.958044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import torch\n",
    "# import shutil\n",
    "# import json\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# gc.collect()           \n",
    "# torch.cuda.empty_cache()  \n",
    "# torch.cuda.ipc_collect()\n",
    "\n",
    "# # ---------- helper: save multiclass confusion matrix ------------------\n",
    "# def save_multiclass_confusion_matrix(model, data_loader, pdf_path, num_classes):\n",
    "#     \"\"\"\n",
    "#     Forward‑pass on CPU, collect predictions, and write an N×N confusion matrix\n",
    "#     to a single‑page PDF (pdf_path).\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     y_true, y_pred = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in data_loader:\n",
    "#             logits = model(xb.cpu())                       # ensure CPU\n",
    "#             preds  = torch.argmax(logits, dim=1).numpy()\n",
    "#             trues  = torch.argmax(yb, dim=1).numpy()\n",
    "#             y_pred.extend(preds.tolist())\n",
    "#             y_true.extend(trues.tolist())\n",
    "\n",
    "#     labels = list(range(num_classes))\n",
    "#     cm  = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "#     disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "#     fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#     disp.plot(ax=ax, xticks_rotation=\"vertical\")\n",
    "#     ax.set_title(\"Few‑shot Confusion Matrix\")\n",
    "#     with PdfPages(pdf_path) as pdf:\n",
    "#         pdf.savefig(fig)\n",
    "#     plt.close(fig)\n",
    "\n",
    "# # -------------------- pick run_* function ------------------------------\n",
    "# if preset[\"model\"] == \"ST-RF\":\n",
    "#     run_model = run_strf\n",
    "# elif preset[\"model\"] == \"LSTM\":\n",
    "#     run_model = run_lstm\n",
    "# elif preset[\"model\"] == \"bi-LSTM\":\n",
    "#     run_model = run_bilstm\n",
    "# elif preset[\"model\"] == \"THAT\":\n",
    "#     run_model = run_that\n",
    "# elif preset[\"model\"] == \"ResNet18\":\n",
    "#     run_model = run_resnet\n",
    "# else:\n",
    "#     raise ValueError(f\"No few‑shot implementation for {preset['model']}.\")\n",
    "\n",
    "# # ------------------------ load / split data ----------------------------\n",
    "# data_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n",
    "#                         var_environment=[dest_env],\n",
    "#                         var_wifi_band=preset[\"data\"][\"wifi_band\"],\n",
    "#                         var_num_users=preset[\"data\"][\"num_users\"])\n",
    "\n",
    "# labels_list = data_pd_y[\"label\"].tolist()\n",
    "# data_x = load_data_x(preset[\"path\"][\"data_x\"], labels_list)\n",
    "# data_y = encode_data_y(data_pd_y, preset[\"task\"])\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(\n",
    "#     data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n",
    "\n",
    "# # Few-shot sample size\n",
    "# train_x = train_x[:few_shot_num_samples]\n",
    "# train_y = train_y[:few_shot_num_samples]\n",
    "\n",
    "# # ----------------------- few‑shot training -----------------------------\n",
    "# original_epochs = preset[\"nn\"][\"epoch\"]\n",
    "# preset[\"nn\"][\"epoch\"] = few_shot_epochs\n",
    "\n",
    "# # Load the best model weights\n",
    "# best_model_path = f\"{name_run}_best_model.pt\"\n",
    "\n",
    "# # Initialize the model \n",
    "# if preset[\"model\"] == \"LSTM\":\n",
    "#     model = LSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "#     # print('train_y_[0].shape:', train_y[0].shape)\n",
    "#     # print('train_x_[0].shape:', train_x[0].reshape(train_x[0].shape[0], -1).shape)\n",
    "# elif preset[\"model\"] == \"bi-LSTM\":\n",
    "#     model = BiLSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "# elif preset[\"model\"] == \"THAT\":\n",
    "#     model = THAT(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "# elif preset[\"model\"] == \"ResNet18\":\n",
    "#     model = ResNet18Model(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "# else:\n",
    "#     raise ValueError(f\"Model {preset['model']} not supported!\")\n",
    "\n",
    "# # Load the weights into the model\n",
    "# model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n",
    "# model = model.to('cuda')\n",
    "\n",
    "# # Fine-tune the model on few-shot data (note: `run_model` should now return only the result)\n",
    "# result = run_model(train_x, train_y, test_x, test_y, var_repeat=1, init_model=model)\n",
    "# print(result)\n",
    "\n",
    "# # --------------------- save few‑shot checkpoints -----------------------\n",
    "# # After fine-tuning, save the model\n",
    "# torch.save(model.state_dict(), f\"{name_run}_fewshot_final_model.pt\")\n",
    "# torch.save(model.state_dict(), f\"{name_run}_fewshot_best_model.pt\")\n",
    "\n",
    "# # ------------------- confusion matrix on CPU ---------------------------\n",
    "# if Confusion_matrix == 1 and preset[\"model\"] != \"ST-RF\":\n",
    "\n",
    "#     # reshape for sequence models\n",
    "#     test_x_rs = (test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n",
    "#                  if preset[\"model\"] in (\"LSTM\", \"bi-LSTM\", \"THAT\") else test_x)\n",
    "\n",
    "#     # instantiate identical architecture on CPU\n",
    "#     if preset[\"model\"] == \"LSTM\":\n",
    "#         model_cpu = LSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "#     elif preset[\"model\"] == \"bi-LSTM\":\n",
    "#         model_cpu = BiLSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "#     elif preset[\"model\"] == \"THAT\":\n",
    "#         model_cpu = THAT(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "#     else:  # ResNet18\n",
    "#         model_cpu = ResNet18Model(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "\n",
    "#     # load weights\n",
    "#     model_cpu.load_state_dict(torch.load(f\"{name_run}_fewshot_best_model.pt\", map_location=\"cpu\"))\n",
    "\n",
    "#     # CPU DataLoader with a safe batch size\n",
    "#     test_ds = TensorDataset(torch.from_numpy(test_x_rs).float(),\n",
    "#                             torch.from_numpy(test_y).float())\n",
    "#     test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "#     pdf_name = f\"{name_run}_fewshot_confusion_matrix.pdf\"\n",
    "#     num_classes = test_y.shape[1]\n",
    "#     save_multiclass_confusion_matrix(model_cpu, test_loader, pdf_name, num_classes)\n",
    "#     print(f\"✅ Saved few‑shot confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\n",
    "\n",
    "# # ----------------------- restore & persist -----------------------------\n",
    "# preset[\"nn\"][\"epoch\"] = original_epochs\n",
    "\n",
    "# # Save the final result to JSON\n",
    "# with open(\"result_fewshot.json\", \"w\") as f:\n",
    "#     json.dump(result, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5487b617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-25T05:39:06.980385Z",
     "iopub.status.busy": "2025-11-25T05:39:06.980124Z",
     "iopub.status.idle": "2025-11-25T06:15:14.570903Z",
     "shell.execute_reply": "2025-11-25T06:15:14.569989Z"
    },
    "papermill": {
     "duration": 2167.597592,
     "end_time": "2025-11-25T06:15:14.572258",
     "exception": false,
     "start_time": "2025-11-25T05:39:06.974666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################\n",
      "STARTING SCENARIO: RPCA\n",
      "################################################\n",
      "*** DEBUG MODE: Using 50.0% of data (940 samples) ***\n",
      "Loading 940 samples - Mode: WITH RPCA...\n",
      "Processing 100/940...\n",
      "Processing 200/940...\n",
      "Processing 300/940...\n",
      "Processing 400/940...\n",
      "Processing 500/940...\n",
      "Processing 600/940...\n",
      "Processing 700/940...\n",
      "Processing 800/940...\n",
      "Processing 900/940...\n",
      "--- Repeat 1/1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1036.)\n",
      "  return F.conv1d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1/80 | LR: 0.001000 | L_tr: 1.1748 | Acc: 0.5239\n",
      "Ep 2/80 | LR: 0.001000 | L_tr: 0.7858 | Acc: 0.5984\n",
      "Ep 3/80 | LR: 0.001000 | L_tr: 0.9298 | Acc: 0.5984\n",
      "Ep 4/80 | LR: 0.001000 | L_tr: 1.0976 | Acc: 0.5957\n",
      "Ep 5/80 | LR: 0.001000 | L_tr: 0.9032 | Acc: 0.5895\n",
      "Ep 6/80 | LR: 0.001000 | L_tr: 0.8656 | Acc: 0.5984\n",
      "Ep 7/80 | LR: 0.001000 | L_tr: 0.6060 | Acc: 0.0115\n",
      "Ep 8/80 | LR: 0.000500 | L_tr: 0.8084 | Acc: 0.5984\n",
      "Ep 9/80 | LR: 0.000500 | L_tr: 1.0711 | Acc: 0.5984\n",
      "Ep 10/80 | LR: 0.000500 | L_tr: 0.6063 | Acc: 0.5984\n",
      "Ep 11/80 | LR: 0.000500 | L_tr: 1.0149 | Acc: 0.5975\n",
      "Ep 12/80 | LR: 0.000500 | L_tr: 0.6212 | Acc: 0.5984\n",
      "Ep 13/80 | LR: 0.000500 | L_tr: 0.5174 | Acc: 0.5975\n",
      "Ep 14/80 | LR: 0.000250 | L_tr: 0.4384 | Acc: 0.5984\n",
      "Ep 15/80 | LR: 0.000250 | L_tr: 0.3868 | Acc: 0.5984\n",
      "Ep 16/80 | LR: 0.000250 | L_tr: 0.3710 | Acc: 0.5984\n",
      "Ep 17/80 | LR: 0.000250 | L_tr: 0.4003 | Acc: 0.5975\n",
      "Ep 18/80 | LR: 0.000250 | L_tr: 0.4993 | Acc: 0.5975\n",
      "Ep 19/80 | LR: 0.000250 | L_tr: 0.3196 | Acc: 0.5975\n",
      "Ep 20/80 | LR: 0.000125 | L_tr: 0.2748 | Acc: 0.5975\n",
      "Ep 21/80 | LR: 0.000125 | L_tr: 0.3391 | Acc: 0.5975\n",
      "Ep 22/80 | LR: 0.000125 | L_tr: 0.2777 | Acc: 0.5975\n",
      "Ep 23/80 | LR: 0.000125 | L_tr: 0.3261 | Acc: 0.5975\n",
      "Ep 24/80 | LR: 0.000125 | L_tr: 0.3294 | Acc: 0.5975\n",
      "Ep 25/80 | LR: 0.000125 | L_tr: 0.2727 | Acc: 0.5984\n",
      "Ep 26/80 | LR: 0.000063 | L_tr: 0.3378 | Acc: 0.5966\n",
      "Ep 27/80 | LR: 0.000063 | L_tr: 0.3772 | Acc: 0.5975\n",
      "Ep 28/80 | LR: 0.000063 | L_tr: 0.3071 | Acc: 0.5975\n",
      "Ep 29/80 | LR: 0.000063 | L_tr: 0.2037 | Acc: 0.5975\n",
      "Ep 30/80 | LR: 0.000063 | L_tr: 0.2800 | Acc: 0.5975\n",
      "Ep 31/80 | LR: 0.000063 | L_tr: 0.2210 | Acc: 0.5975\n",
      "Ep 32/80 | LR: 0.000031 | L_tr: 0.2426 | Acc: 0.5975\n",
      "Ep 33/80 | LR: 0.000031 | L_tr: 0.3106 | Acc: 0.5975\n",
      "Ep 34/80 | LR: 0.000031 | L_tr: 0.3340 | Acc: 0.5975\n",
      "Ep 35/80 | LR: 0.000031 | L_tr: 0.2620 | Acc: 0.5975\n",
      "Ep 36/80 | LR: 0.000031 | L_tr: 0.2593 | Acc: 0.5975\n",
      "Ep 37/80 | LR: 0.000031 | L_tr: 0.1790 | Acc: 0.5975\n",
      "Ep 38/80 | LR: 0.000016 | L_tr: 0.2619 | Acc: 0.5975\n",
      "Ep 39/80 | LR: 0.000016 | L_tr: 0.2411 | Acc: 0.5975\n",
      "Ep 40/80 | LR: 0.000016 | L_tr: 0.2554 | Acc: 0.5975\n",
      "Ep 41/80 | LR: 0.000016 | L_tr: 0.2172 | Acc: 0.5984\n",
      "Ep 42/80 | LR: 0.000016 | L_tr: 0.2294 | Acc: 0.5975\n",
      "Ep 43/80 | LR: 0.000016 | L_tr: 0.2100 | Acc: 0.5975\n",
      "Ep 44/80 | LR: 0.000008 | L_tr: 0.2813 | Acc: 0.5984\n",
      "Ep 45/80 | LR: 0.000008 | L_tr: 0.2886 | Acc: 0.5984\n",
      "Ep 46/80 | LR: 0.000008 | L_tr: 0.2436 | Acc: 0.5984\n",
      "Ep 47/80 | LR: 0.000008 | L_tr: 0.1863 | Acc: 0.5984\n",
      "Ep 48/80 | LR: 0.000008 | L_tr: 0.2932 | Acc: 0.5984\n",
      "Ep 49/80 | LR: 0.000008 | L_tr: 0.2377 | Acc: 0.5984\n",
      "Ep 50/80 | LR: 0.000004 | L_tr: 0.3123 | Acc: 0.5984\n",
      "Ep 51/80 | LR: 0.000004 | L_tr: 0.2396 | Acc: 0.5993\n",
      "Ep 52/80 | LR: 0.000004 | L_tr: 0.2722 | Acc: 0.5984\n",
      "Ep 53/80 | LR: 0.000004 | L_tr: 0.2038 | Acc: 0.5984\n",
      "Ep 54/80 | LR: 0.000004 | L_tr: 0.2271 | Acc: 0.5984\n",
      "Ep 55/80 | LR: 0.000004 | L_tr: 0.2398 | Acc: 0.5984\n",
      "Ep 56/80 | LR: 0.000004 | L_tr: 0.3040 | Acc: 0.5984\n",
      "Ep 57/80 | LR: 0.000002 | L_tr: 0.2641 | Acc: 0.5984\n",
      "Ep 58/80 | LR: 0.000002 | L_tr: 0.2538 | Acc: 0.5984\n",
      "Ep 59/80 | LR: 0.000002 | L_tr: 0.2203 | Acc: 0.5984\n",
      "Ep 60/80 | LR: 0.000002 | L_tr: 0.3169 | Acc: 0.5984\n",
      "Ep 61/80 | LR: 0.000002 | L_tr: 0.2560 | Acc: 0.5984\n",
      "Ep 62/80 | LR: 0.000002 | L_tr: 0.2557 | Acc: 0.5984\n",
      "Ep 63/80 | LR: 0.000001 | L_tr: 0.2382 | Acc: 0.5984\n",
      "Ep 64/80 | LR: 0.000001 | L_tr: 0.2450 | Acc: 0.5984\n",
      "Ep 65/80 | LR: 0.000001 | L_tr: 0.1612 | Acc: 0.5984\n",
      "Ep 66/80 | LR: 0.000001 | L_tr: 0.3113 | Acc: 0.5984\n",
      "Ep 67/80 | LR: 0.000001 | L_tr: 0.2093 | Acc: 0.5984\n",
      "Ep 68/80 | LR: 0.000001 | L_tr: 0.2703 | Acc: 0.5984\n",
      "Ep 69/80 | LR: 0.000001 | L_tr: 0.2136 | Acc: 0.5984\n",
      "Ep 70/80 | LR: 0.000001 | L_tr: 0.1958 | Acc: 0.5984\n",
      "Ep 71/80 | LR: 0.000001 | L_tr: 0.1991 | Acc: 0.5984\n",
      "Ep 72/80 | LR: 0.000001 | L_tr: 0.1741 | Acc: 0.5984\n",
      "Ep 73/80 | LR: 0.000001 | L_tr: 0.2846 | Acc: 0.5984\n",
      "Ep 74/80 | LR: 0.000001 | L_tr: 0.2372 | Acc: 0.5984\n",
      "Ep 75/80 | LR: 0.000001 | L_tr: 0.1678 | Acc: 0.5984\n",
      "Ep 76/80 | LR: 0.000001 | L_tr: 0.2804 | Acc: 0.5984\n",
      "Ep 77/80 | LR: 0.000001 | L_tr: 0.2630 | Acc: 0.5984\n",
      "Ep 78/80 | LR: 0.000001 | L_tr: 0.2710 | Acc: 0.5984\n",
      "Ep 79/80 | LR: 0.000001 | L_tr: 0.1981 | Acc: 0.5984\n",
      "Ep 80/80 | LR: 0.000001 | L_tr: 0.2222 | Acc: 0.5984\n",
      "Final Accuracy (RPCA): 0.5993\n",
      "Generating Confusion Matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/737121878.py:335: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cm.load_state_dict(torch.load(model_save_path, map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with RPCA.\n",
      "\n",
      "\n",
      "################################################\n",
      "STARTING SCENARIO: RAW\n",
      "################################################\n",
      "*** DEBUG MODE: Using 50.0% of data (940 samples) ***\n",
      "Loading 940 samples - Mode: RAW DATA (No RPCA)...\n",
      "Processing 100/940...\n",
      "Processing 200/940...\n",
      "Processing 300/940...\n",
      "Processing 400/940...\n",
      "Processing 500/940...\n",
      "Processing 600/940...\n",
      "Processing 700/940...\n",
      "Processing 800/940...\n",
      "Processing 900/940...\n",
      "--- Repeat 1/1 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1/80 | LR: 0.001000 | L_tr: 1.6359 | Acc: 0.4592\n",
      "Ep 2/80 | LR: 0.001000 | L_tr: 0.9560 | Acc: 0.5488\n",
      "Ep 3/80 | LR: 0.001000 | L_tr: 0.4081 | Acc: 0.5984\n",
      "Ep 4/80 | LR: 0.001000 | L_tr: 0.2887 | Acc: 0.5922\n",
      "Ep 5/80 | LR: 0.001000 | L_tr: 0.2744 | Acc: 0.5975\n",
      "Ep 6/80 | LR: 0.001000 | L_tr: 0.2619 | Acc: 0.5984\n",
      "Ep 7/80 | LR: 0.001000 | L_tr: 0.2969 | Acc: 0.5949\n",
      "Ep 8/80 | LR: 0.001000 | L_tr: 0.3000 | Acc: 0.5984\n",
      "Ep 9/80 | LR: 0.000500 | L_tr: 0.4339 | Acc: 0.5975\n",
      "Ep 10/80 | LR: 0.000500 | L_tr: 0.2407 | Acc: 0.5984\n",
      "Ep 11/80 | LR: 0.000500 | L_tr: 0.1940 | Acc: 0.5993\n",
      "Ep 12/80 | LR: 0.000500 | L_tr: 0.2566 | Acc: 0.5993\n",
      "Ep 13/80 | LR: 0.000500 | L_tr: 0.2462 | Acc: 0.5984\n",
      "Ep 14/80 | LR: 0.000500 | L_tr: 0.2257 | Acc: 0.5984\n",
      "Ep 15/80 | LR: 0.000500 | L_tr: 0.1991 | Acc: 0.5993\n",
      "Ep 16/80 | LR: 0.000500 | L_tr: 0.1731 | Acc: 0.5984\n",
      "Ep 17/80 | LR: 0.000250 | L_tr: 0.1845 | Acc: 0.5957\n",
      "Ep 18/80 | LR: 0.000250 | L_tr: 0.2348 | Acc: 0.5975\n",
      "Ep 19/80 | LR: 0.000250 | L_tr: 0.1965 | Acc: 0.5949\n",
      "Ep 20/80 | LR: 0.000250 | L_tr: 0.1245 | Acc: 0.5984\n",
      "Ep 21/80 | LR: 0.000250 | L_tr: 0.1506 | Acc: 0.5966\n",
      "Ep 22/80 | LR: 0.000250 | L_tr: 0.1296 | Acc: 0.6011\n",
      "Ep 23/80 | LR: 0.000250 | L_tr: 0.1655 | Acc: 0.5975\n",
      "Ep 24/80 | LR: 0.000250 | L_tr: 0.1438 | Acc: 0.5984\n",
      "Ep 25/80 | LR: 0.000250 | L_tr: 0.1801 | Acc: 0.5975\n",
      "Ep 26/80 | LR: 0.000250 | L_tr: 0.2266 | Acc: 0.5984\n",
      "Ep 27/80 | LR: 0.000250 | L_tr: 0.1470 | Acc: 0.5949\n",
      "Ep 28/80 | LR: 0.000125 | L_tr: 0.1634 | Acc: 0.5949\n",
      "Ep 29/80 | LR: 0.000125 | L_tr: 0.1243 | Acc: 0.5975\n",
      "Ep 30/80 | LR: 0.000125 | L_tr: 0.1404 | Acc: 0.6002\n",
      "Ep 31/80 | LR: 0.000125 | L_tr: 0.1344 | Acc: 0.6020\n",
      "Ep 32/80 | LR: 0.000125 | L_tr: 0.1455 | Acc: 0.5984\n",
      "Ep 33/80 | LR: 0.000125 | L_tr: 0.1579 | Acc: 0.5984\n",
      "Ep 34/80 | LR: 0.000125 | L_tr: 0.1273 | Acc: 0.5966\n",
      "Ep 35/80 | LR: 0.000125 | L_tr: 0.1039 | Acc: 0.5975\n",
      "Ep 36/80 | LR: 0.000125 | L_tr: 0.1312 | Acc: 0.6002\n",
      "Ep 37/80 | LR: 0.000063 | L_tr: 0.1278 | Acc: 0.5957\n",
      "Ep 38/80 | LR: 0.000063 | L_tr: 0.1172 | Acc: 0.5984\n",
      "Ep 39/80 | LR: 0.000063 | L_tr: 0.1136 | Acc: 0.6002\n",
      "Ep 40/80 | LR: 0.000063 | L_tr: 0.1150 | Acc: 0.5993\n",
      "Ep 41/80 | LR: 0.000063 | L_tr: 0.1110 | Acc: 0.5984\n",
      "Ep 42/80 | LR: 0.000063 | L_tr: 0.1137 | Acc: 0.5975\n",
      "Ep 43/80 | LR: 0.000031 | L_tr: 0.0874 | Acc: 0.5984\n",
      "Ep 44/80 | LR: 0.000031 | L_tr: 0.1384 | Acc: 0.5993\n",
      "Ep 45/80 | LR: 0.000031 | L_tr: 0.1629 | Acc: 0.5984\n",
      "Ep 46/80 | LR: 0.000031 | L_tr: 0.0867 | Acc: 0.5984\n",
      "Ep 47/80 | LR: 0.000031 | L_tr: 0.1029 | Acc: 0.5957\n",
      "Ep 48/80 | LR: 0.000031 | L_tr: 0.0897 | Acc: 0.5984\n",
      "Ep 49/80 | LR: 0.000016 | L_tr: 0.1102 | Acc: 0.5957\n",
      "Ep 50/80 | LR: 0.000016 | L_tr: 0.1156 | Acc: 0.5975\n",
      "Ep 51/80 | LR: 0.000016 | L_tr: 0.1335 | Acc: 0.5975\n",
      "Ep 52/80 | LR: 0.000016 | L_tr: 0.1249 | Acc: 0.5984\n",
      "Ep 53/80 | LR: 0.000016 | L_tr: 0.1303 | Acc: 0.5975\n",
      "Ep 54/80 | LR: 0.000016 | L_tr: 0.1212 | Acc: 0.5975\n",
      "Ep 55/80 | LR: 0.000008 | L_tr: 0.1499 | Acc: 0.5966\n",
      "Ep 56/80 | LR: 0.000008 | L_tr: 0.0937 | Acc: 0.5975\n",
      "Ep 57/80 | LR: 0.000008 | L_tr: 0.1376 | Acc: 0.5984\n",
      "Ep 58/80 | LR: 0.000008 | L_tr: 0.1344 | Acc: 0.5975\n",
      "Ep 59/80 | LR: 0.000008 | L_tr: 0.1317 | Acc: 0.5975\n",
      "Ep 60/80 | LR: 0.000008 | L_tr: 0.1056 | Acc: 0.5984\n",
      "Ep 61/80 | LR: 0.000004 | L_tr: 0.1266 | Acc: 0.5993\n",
      "Ep 62/80 | LR: 0.000004 | L_tr: 0.1445 | Acc: 0.5984\n",
      "Ep 63/80 | LR: 0.000004 | L_tr: 0.1414 | Acc: 0.5993\n",
      "Ep 64/80 | LR: 0.000004 | L_tr: 0.0758 | Acc: 0.5966\n",
      "Ep 65/80 | LR: 0.000004 | L_tr: 0.1298 | Acc: 0.5975\n",
      "Ep 66/80 | LR: 0.000004 | L_tr: 0.1136 | Acc: 0.5975\n",
      "Ep 67/80 | LR: 0.000002 | L_tr: 0.1514 | Acc: 0.5975\n",
      "Ep 68/80 | LR: 0.000002 | L_tr: 0.0846 | Acc: 0.5984\n",
      "Ep 69/80 | LR: 0.000002 | L_tr: 0.1183 | Acc: 0.5984\n",
      "Ep 70/80 | LR: 0.000002 | L_tr: 0.1378 | Acc: 0.5984\n",
      "Ep 71/80 | LR: 0.000002 | L_tr: 0.1095 | Acc: 0.5984\n",
      "Ep 72/80 | LR: 0.000002 | L_tr: 0.1252 | Acc: 0.5975\n",
      "Ep 73/80 | LR: 0.000001 | L_tr: 0.1452 | Acc: 0.5975\n",
      "Ep 74/80 | LR: 0.000001 | L_tr: 0.1068 | Acc: 0.5975\n",
      "Ep 75/80 | LR: 0.000001 | L_tr: 0.1137 | Acc: 0.5975\n",
      "Ep 76/80 | LR: 0.000001 | L_tr: 0.0860 | Acc: 0.5984\n",
      "Ep 77/80 | LR: 0.000001 | L_tr: 0.1098 | Acc: 0.5984\n",
      "Ep 78/80 | LR: 0.000001 | L_tr: 0.1211 | Acc: 0.5975\n",
      "Ep 79/80 | LR: 0.000001 | L_tr: 0.1157 | Acc: 0.5975\n",
      "Ep 80/80 | LR: 0.000001 | L_tr: 0.1337 | Acc: 0.5975\n",
      "Final Accuracy (RAW): 0.6020\n",
      "Generating Confusion Matrix...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/737121878.py:335: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_cm.load_state_dict(torch.load(model_save_path, map_location=\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with RAW.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as scio\n",
    "import time\n",
    "import torch\n",
    "import gc\n",
    "from numpy.linalg import svd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch._dynamo\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- تنظیمات سیستمی ---\n",
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# --------------------------\n",
    "# 1. تنظیمات (Configuration)\n",
    "# --------------------------\n",
    "preset = {\n",
    "    \"model\": \"THAT\",          \n",
    "    \"task\": \"activity\",       \n",
    "    \"repeat\": 1,\n",
    "    \"path\": {\n",
    "        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   \n",
    "        \"data_y\": \"/kaggle/input/wimans/annotation.csv\", \n",
    "    },\n",
    "    \"data\": {\n",
    "        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  \n",
    "        \"wifi_band\": [\"2.4\"],                         \n",
    "        \"environment\": [\"classroom\"],                 \n",
    "        \"length\": 3000,\n",
    "        \n",
    "        # 1.0 = 100% data (Full run) | 0.1 = 10% data (Quick test)\n",
    "        \"subset_ratio\": 0.5,  \n",
    "    },\n",
    "    \"nn\": {\n",
    "        \"lr\": 1e-3,           \n",
    "        \"epoch\": 80,          \n",
    "        \"batch_size\": 32,    \n",
    "        \"threshold\": 0.5,\n",
    "        \"patience\": 5,        \n",
    "        \"factor\": 0.5,        \n",
    "        \"min_lr\": 1e-6        \n",
    "    },\n",
    "    \"encoding\": {\n",
    "        \"activity\": {\n",
    "            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# --------------------------\n",
    "# 2. توابع RPCA و لود دیتا\n",
    "# --------------------------\n",
    "def soft_threshold(x, epsilon):\n",
    "    return np.maximum(np.abs(x) - epsilon, 0) * np.sign(x)\n",
    "\n",
    "def robust_pca(M, max_iter=10, tol=1e-4):\n",
    "    n1, n2 = M.shape\n",
    "    lambda_param = 1 / np.sqrt(max(n1, n2))\n",
    "    Y = M / np.maximum(np.linalg.norm(M, 2), np.linalg.norm(M, np.inf) / lambda_param)\n",
    "    L = np.zeros_like(M)\n",
    "    S = np.zeros_like(M)\n",
    "    mu = 1.25 / np.linalg.norm(M, 2)\n",
    "    rho = 1.5\n",
    "    for i in range(max_iter):\n",
    "        temp_L = M - S + (1/mu) * Y\n",
    "        U, Sigma, Vt = svd(temp_L, full_matrices=False)\n",
    "        Sigma_thresh = soft_threshold(Sigma, 1/mu)\n",
    "        L_new = np.dot(U * Sigma_thresh, Vt)\n",
    "        temp_S = M - L_new + (1/mu) * Y\n",
    "        S_new = soft_threshold(temp_S, lambda_param/mu)\n",
    "        error = np.linalg.norm(M - L_new - S_new, 'fro') / np.linalg.norm(M, 'fro')\n",
    "        L = L_new; S = S_new\n",
    "        if error < tol: break\n",
    "        Y = Y + mu * (M - L - S)\n",
    "        mu = min(mu * rho, 1e7)\n",
    "    return L, S\n",
    "\n",
    "def load_data_y(var_path_data_y, var_environment=None, var_wifi_band=None, var_num_users=None):\n",
    "    data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "    if var_environment is not None: data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "    if var_wifi_band is not None: data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "    if var_num_users is not None: data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "    return data_pd_y\n",
    "\n",
    "def load_data_x(var_path_data_x, var_label_list, use_rpca=True):\n",
    "    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "    data_x = []\n",
    "    mode_str = \"WITH RPCA\" if use_rpca else \"RAW DATA (No RPCA)\"\n",
    "    print(f\"Loading {len(var_path_list)} samples - Mode: {mode_str}...\")\n",
    "    for i, var_path in enumerate(var_path_list):\n",
    "        if i % 100 == 0 and i > 0: print(f\"Processing {i}/{len(var_path_list)}...\")\n",
    "        data_csi = np.load(var_path) \n",
    "        data_csi_2d = data_csi.reshape(data_csi.shape[0], -1)\n",
    "        target_len = preset[\"data\"][\"length\"]\n",
    "        current_len = data_csi_2d.shape[0]\n",
    "        var_pad_length = target_len - current_len\n",
    "        if var_pad_length > 0: data_csi_pad = np.pad(data_csi_2d, ((0, var_pad_length), (0, 0)), mode='constant')\n",
    "        else: data_csi_pad = data_csi_2d[:target_len, :]\n",
    "        if use_rpca:\n",
    "            L, S = robust_pca(data_csi_pad)\n",
    "            final_sample = np.concatenate([L, S], axis=1) \n",
    "        else:\n",
    "            final_sample = data_csi_pad\n",
    "        data_x.append(final_sample)\n",
    "    data_x = np.array(data_x)\n",
    "    return data_x\n",
    "\n",
    "def encode_data_y(data_pd_y, var_task):\n",
    "    if var_task == \"activity\": return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "    return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "\n",
    "def encode_activity(data_pd_y, var_encoding):\n",
    "    cols = [f\"user_{i}_activity\" for i in range(1, 7)]\n",
    "    data = data_pd_y[cols].to_numpy(copy=True).astype(str)\n",
    "    return np.array([[var_encoding[y] for y in sample] for sample in data])\n",
    "\n",
    "# --------------------------\n",
    "# 3. مدل THAT\n",
    "# --------------------------\n",
    "class Gaussian_Position(torch.nn.Module):\n",
    "    def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n",
    "        super(Gaussian_Position, self).__init__()\n",
    "        self.var_embedding = torch.nn.Parameter(torch.zeros([var_num_gaussian, var_dim_feature]), requires_grad=True)\n",
    "        torch.nn.init.xavier_uniform_(self.var_embedding)\n",
    "        self.var_position = torch.nn.Parameter(torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian), requires_grad=False)\n",
    "        self.var_mu = torch.nn.Parameter(torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0), requires_grad=True)\n",
    "        self.var_sigma = torch.nn.Parameter(torch.tensor([50.0] * var_num_gaussian).unsqueeze(0), requires_grad=True)\n",
    "    def forward(self, var_input):\n",
    "        var_pdf = - (self.var_position - self.var_mu)**2 / (2 * self.var_sigma**2) - torch.log(self.var_sigma)\n",
    "        var_pdf = torch.softmax(var_pdf, dim=-1)\n",
    "        return var_input + torch.matmul(var_pdf, self.var_embedding).unsqueeze(0)\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n",
    "        self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n",
    "        self.layer_dropout_0 = torch.nn.Dropout(0.1)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n",
    "        self.layer_cnn = torch.nn.ModuleList([torch.nn.Sequential(torch.nn.Conv1d(var_dim_feature, var_dim_feature, s, padding=\"same\"), torch.nn.BatchNorm1d(var_dim_feature), torch.nn.Dropout(0.1), torch.nn.LeakyReLU()) for s in var_size_cnn])\n",
    "        self.layer_dropout_1 = torch.nn.Dropout(0.1)\n",
    "    def forward(self, var_input):\n",
    "        var_t = self.layer_norm_0(var_input)\n",
    "        var_t, _ = self.layer_attention(var_t, var_t, var_t)\n",
    "        var_t = self.layer_dropout_0(var_t) + var_input\n",
    "        var_s = self.layer_norm_1(var_t).permute(0, 2, 1)\n",
    "        var_c = torch.stack([l(var_s) for l in self.layer_cnn], dim=0)\n",
    "        var_s = self.layer_dropout_1((torch.sum(var_c, dim=0) / len(self.layer_cnn)).permute(0, 2, 1))\n",
    "        return var_s + var_t\n",
    "\n",
    "class THAT(torch.nn.Module):\n",
    "    def __init__(self, var_x_shape, var_y_shape):\n",
    "        super(THAT, self).__init__()\n",
    "        var_dim_feature, var_dim_time = var_x_shape[-1], var_x_shape[-2]\n",
    "        var_dim_output = var_y_shape[-1]\n",
    "        self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "        self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n",
    "        self.layer_left_encoder = torch.nn.ModuleList([Encoder(var_dim_feature, 10, [1, 3, 5]) for _ in range(4)])\n",
    "        self.layer_left_norm = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n",
    "        self.layer_left_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_feature, 128, k) for k in [8, 16]])\n",
    "        self.layer_left_dropout = torch.nn.Dropout(0.5)\n",
    "        var_dim_right = var_dim_time // 20\n",
    "        self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "        self.layer_right_encoder = torch.nn.ModuleList([Encoder(var_dim_right, 10, [1, 2, 3])])\n",
    "        self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n",
    "        self.layer_right_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_right, 16, k) for k in [2, 4]])\n",
    "        self.layer_right_dropout = torch.nn.Dropout(0.5)\n",
    "        self.layer_leakyrelu = torch.nn.LeakyReLU()\n",
    "        self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n",
    "    def forward(self, var_input):\n",
    "        v_l = self.layer_left_gaussian(self.layer_left_pooling(var_input.permute(0, 2, 1)).permute(0, 2, 1))\n",
    "        for l in self.layer_left_encoder: v_l = l(v_l)\n",
    "        v_l = self.layer_left_norm(v_l).permute(0, 2, 1)\n",
    "        v_l = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_l)), dim=-1) for cnn in self.layer_left_cnn], dim=-1)\n",
    "        v_l = self.layer_left_dropout(v_l)\n",
    "        v_r = self.layer_right_pooling(var_input.permute(0, 2, 1))\n",
    "        for l in self.layer_right_encoder: v_r = l(v_r)\n",
    "        v_r = self.layer_right_norm(v_r).permute(0, 2, 1)\n",
    "        v_r = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_r)), dim=-1) for cnn in self.layer_right_cnn], dim=-1)\n",
    "        v_r = self.layer_right_dropout(v_r)\n",
    "        return self.layer_output(torch.cat([v_l, v_r], dim=-1))\n",
    "\n",
    "# --------------------------\n",
    "# 4. Training Loop\n",
    "# --------------------------\n",
    "def train(model, optimizer, loss_fn, train_loader, test_loader, threshold, epochs, device, model_path):\n",
    "    best_acc = -1.0\n",
    "    best_w = deepcopy(model.state_dict())\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='max', factor=preset[\"nn\"][\"factor\"], patience=preset[\"nn\"][\"patience\"],\n",
    "        min_lr=preset[\"nn\"][\"min_lr\"], verbose=True\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "        \n",
    "        # --- [MODIFIED] Using requested variable names ---\n",
    "        for data_batch_x, data_batch_y in train_loader:\n",
    "            data_batch_x = data_batch_x.to(device)\n",
    "            data_batch_y = data_batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predict_train_y = model(data_batch_x)\n",
    "            \n",
    "            # --- [REQUESTED LINE] ---\n",
    "            loss_value = loss_fn(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n",
    "            \n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tx, ty = next(iter(test_loader))\n",
    "            tx, ty = tx.to(device), ty.to(device)\n",
    "            pred_t = model(tx)\n",
    "            \n",
    "            p_cls = (torch.sigmoid(pred_t) > threshold).float().cpu().numpy()\n",
    "            t_cls = ty.cpu().numpy()\n",
    "            acc = accuracy_score(t_cls.reshape(-1, t_cls.shape[-1]), p_cls.reshape(-1, t_cls.shape[-1]))\n",
    "            \n",
    "        scheduler.step(acc)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Ep {epoch+1}/{epochs} | LR: {current_lr:.6f} | L_tr: {loss_value.item():.4f} | Acc: {acc:.4f}\")\n",
    "        \n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_w = deepcopy(model.state_dict())\n",
    "            \n",
    "    torch.save(best_w, model_path)\n",
    "    return best_w\n",
    "\n",
    "def save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes, title_text):\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in data_loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb) \n",
    "            logits = logits.reshape(-1, num_classes) \n",
    "            yb = yb.reshape(-1, num_classes)        \n",
    "            y_pred.extend(torch.argmax(logits, dim=1).cpu().numpy().tolist())\n",
    "            y_true.extend(torch.argmax(yb, dim=1).cpu().numpy().tolist())\n",
    "    \n",
    "    labels = list(range(num_classes))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(12, 12))\n",
    "    disp.plot(ax=ax, xticks_rotation=\"vertical\", cmap='Blues')\n",
    "    ax.set_title(title_text)\n",
    "    with PdfPages(pdf_path) as pdf: pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "# --------------------------\n",
    "# 5. اجرا\n",
    "# --------------------------\n",
    "def run_experiment(scenario_name, use_rpca):\n",
    "    print(f\"\\n################################################\")\n",
    "    print(f\"STARTING SCENARIO: {scenario_name}\")\n",
    "    print(f\"################################################\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    current_run_name = f\"{preset['model']}_{preset['task']}_{scenario_name}\"\n",
    "    model_save_path = f\"{current_run_name}_best_model.pt\"\n",
    "    json_save_path = f\"result_{current_run_name}.json\"\n",
    "    pdf_save_path = f\"Confusion_{current_run_name}.pdf\"\n",
    "    \n",
    "    # 1. Load Labels\n",
    "    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], preset[\"data\"][\"environment\"], preset[\"data\"][\"wifi_band\"], preset[\"data\"][\"num_users\"])\n",
    "    \n",
    "    # Apply Subset Ratio\n",
    "    subset_ratio = preset[\"data\"][\"subset_ratio\"]\n",
    "    if subset_ratio < 1.0:\n",
    "        data_pd_y = data_pd_y.sample(frac=subset_ratio, random_state=42).reset_index(drop=True)\n",
    "        print(f\"*** DEBUG MODE: Using {subset_ratio*100}% of data ({len(data_pd_y)} samples) ***\")\n",
    "    \n",
    "    # 2. Load X\n",
    "    data_x = load_data_x(preset[\"path\"][\"data_x\"], data_pd_y[\"label\"].tolist(), use_rpca=use_rpca)\n",
    "    data_y = encode_data_y(data_pd_y, preset[\"task\"])\n",
    "    \n",
    "    # 3. Split\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n",
    "    train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "    test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "    train_loader = DataLoader(train_ds, batch_size=preset[\"nn\"][\"batch_size\"], shuffle=True)\n",
    "    test_loader = DataLoader(test_ds, batch_size=len(test_ds), shuffle=False)\n",
    "    \n",
    "    result = {\"accuracy\": []}\n",
    "    \n",
    "    for r in range(preset[\"repeat\"]):\n",
    "        print(f\"--- Repeat {r+1}/{preset['repeat']} ---\")\n",
    "        torch.random.manual_seed(r + 39)\n",
    "        \n",
    "        model = THAT(train_x[0].shape, train_y[0].reshape(-1).shape).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=preset[\"nn\"][\"lr\"])\n",
    "        loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        best_w = train(model, optimizer, loss_fn, train_loader, test_loader, \n",
    "                       preset[\"nn\"][\"threshold\"], preset[\"nn\"][\"epoch\"], device, model_save_path)\n",
    "        \n",
    "        model.load_state_dict(best_w)\n",
    "        with torch.no_grad():\n",
    "            preds = model(torch.from_numpy(test_x).to(device))\n",
    "            preds_reshaped = (torch.sigmoid(preds) > preset[\"nn\"][\"threshold\"]).float().cpu().numpy().reshape(-1, 9)\n",
    "            targets_reshaped = test_y.reshape(-1, 9)\n",
    "            acc = accuracy_score(targets_reshaped, preds_reshaped)\n",
    "            result[\"accuracy\"].append(acc)\n",
    "            \n",
    "    print(f\"Final Accuracy ({scenario_name}): {np.mean(result['accuracy']):.4f}\")\n",
    "    with open(json_save_path, \"w\") as f: json.dump(result, f, indent=4)\n",
    "    \n",
    "    print(\"Generating Confusion Matrix...\")\n",
    "    model_cm = THAT(test_x[0].shape, test_y[0].reshape(-1).shape).to(\"cpu\")\n",
    "    model_cm.load_state_dict(torch.load(model_save_path, map_location=\"cpu\"))\n",
    "    cm_loader = DataLoader(TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y)), batch_size=32)\n",
    "    num_classes = test_y.shape[2] \n",
    "    title = f\"Confusion Matrix: {scenario_name} (Acc: {np.mean(result['accuracy']):.2f} - {subset_ratio*100}% Data)\"\n",
    "    save_multiclass_confusion_matrix(model_cm, cm_loader, \"cpu\", pdf_save_path, num_classes, title)\n",
    "    \n",
    "    del model, model_cm, train_x, test_x, data_x\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"Done with {scenario_name}.\\n\")\n",
    "\n",
    "def run():\n",
    "    scenarios = [\n",
    "        (\"RPCA\", True),\n",
    "        (\"RAW\", False)\n",
    "    ]\n",
    "    for name, rpca_flag in scenarios:\n",
    "        run_experiment(name, rpca_flag)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575f7a94",
   "metadata": {
    "papermill": {
     "duration": 0.01109,
     "end_time": "2025-11-25T06:15:14.595513",
     "exception": false,
     "start_time": "2025-11-25T06:15:14.584423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4451316,
     "sourceId": 7638081,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7503373,
     "sourceId": 11934698,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2175.418559,
   "end_time": "2025-11-25T06:15:17.928444",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-25T05:39:02.509885",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
