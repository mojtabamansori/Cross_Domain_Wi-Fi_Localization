{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5186896a",
   "metadata": {
    "papermill": {
     "duration": 0.008256,
     "end_time": "2025-12-28T16:51:29.780971",
     "exception": false,
     "start_time": "2025-12-28T16:51:29.772715",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 1: Library Imports\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b7a1a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:29.795763Z",
     "iopub.status.busy": "2025-12-28T16:51:29.795503Z",
     "iopub.status.idle": "2025-12-28T16:51:40.069840Z",
     "shell.execute_reply": "2025-12-28T16:51:40.069253Z"
    },
    "papermill": {
     "duration": 10.283282,
     "end_time": "2025-12-28T16:51:40.071279",
     "exception": false,
     "start_time": "2025-12-28T16:51:29.787997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 1: Library Imports\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as scio\n",
    "import time\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import torch._dynamo\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# from ptflops import get_model_complexity_info\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from copy import deepcopy\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64627a61",
   "metadata": {
    "papermill": {
     "duration": 0.006753,
     "end_time": "2025-12-28T16:51:40.085415",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.078662",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 2: preset.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a898c2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.100299Z",
     "iopub.status.busy": "2025-12-28T16:51:40.099970Z",
     "iopub.status.idle": "2025-12-28T16:51:40.108528Z",
     "shell.execute_reply": "2025-12-28T16:51:40.108000Z"
    },
    "papermill": {
     "duration": 0.01733,
     "end_time": "2025-12-28T16:51:40.109524",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.092194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few=empty_room,100,5,m=THAT,t=activity,epoch=1000,batch=64,environment=['classroom']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "[file]          preset.py\n",
    "[description]   default settings of WiFi-based models\n",
    "\"\"\"\n",
    "minidata_set = 1\n",
    "preset = {\n",
    "    # define model\n",
    "    \"model\": \"THAT\",  # \"ST-RF\", \"MLP\", \"LSTM\", \"CNN-1D\", \"CNN-2D\", \"CLSTM\", \"ABLSTM\", \"THAT\", \"bi-LSTM\", \"ResNet18\"\n",
    "    # define task\n",
    "    \"task\": \"activity\",  # \"identity\", \"activity\", \"location\", \"count\"\n",
    "    # number of repeated experiments\n",
    "    \"repeat\": 1,\n",
    "    # path of data\n",
    "    \"path\": {\n",
    "        # \"data_x\": \"/kaggle/input/wimans/wifi_csi/mat\",   # directory of CSI amplitude files \n",
    "        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   # directory of CSI amplitude files \n",
    "        \"data_y\": \"/kaggle/input/wimans/annotation.csv\", # path of annotation file\n",
    "        \"save\": \"result_lstm_epoch=80_batchsize=32_envs=empty_room_wifiband=2.4.json\"               # path to save results\n",
    "    },\n",
    "    # data selection for experiments\n",
    "    \"data\": {\n",
    "        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  # select number(s) of users\n",
    "        \"wifi_band\": [\"2.4\"],                         # select WiFi band(s)\n",
    "        \"environment\": [\"classroom\"],                 # select environment(s) [\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\n",
    "        \"length\": 3000,                               # default length of CSI\n",
    "    },\n",
    "    # hyperparameters of models\n",
    "    \"nn\": {\n",
    "        \"lr\": 1e-6,           # learning rate\n",
    "        \"epoch\": 1000,         # number of epochs\n",
    "        \"batch_size\": 64,    # batch size\n",
    "        \"threshold\": 0.5,     # threshold to binarize sigmoid outputs\n",
    "    },\n",
    "    # encoding of activities and locations\n",
    "    \"encoding\": {\n",
    "        \"activity\": {  # encoding of different activities\n",
    "            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        },\n",
    "        \"location\": {  # encoding of different locations\n",
    "            \"nan\":  [0, 0, 0, 0, 0],\n",
    "            \"a\":    [1, 0, 0, 0, 0],\n",
    "            \"b\":    [0, 1, 0, 0, 0],\n",
    "            \"c\":    [0, 0, 1, 0, 0],\n",
    "            \"d\":    [0, 0, 0, 1, 0],\n",
    "            \"e\":    [0, 0, 0, 0, 1],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# Few-shot parameters (manually set)\n",
    "dest_env = \"empty_room\"       # Destination environment[\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\n",
    "few_shot_epochs = 100         # Number of epochs for few-shot training\n",
    "few_shot_num_samples = 5     # Number of samples to use from the destination test data\n",
    "\n",
    "Confusion_matrix = 1\n",
    "\n",
    "name_run = \"few={},{},{},m={},t={},epoch={},batch={},environment={}\".format(dest_env, few_shot_epochs, few_shot_num_samples, preset[\"model\"], preset[\"task\"], preset[\"nn\"][\"epoch\"], preset[\"nn\"][\"batch_size\"], preset[\"data\"][\"environment\"])\n",
    "print(name_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897879f4",
   "metadata": {
    "papermill": {
     "duration": 0.006633,
     "end_time": "2025-12-28T16:51:40.123157",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.116524",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 3: load_data.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa933f0",
   "metadata": {
    "papermill": {
     "duration": 0.007011,
     "end_time": "2025-12-28T16:51:40.136836",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.129825",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "raw + sparse\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c704494b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.152297Z",
     "iopub.status.busy": "2025-12-28T16:51:40.152053Z",
     "iopub.status.idle": "2025-12-28T16:51:40.177159Z",
     "shell.execute_reply": "2025-12-28T16:51:40.176443Z"
    },
    "papermill": {
     "duration": 0.034185,
     "end_time": "2025-12-28T16:51:40.178304",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.144119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 3: load_data.py  (AMP + RPCA sparse, and RAW + alpha*SPARSE)\n",
    "# =========================\n",
    "\"\"\"\n",
    "[file]          load_data.py\n",
    "[description]   load annotation file and CSI amplitude, and encode labels\n",
    "                (Test mode) X_input = X_raw + alpha * X_sparse\n",
    "                where X_sparse is RPCA sparse component computed per (Tx,Rx) link\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd  # Cell1 already imports, but safe here too\n",
    "\n",
    "# =========================================================\n",
    "# NEW TEST SETTINGS\n",
    "# =========================================================\n",
    "# \"raw\"            : use amplitude as-is\n",
    "# \"sparse\"         : use RPCA sparse component only\n",
    "# \"raw_plus_sparse\": raw + alpha*sparse  (your requested test)\n",
    "CSI_INPUT_MODE = \"raw_plus_sparse\"   # <-- \"raw\" / \"sparse\" / \"raw_plus_sparse\"\n",
    "\n",
    "# weight of sparse when adding to raw\n",
    "SPARSE_ALPHA = 1.0\n",
    "\n",
    "# keep amplitudes non-negative after addition (recommended)\n",
    "CLAMP_NONNEG = True\n",
    "\n",
    "# RPCA settings (IALM)\n",
    "RPCA_MAX_ITER = 60\n",
    "RPCA_TOL      = 1e-5\n",
    "RPCA_RHO      = 1.5\n",
    "RPCA_MU_INIT  = None\n",
    "\n",
    "# lambda options you asked before\n",
    "# \"classic\": 1/sqrt(max(m,n))\n",
    "# \"median\" : 1/sqrt(max(m,n)) * median(abs(M))\n",
    "# \"scaled\" : 1.2/sqrt(max(m,n))\n",
    "RPCA_LAMBDA_MODE = \"median\"   # <-- \"classic\" / \"median\" / \"scaled\"\n",
    "\n",
    "# cache for speed\n",
    "CACHE_ENABLED = True\n",
    "CACHE_ROOT = \"/kaggle/working/csi_cache_amp_raw_plus_sparse\"\n",
    "\n",
    "# debug print once to confirm amplitude/phase\n",
    "_DEBUG_PRINT_ONCE = True\n",
    "\n",
    "# expected antenna/subcarrier dims (WiMANS typical)\n",
    "TX = 3\n",
    "RX = 3\n",
    "SC = 30\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "# =========================\n",
    "# RPCA helpers (IALM)\n",
    "# =========================\n",
    "def _compute_lambda(M: np.ndarray) -> float:\n",
    "    m, n = M.shape\n",
    "    base = 1.0 / np.sqrt(max(m, n))\n",
    "\n",
    "    if RPCA_LAMBDA_MODE == \"classic\":\n",
    "        return base\n",
    "\n",
    "    if RPCA_LAMBDA_MODE == \"scaled\":\n",
    "        return 1.2 * base\n",
    "\n",
    "    if RPCA_LAMBDA_MODE == \"median\":\n",
    "        med = np.median(np.abs(M))\n",
    "        med = float(med) if med > 1e-12 else 1e-12\n",
    "        return base * med\n",
    "\n",
    "    raise ValueError(f\"Unknown RPCA_LAMBDA_MODE: {RPCA_LAMBDA_MODE}\")\n",
    "\n",
    "\n",
    "def _soft_threshold(X: np.ndarray, tau: float) -> np.ndarray:\n",
    "    return np.sign(X) * np.maximum(np.abs(X) - tau, 0.0)\n",
    "\n",
    "\n",
    "def _svt(X: np.ndarray, tau: float) -> np.ndarray:\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    s_thr = np.maximum(s - tau, 0.0)\n",
    "    if np.all(s_thr == 0):\n",
    "        return np.zeros_like(X)\n",
    "    return (U * s_thr) @ Vt\n",
    "\n",
    "\n",
    "def _rpca_ialm(M: np.ndarray,\n",
    "              max_iter: int = 60,\n",
    "              tol: float = 1e-5,\n",
    "              rho: float = 1.5,\n",
    "              mu: float | None = None):\n",
    "    \"\"\"\n",
    "    Robust PCA via Inexact Augmented Lagrange Multiplier (IALM)\n",
    "    Decompose: M = L + S\n",
    "    Returns: L, S (float32)\n",
    "    \"\"\"\n",
    "    M = M.astype(np.float64, copy=False)\n",
    "    lam = _compute_lambda(M)\n",
    "\n",
    "    if mu is None:\n",
    "        # spectral norm approx via top singular value\n",
    "        s0 = np.linalg.svd(M, compute_uv=False, full_matrices=False)[0] if M.size else 1.0\n",
    "        mu = 1.25 / (s0 + 1e-12)\n",
    "\n",
    "    L = np.zeros_like(M)\n",
    "    S = np.zeros_like(M)\n",
    "    Y = np.zeros_like(M)\n",
    "\n",
    "    normM = np.linalg.norm(M, ord=\"fro\") + 1e-12\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        L = _svt(M - S + (1.0 / mu) * Y, 1.0 / mu)\n",
    "        S = _soft_threshold(M - L + (1.0 / mu) * Y, lam / mu)\n",
    "\n",
    "        R = M - L - S\n",
    "        Y = Y + mu * R\n",
    "\n",
    "        err = np.linalg.norm(R, ord=\"fro\") / normM\n",
    "        if err < tol:\n",
    "            break\n",
    "\n",
    "        mu *= rho\n",
    "\n",
    "    return L.astype(np.float32), S.astype(np.float32)\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Data shape helpers\n",
    "# =========================\n",
    "def _ensure_shape_4d_amp(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Expect amp npy to be either:\n",
    "      - (T, 3, 3, 30)\n",
    "      - (T, 270)  -> reshape to (T,3,3,30)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x)\n",
    "    if x.ndim == 4:\n",
    "        return x\n",
    "    if x.ndim == 2 and x.shape[1] == TX * RX * SC:\n",
    "        T = x.shape[0]\n",
    "        return x.reshape(T, TX, RX, SC)\n",
    "    raise ValueError(f\"Unexpected AMP shape: {x.shape} (expected (T,{TX},{RX},{SC}) or (T,{TX*RX*SC}))\")\n",
    "\n",
    "\n",
    "def _debug_print_once(label: str, arr: np.ndarray):\n",
    "    global _DEBUG_PRINT_ONCE\n",
    "    if not _DEBUG_PRINT_ONCE:\n",
    "        return\n",
    "    _DEBUG_PRINT_ONCE = False\n",
    "    print(f\"\\n[DEBUG] First loaded AMP sample: {label}\")\n",
    "    print(f\"[DEBUG] shape={arr.shape}, dtype={arr.dtype}, complex={np.iscomplexobj(arr)}\")\n",
    "    if np.iscomplexobj(arr):\n",
    "        print(\"[DEBUG] ==> WARNING: This looks complex; amp folder usually should be real amplitude.\")\n",
    "    else:\n",
    "        print(\"[DEBUG] ==> Input is REAL -> amplitude-only (no true phase).\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def _cache_path(label: str, mode: str) -> str:\n",
    "    return os.path.join(CACHE_ROOT, mode, f\"{label}.npy\")\n",
    "\n",
    "\n",
    "def _make_sparse_component_pairwise(x4: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    x4: (T,3,3,30) real amplitude\n",
    "    Run RPCA on each (Tx,Rx) link separately:\n",
    "      M = (T,30) for each link, compute S, place back.\n",
    "    Return: S_out same shape as x4 (float32)\n",
    "    \"\"\"\n",
    "    x4 = x4.astype(np.float32, copy=False)\n",
    "    T = x4.shape[0]\n",
    "    S_out = np.empty((T, TX, RX, SC), dtype=np.float32)\n",
    "\n",
    "    for tx in range(TX):\n",
    "        for rx in range(RX):\n",
    "            M = x4[:, tx, rx, :]  # (T,30)\n",
    "            _, S = _rpca_ialm(\n",
    "                M,\n",
    "                max_iter=RPCA_MAX_ITER,\n",
    "                tol=RPCA_TOL,\n",
    "                rho=RPCA_RHO,\n",
    "                mu=RPCA_MU_INIT\n",
    "            )\n",
    "            S_out[:, tx, rx, :] = S\n",
    "\n",
    "    return S_out\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Public API (used by run.py)\n",
    "# =========================\n",
    "def load_data_y(var_path_data_y,\n",
    "                var_environment=None,\n",
    "                var_wifi_band=None,\n",
    "                var_num_users=None):\n",
    "    \"\"\"\n",
    "    Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n",
    "    \"\"\"\n",
    "    data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "    if var_environment is not None:\n",
    "        data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "    if var_wifi_band is not None:\n",
    "        data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "    if var_num_users is not None:\n",
    "        data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "    return data_pd_y\n",
    "\n",
    "\n",
    "def load_data_x(var_path_data_x, var_label_list):\n",
    "    \"\"\"\n",
    "    Load CSI amplitude (*.npy) files based on a label list.\n",
    "\n",
    "    Modes:\n",
    "      - raw:            x_out = x_raw\n",
    "      - sparse:         x_out = S\n",
    "      - raw_plus_sparse:x_out = x_raw + alpha*S\n",
    "    \"\"\"\n",
    "    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "    data_x = []\n",
    "    target_len = preset[\"data\"][\"length\"]\n",
    "\n",
    "    for var_label, var_path in zip(var_label_list, var_path_list):\n",
    "        x_raw = np.load(var_path)\n",
    "        x_raw = _ensure_shape_4d_amp(x_raw).astype(np.float32, copy=False)\n",
    "\n",
    "        _debug_print_once(var_label, x_raw)\n",
    "\n",
    "        mode = CSI_INPUT_MODE\n",
    "\n",
    "        if mode == \"raw\":\n",
    "            x_out = x_raw\n",
    "\n",
    "        else:\n",
    "            if CACHE_ENABLED:\n",
    "                os.makedirs(os.path.join(CACHE_ROOT, mode), exist_ok=True)\n",
    "                p = _cache_path(var_label, mode)\n",
    "                if os.path.exists(p):\n",
    "                    x_out = np.load(p).astype(np.float32, copy=False)\n",
    "                else:\n",
    "                    S = _make_sparse_component_pairwise(x_raw)\n",
    "                    if mode == \"sparse\":\n",
    "                        x_out = S\n",
    "                    elif mode == \"raw_plus_sparse\":\n",
    "                        x_out = x_raw + (SPARSE_ALPHA * S)\n",
    "                        if CLAMP_NONNEG:\n",
    "                            x_out = np.maximum(x_out, 0.0)\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown CSI_INPUT_MODE={mode}\")\n",
    "\n",
    "                    np.save(p, x_out.astype(np.float32))\n",
    "            else:\n",
    "                S = _make_sparse_component_pairwise(x_raw)\n",
    "                if mode == \"sparse\":\n",
    "                    x_out = S\n",
    "                elif mode == \"raw_plus_sparse\":\n",
    "                    x_out = x_raw + (SPARSE_ALPHA * S)\n",
    "                    if CLAMP_NONNEG:\n",
    "                        x_out = np.maximum(x_out, 0.0)\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown CSI_INPUT_MODE={mode}\")\n",
    "\n",
    "        # trim/pad to target_len (same behavior as your existing code expects)\n",
    "        if x_out.shape[0] > target_len:\n",
    "            x_out = x_out[-target_len:, :, :, :]\n",
    "\n",
    "        pad_len = target_len - x_out.shape[0]\n",
    "        if pad_len > 0:\n",
    "            x_out = np.pad(x_out, ((pad_len, 0), (0, 0), (0, 0), (0, 0)))\n",
    "\n",
    "        data_x.append(x_out)\n",
    "\n",
    "    return np.array(data_x)\n",
    "\n",
    "\n",
    "def encode_data_y(data_pd_y, var_task):\n",
    "    \"\"\"\n",
    "    Encode labels according to specific task.\n",
    "    \"\"\"\n",
    "    if var_task == \"identity\":\n",
    "        data_y = encode_identity(data_pd_y)\n",
    "    elif var_task == \"activity\":\n",
    "        data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "    elif var_task == \"location\":\n",
    "        data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "    elif var_task == \"count\":\n",
    "        data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "    return data_y\n",
    "\n",
    "\n",
    "def encode_identity(data_pd_y):\n",
    "    \"\"\"\n",
    "    Onehot encoding for identity labels.\n",
    "    \"\"\"\n",
    "    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "                                    \"user_3_location\", \"user_4_location\",\n",
    "                                    \"user_5_location\", \"user_6_location\"]]\n",
    "    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "    data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "    data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "    return data_identity_y.astype(\"int8\")\n",
    "\n",
    "\n",
    "def encode_activity(data_pd_y, var_encoding):\n",
    "    \"\"\"\n",
    "    Onehot encoding for activity labels.\n",
    "    \"\"\"\n",
    "    data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\",\n",
    "                                    \"user_3_activity\", \"user_4_activity\",\n",
    "                                    \"user_5_activity\", \"user_6_activity\"]]\n",
    "    data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "    return np.array([[var_encoding[v] for v in sample] for sample in data_activity_y])\n",
    "\n",
    "\n",
    "def encode_location(data_pd_y, var_encoding):\n",
    "    \"\"\"\n",
    "    Onehot encoding for location labels.\n",
    "    \"\"\"\n",
    "    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "                                    \"user_3_location\", \"user_4_location\",\n",
    "                                    \"user_5_location\", \"user_6_location\"]]\n",
    "    data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "    return np.array([[var_encoding[v] for v in sample] for sample in data_location_y])\n",
    "\n",
    "\n",
    "def encode_count(data_pd_y, var_encoding):\n",
    "    \"\"\"\n",
    "    Onehot encoding for count labels.\n",
    "    \"\"\"\n",
    "    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "                                    \"user_3_location\", \"user_4_location\",\n",
    "                                    \"user_5_location\", \"user_6_location\"]]\n",
    "    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "    data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "    data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "\n",
    "    count_data = np.sum(data_identity_onehot_y, axis=1).reshape(-1, 1)\n",
    "    encoder = OneHotEncoder(sparse=False)\n",
    "    return encoder.fit_transform(count_data).astype(\"int8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62d1271",
   "metadata": {
    "papermill": {
     "duration": 0.00708,
     "end_time": "2025-12-28T16:51:40.192423",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.185343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "last stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8fc57d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.207435Z",
     "iopub.status.busy": "2025-12-28T16:51:40.206878Z",
     "iopub.status.idle": "2025-12-28T16:51:40.215267Z",
     "shell.execute_reply": "2025-12-28T16:51:40.214695Z"
    },
    "papermill": {
     "duration": 0.017114,
     "end_time": "2025-12-28T16:51:40.216298",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.199184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          load_data.py\n",
    "# [description]   load annotation file and CSI (from .mat), and encode labels\n",
    "# \"\"\"\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import scipy.io as scio\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from numpy.fft import ifft\n",
    "\n",
    "# # =========================================================\n",
    "# #  Settings\n",
    "# # =========================================================\n",
    "# # \"raw\"     : abs(raw complex CSI)  -> float\n",
    "# # \"lowrank\" : abs(L) after RPCA     -> float\n",
    "# # \"sparse\"  : abs(S) after RPCA     -> float\n",
    "# CSI_INPUT_MODE = \"sparse\"   # raw / lowrank / sparse\n",
    "\n",
    "# # expected dimensions\n",
    "# TX = 3\n",
    "# RX = 3\n",
    "# SC = 30\n",
    "\n",
    "# # optional IFFT (frequency -> delay)\n",
    "# USE_IFFT = True\n",
    "\n",
    "# # RPCA iterations (برای شروع کم بگذار؛ اگر لازم شد بیشتر کن)\n",
    "# RPCA_MAX_ITER = 50\n",
    "\n",
    "# # lambda mode (اختیاری)\n",
    "# # \"classic\" : 1/sqrt(max(m,n))\n",
    "# # \"median\"  : 1/sqrt(max(m,n)) * median(abs(M))\n",
    "# # \"scaled\"  : 1.2/sqrt(max(m,n))\n",
    "# RPCA_LAMBDA_MODE = \"classic\"\n",
    "\n",
    "# # cache (very important for speed)\n",
    "# CACHE_ENABLED = True\n",
    "# CACHE_ROOT = \"/kaggle/working/csi_cache_mat_pipeline\"\n",
    "\n",
    "# # print once to verify input is amplitude or complex/phase\n",
    "# _DEBUG_PRINT_ONCE = True\n",
    "# # =========================================================\n",
    "\n",
    "\n",
    "# # =========================================================\n",
    "# # Minimal R_pca implementation (no external dependency)\n",
    "# # Robust PCA via Inexact Augmented Lagrange Multiplier (IALM)\n",
    "# # =========================================================\n",
    "# class R_pca:\n",
    "#     def __init__(self, D):\n",
    "#         self.D = np.asarray(D, dtype=np.float64)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _shrink(M, tau):\n",
    "#         return np.sign(M) * np.maximum(np.abs(M) - tau, 0.0)\n",
    "\n",
    "#     @staticmethod\n",
    "#     def _svt(M, tau):\n",
    "#         U, s, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "#         s = np.maximum(s - tau, 0.0)\n",
    "#         if np.all(s == 0):\n",
    "#             return np.zeros_like(M)\n",
    "#         return (U * s) @ Vt\n",
    "\n",
    "#     def _lambda(self, D):\n",
    "#         m, n = D.shape\n",
    "#         base = 1.0 / np.sqrt(max(m, n))\n",
    "#         if RPCA_LAMBDA_MODE == \"classic\":\n",
    "#             return base\n",
    "#         if RPCA_LAMBDA_MODE == \"scaled\":\n",
    "#             return 1.2 * base\n",
    "#         if RPCA_LAMBDA_MODE == \"median\":\n",
    "#             med = np.median(np.abs(D))\n",
    "#             med = float(med) if med > 1e-12 else 1e-12\n",
    "#             return base * med\n",
    "#         raise ValueError(f\"Unknown RPCA_LAMBDA_MODE={RPCA_LAMBDA_MODE}\")\n",
    "\n",
    "#     def fit(self, max_iter=200, tol=1e-6, rho=1.5, mu=None):\n",
    "#         \"\"\"\n",
    "#         Returns L, S such that D ≈ L + S\n",
    "#         \"\"\"\n",
    "#         D = self.D\n",
    "#         m, n = D.shape\n",
    "#         lam = self._lambda(D)\n",
    "\n",
    "#         # auto mu\n",
    "#         if mu is None:\n",
    "#             s0 = np.linalg.svd(D, compute_uv=False, full_matrices=False)[0] if D.size else 1.0\n",
    "#             mu = 1.25 / (s0 + 1e-12)\n",
    "\n",
    "#         L = np.zeros_like(D)\n",
    "#         S = np.zeros_like(D)\n",
    "#         Y = np.zeros_like(D)\n",
    "\n",
    "#         normD = np.linalg.norm(D, ord=\"fro\") + 1e-12\n",
    "\n",
    "#         for _ in range(max_iter):\n",
    "#             L = self._svt(D - S + (1.0 / mu) * Y, 1.0 / mu)\n",
    "#             S = self._shrink(D - L + (1.0 / mu) * Y, lam / mu)\n",
    "\n",
    "#             R = D - L - S\n",
    "#             Y = Y + mu * R\n",
    "\n",
    "#             if (np.linalg.norm(R, ord=\"fro\") / normD) < tol:\n",
    "#                 break\n",
    "\n",
    "#             mu *= rho\n",
    "\n",
    "#         return L.astype(np.float64), S.astype(np.float64)\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 1) Phase calibration (sanitize) - vectorized\n",
    "# # --------------------------------------------------\n",
    "# def phase_sanitize_matrix(X):\n",
    "#     \"\"\"\n",
    "#     X: complex matrix (N_subcarriers, T)\n",
    "#     \"\"\"\n",
    "#     phase = np.unwrap(np.angle(X), axis=0)  # (N,T)\n",
    "#     N, T = phase.shape\n",
    "#     k = np.arange(N, dtype=np.float64)[:, None]  # (N,1)\n",
    "\n",
    "#     A = np.concatenate([k, np.ones((N, 1), dtype=np.float64)], axis=1)  # (N,2)\n",
    "#     pinvA = np.linalg.pinv(A)  # (2,N)\n",
    "#     coeff = pinvA @ phase      # (2,T)\n",
    "#     a = coeff[0:1, :]\n",
    "#     b = coeff[1:2, :]\n",
    "\n",
    "#     phase_corr = phase - (k @ a + b)\n",
    "#     return np.abs(X) * np.exp(1j * phase_corr)\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 2) Preprocess CSI matrix\n",
    "# # --------------------------------------------------\n",
    "# def preprocess_csi(X):\n",
    "#     \"\"\"\n",
    "#     X : complex CSI matrix (N_subcarriers, T)\n",
    "#     \"\"\"\n",
    "#     X_corr = phase_sanitize_matrix(X).astype(np.complex128, copy=False)\n",
    "#     fro = np.linalg.norm(X_corr, \"fro\")\n",
    "#     if fro > 0:\n",
    "#         X_corr /= fro\n",
    "#     return X_corr\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 3) Optional IFFT\n",
    "# # --------------------------------------------------\n",
    "# def csi_to_cir(X):\n",
    "#     return ifft(X, axis=0)\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 4) RPCA on complex matrix (real & imag separately)\n",
    "# # --------------------------------------------------\n",
    "# def rpca_complex(X, max_iter=200):\n",
    "#     Xr = np.real(X)\n",
    "#     Xi = np.imag(X)\n",
    "\n",
    "#     rpca_r = R_pca(Xr)\n",
    "#     Lr, Sr = rpca_r.fit(max_iter=max_iter)\n",
    "\n",
    "#     rpca_i = R_pca(Xi)\n",
    "#     Li, Si = rpca_i.fit(max_iter=max_iter)\n",
    "\n",
    "#     L = Lr + 1j * Li\n",
    "#     S = Sr + 1j * Si\n",
    "#     return L, S\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # 5) Full pipeline\n",
    "# # --------------------------------------------------\n",
    "# def csi_lowrank_sparse_pipeline(X, use_ifft=True, max_iter=200):\n",
    "#     Xp = preprocess_csi(X)\n",
    "#     if use_ifft:\n",
    "#         Xp = csi_to_cir(Xp)\n",
    "#     L, S = rpca_complex(Xp, max_iter=max_iter)\n",
    "#     return L, S\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # MAT loader -> (T,3,3,30) complex\n",
    "# # --------------------------------------------------\n",
    "# def load_csi_from_mat(mat_path):\n",
    "#     m = scio.loadmat(mat_path)\n",
    "#     if \"trace\" not in m:\n",
    "#         raise KeyError(f\"'trace' not found in {mat_path}\")\n",
    "\n",
    "#     trace = m[\"trace\"]  # (T,1) object array\n",
    "#     T = trace.shape[0]\n",
    "#     out = np.empty((T, TX, RX, SC), dtype=np.complex128)\n",
    "\n",
    "#     for t in range(T):\n",
    "#         out[t] = trace[t, 0][\"csi\"][0, 0]  # (3,3,30) complex\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# def _debug_print_once(label, csi_4d):\n",
    "#     global _DEBUG_PRINT_ONCE\n",
    "#     if not _DEBUG_PRINT_ONCE:\n",
    "#         return\n",
    "#     _DEBUG_PRINT_ONCE = False\n",
    "\n",
    "#     is_cplx = np.iscomplexobj(csi_4d)\n",
    "#     print(f\"\\n[DEBUG] First MAT sample: {label}\")\n",
    "#     print(f\"[DEBUG] shape={csi_4d.shape}, dtype={csi_4d.dtype}, complex={is_cplx}\")\n",
    "\n",
    "#     x0 = csi_4d[0, 0, 0, :]\n",
    "#     if is_cplx:\n",
    "#         ang = np.angle(x0)\n",
    "#         print(f\"[DEBUG] abs range:  min={np.min(np.abs(x0)):.6f}, max={np.max(np.abs(x0)):.6f}\")\n",
    "#         print(f\"[DEBUG] phase stats: mean={np.mean(ang):.6f}, std={np.std(ang):.6f}\")\n",
    "#         print(\"[DEBUG] ==> Input is COMPLEX (phase exists).\")\n",
    "#     else:\n",
    "#         print(f\"[DEBUG] value range: min={np.min(x0):.6f}, max={np.max(x0):.6f}\")\n",
    "#         print(\"[DEBUG] ==> Input is REAL (likely amplitude-only).\")\n",
    "\n",
    "\n",
    "# def _cache_path(label, mode):\n",
    "#     return os.path.join(CACHE_ROOT, mode, f\"{label}.npy\")\n",
    "\n",
    "\n",
    "# def _apply_pipeline_pairwise_9links(csi_4d_complex, label):\n",
    "#     \"\"\"\n",
    "#     csi_4d_complex: (T,3,3,30) complex\n",
    "#     Run pipeline on each link separately: (30,T) -> RPCA -> abs -> back to (T,3,3,30) float32\n",
    "#     \"\"\"\n",
    "#     _debug_print_once(label, csi_4d_complex)\n",
    "\n",
    "#     if CSI_INPUT_MODE == \"raw\":\n",
    "#         return np.abs(csi_4d_complex).astype(np.float32)\n",
    "\n",
    "#     mode = CSI_INPUT_MODE  # lowrank / sparse\n",
    "\n",
    "#     if CACHE_ENABLED:\n",
    "#         os.makedirs(os.path.join(CACHE_ROOT, mode), exist_ok=True)\n",
    "#         p = _cache_path(label, mode)\n",
    "#         if os.path.exists(p):\n",
    "#             return np.load(p).astype(np.float32, copy=False)\n",
    "\n",
    "#     T = csi_4d_complex.shape[0]\n",
    "#     out = np.empty((T, TX, RX, SC), dtype=np.float32)\n",
    "\n",
    "#     for tx in range(TX):\n",
    "#         for rx in range(RX):\n",
    "#             X = csi_4d_complex[:, tx, rx, :].T  # (30,T) complex\n",
    "#             L, S = csi_lowrank_sparse_pipeline(X, use_ifft=USE_IFFT, max_iter=RPCA_MAX_ITER)\n",
    "#             Y = L if mode == \"lowrank\" else S\n",
    "#             out[:, tx, rx, :] = np.abs(Y.T).astype(np.float32)\n",
    "\n",
    "#     if CACHE_ENABLED:\n",
    "#         np.save(p, out)\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# # --------------------------------------------------\n",
    "# # Existing label loading/encoding\n",
    "# # --------------------------------------------------\n",
    "# def load_data_y(var_path_data_y,\n",
    "#                 var_environment=None,\n",
    "#                 var_wifi_band=None,\n",
    "#                 var_num_users=None):\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list):\n",
    "#     \"\"\"\n",
    "#     var_path_data_x should point to MAT directory, e.g. /kaggle/input/wimans/wifi_csi/mat\n",
    "#     Each label corresponds to <label>.mat\n",
    "#     \"\"\"\n",
    "#     data_x = []\n",
    "#     target_len = preset[\"data\"][\"length\"]\n",
    "\n",
    "#     for label in var_label_list:\n",
    "#         mat_path = os.path.join(var_path_data_x, label + \".mat\")\n",
    "#         if not os.path.exists(mat_path):\n",
    "#             raise FileNotFoundError(f\"MAT file not found: {mat_path}\")\n",
    "\n",
    "#         csi_complex = load_csi_from_mat(mat_path)  # (T,3,3,30) complex\n",
    "\n",
    "#         # if longer than target_len, keep last target_len frames\n",
    "#         if csi_complex.shape[0] > target_len:\n",
    "#             csi_complex = csi_complex[-target_len:, :, :, :]\n",
    "\n",
    "#         csi_feat = _apply_pipeline_pairwise_9links(csi_complex, label)\n",
    "\n",
    "#         # pad if shorter\n",
    "#         pad_len = target_len - csi_feat.shape[0]\n",
    "#         if pad_len > 0:\n",
    "#             csi_feat = np.pad(csi_feat, ((pad_len, 0), (0, 0), (0, 0), (0, 0)))\n",
    "\n",
    "#         data_x.append(csi_feat)\n",
    "\n",
    "#     return np.array(data_x)\n",
    "\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     if var_task == \"identity\":\n",
    "#         data_y = encode_identity(data_pd_y)\n",
    "#     elif var_task == \"activity\":\n",
    "#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     elif var_task == \"location\":\n",
    "#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     elif var_task == \"count\":\n",
    "#         data_y = encode_count(data_pd_y)\n",
    "#     return data_y\n",
    "\n",
    "\n",
    "# def encode_identity(data_pd_y):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     return data_identity_y.astype(\"int8\")\n",
    "\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\",\n",
    "#                                     \"user_3_activity\", \"user_4_activity\",\n",
    "#                                     \"user_5_activity\", \"user_6_activity\"]]\n",
    "#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     return np.array([[var_encoding[v] for v in sample] for sample in data_activity_y])\n",
    "\n",
    "\n",
    "# def encode_location(data_pd_y, var_encoding):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     return np.array([[var_encoding[v] for v in sample] for sample in data_location_y])\n",
    "\n",
    "\n",
    "# def encode_count(data_pd_y):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "\n",
    "#     count_data = np.sum(data_identity_onehot_y, axis=1).reshape(-1, 1)\n",
    "#     encoder = OneHotEncoder(sparse=False)\n",
    "#     return encoder.fit_transform(count_data).astype(\"int8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba059be2",
   "metadata": {
    "papermill": {
     "duration": 0.006616,
     "end_time": "2025-12-28T16:51:40.229822",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.223206",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "rpca 30 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36bfea0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.244856Z",
     "iopub.status.busy": "2025-12-28T16:51:40.244629Z",
     "iopub.status.idle": "2025-12-28T16:51:40.251175Z",
     "shell.execute_reply": "2025-12-28T16:51:40.250429Z"
    },
    "papermill": {
     "duration": 0.015686,
     "end_time": "2025-12-28T16:51:40.252247",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.236561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          load_data.py\n",
    "# [description]   load annotation file and CSI amplitude, and encode labels\n",
    "# \"\"\"\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # =========================================================\n",
    "# # انتخاب نوع دیتای ورودی مدل:\n",
    "# # \"raw\"     : amp خام\n",
    "# # \"lowrank\" : خروجی Low-rank (L) از RPCA\n",
    "# # \"sparse\"  : خروجی Sparse (S) از RPCA\n",
    "# CSI_INPUT_MODE = \"lowrank\"   # <-- raw / lowrank / sparse\n",
    "\n",
    "# # ابعاد مورد انتظار CSI\n",
    "# TX = 3\n",
    "# RX = 3\n",
    "# SC = 30\n",
    "\n",
    "# # RPCA (IALM) تنظیمات سریع‌تر\n",
    "# RPCA_MAX_ITER = 60\n",
    "# RPCA_TOL      = 1e-5\n",
    "# RPCA_RHO      = 1.5\n",
    "# RPCA_MU_INIT  = None\n",
    "\n",
    "# # ✅ انتخاب لامبدا:\n",
    "# # \"median\" : lam = 1/sqrt(max(m,n)) * median(abs(M))\n",
    "# # \"scaled\" : lam = 1.2/sqrt(max(m,n))\n",
    "# RPCA_LAMBDA_MODE = \"median\"  # <-- \"median\" یا \"scaled\"\n",
    "\n",
    "# # Cache (خیلی مهم برای سرعت)\n",
    "# CACHE_ENABLED = True\n",
    "# CACHE_ROOT    = \"/kaggle/working/csi_cache_pairwise\"\n",
    "# # =========================================================\n",
    "\n",
    "\n",
    "# def _soft_threshold(X, tau):\n",
    "#     return np.sign(X) * np.maximum(np.abs(X) - tau, 0.0)\n",
    "\n",
    "# def _svt(X, tau):\n",
    "#     # Singular Value Thresholding\n",
    "#     U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "#     s = np.maximum(s - tau, 0.0)\n",
    "#     if np.all(s == 0):\n",
    "#         return np.zeros_like(X)\n",
    "#     return (U * s) @ Vt\n",
    "\n",
    "# def _compute_lambda(M, mode):\n",
    "#     \"\"\"\n",
    "#     mode:\n",
    "#       - 'median': 1/sqrt(max(m,n)) * median(abs(M))\n",
    "#       - 'scaled': 1.2/sqrt(max(m,n))\n",
    "#     \"\"\"\n",
    "#     m, n = M.shape\n",
    "#     base = 1.0 / np.sqrt(max(m, n))\n",
    "\n",
    "#     if mode == \"median\":\n",
    "#         med = np.median(np.abs(M))\n",
    "#         # اگر med خیلی کوچک بود برای پایداری:\n",
    "#         med = float(med) if med > 1e-12 else 1e-12\n",
    "#         return base * med\n",
    "\n",
    "#     if mode == \"scaled\":\n",
    "#         return 1.2 * base\n",
    "\n",
    "#     raise ValueError(f\"Unknown RPCA_LAMBDA_MODE: {mode}. Use 'median' or 'scaled'.\")\n",
    "\n",
    "\n",
    "# def _rpca_ialm(M, mu=None, rho=1.5, max_iter=60, tol=1e-5):\n",
    "#     \"\"\"\n",
    "#     Robust PCA via Inexact Augmented Lagrange Multiplier (IALM)\n",
    "#     Decompose: M = L + S\n",
    "#     M shape: (T, SC) = (3000, 30)\n",
    "#     \"\"\"\n",
    "#     M = M.astype(np.float64, copy=False)\n",
    "#     m, n = M.shape\n",
    "\n",
    "#     # ✅ lambda طبق انتخاب کاربر\n",
    "#     lam = _compute_lambda(M, RPCA_LAMBDA_MODE)\n",
    "\n",
    "#     # mu خودکار یا دستی\n",
    "#     if mu is None:\n",
    "#         s0 = np.linalg.svd(M, compute_uv=False, full_matrices=False)[0] if M.size else 1.0\n",
    "#         mu = 1.25 / (s0 + 1e-12)\n",
    "\n",
    "#     L = np.zeros_like(M)\n",
    "#     S = np.zeros_like(M)\n",
    "#     Y = np.zeros_like(M)\n",
    "\n",
    "#     normM = np.linalg.norm(M, ord=\"fro\") + 1e-12\n",
    "\n",
    "#     for _ in range(max_iter):\n",
    "#         L = _svt(M - S + (1.0 / mu) * Y, 1.0 / mu)\n",
    "#         S = _soft_threshold(M - L + (1.0 / mu) * Y, lam / mu)\n",
    "\n",
    "#         R = M - L - S\n",
    "#         Y = Y + mu * R\n",
    "\n",
    "#         if (np.linalg.norm(R, ord=\"fro\") / normM) < tol:\n",
    "#             break\n",
    "\n",
    "#         mu *= rho\n",
    "\n",
    "#     return L.astype(np.float32), S.astype(np.float32)\n",
    "\n",
    "\n",
    "# def _ensure_shape_4d(data_csi):\n",
    "#     \"\"\"\n",
    "#     Ensure CSI shape is (T, TX, RX, SC).\n",
    "#     If input is (T, 270) we reshape to (T,3,3,30).\n",
    "#     \"\"\"\n",
    "#     if data_csi.ndim == 4:\n",
    "#         return data_csi\n",
    "\n",
    "#     if data_csi.ndim == 2 and data_csi.shape[1] == TX * RX * SC:\n",
    "#         T = data_csi.shape[0]\n",
    "#         return data_csi.reshape(T, TX, RX, SC)\n",
    "\n",
    "#     raise ValueError(\n",
    "#         f\"Unexpected CSI shape {data_csi.shape}. Expected (T,{TX},{RX},{SC}) or (T,{TX*RX*SC}).\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# def _cache_path(label, mode):\n",
    "#     return os.path.join(CACHE_ROOT, mode, f\"{label}.npy\")\n",
    "\n",
    "\n",
    "# def _rpca_pairwise_9links(data_csi_4d):\n",
    "#     \"\"\"\n",
    "#     data_csi_4d: (T, TX, RX, SC)\n",
    "#     Run RPCA on each (tx,rx) separately on matrix (T, SC) and reassemble.\n",
    "#     Output shape stays (T, TX, RX, SC).\n",
    "#     \"\"\"\n",
    "#     T = data_csi_4d.shape[0]\n",
    "#     out = np.empty((T, TX, RX, SC), dtype=np.float32)\n",
    "\n",
    "#     for tx in range(TX):\n",
    "#         for rx in range(RX):\n",
    "#             M = data_csi_4d[:, tx, rx, :]  # (T,30)\n",
    "#             L, S = _rpca_ialm(\n",
    "#                 M,\n",
    "#                 mu=RPCA_MU_INIT,\n",
    "#                 rho=RPCA_RHO,\n",
    "#                 max_iter=RPCA_MAX_ITER,\n",
    "#                 tol=RPCA_TOL\n",
    "#             )\n",
    "#             out[:, tx, rx, :] = L if CSI_INPUT_MODE == \"lowrank\" else S\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# def _apply_mode_with_cache(data_csi, label):\n",
    "#     \"\"\"\n",
    "#     Apply raw/lowrank/sparse. For lowrank/sparse use pairwise RPCA (9 links of 3000x30).\n",
    "#     Keeps the original 4D shape (T,3,3,30).\n",
    "#     \"\"\"\n",
    "#     data_csi = _ensure_shape_4d(np.asarray(data_csi, dtype=np.float32))\n",
    "\n",
    "#     if CSI_INPUT_MODE == \"raw\":\n",
    "#         return data_csi.astype(np.float32, copy=False)\n",
    "\n",
    "#     mode = CSI_INPUT_MODE\n",
    "#     if CACHE_ENABLED:\n",
    "#         os.makedirs(os.path.join(CACHE_ROOT, mode), exist_ok=True)\n",
    "#         p = _cache_path(label, mode)\n",
    "#         if os.path.exists(p):\n",
    "#             cached = np.load(p)\n",
    "#             return _ensure_shape_4d(cached).astype(np.float32, copy=False)\n",
    "\n",
    "#     out = _rpca_pairwise_9links(data_csi)\n",
    "\n",
    "#     if CACHE_ENABLED:\n",
    "#         np.save(p, out.astype(np.float32))\n",
    "\n",
    "#     return out.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "# def load_data_y(var_path_data_y,\n",
    "#                 var_environment=None,\n",
    "#                 var_wifi_band=None,\n",
    "#                 var_num_users=None):\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list):\n",
    "#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "#     data_x = []\n",
    "#     for var_label, var_path in zip(var_label_list, var_path_list):\n",
    "#         data_csi = np.load(var_path)\n",
    "\n",
    "#         # ✅ RPCA روی 9 لینک جدا (3000x30) و بعد اتصال\n",
    "#         data_csi = _apply_mode_with_cache(data_csi, var_label)\n",
    "\n",
    "#         var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n",
    "#         data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n",
    "#         data_x.append(data_csi_pad)\n",
    "\n",
    "#     return np.array(data_x)\n",
    "\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     if var_task == \"identity\":\n",
    "#         data_y = encode_identity(data_pd_y)\n",
    "#     elif var_task == \"activity\":\n",
    "#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     elif var_task == \"location\":\n",
    "#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     elif var_task == \"count\":\n",
    "#         data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     return data_y\n",
    "\n",
    "\n",
    "# def encode_identity(data_pd_y):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     return data_identity_y.astype(\"int8\")\n",
    "\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\",\n",
    "#                                     \"user_3_activity\", \"user_4_activity\",\n",
    "#                                     \"user_5_activity\", \"user_6_activity\"]]\n",
    "#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     return np.array([[var_encoding[v] for v in sample] for sample in data_activity_y])\n",
    "\n",
    "\n",
    "# def encode_location(data_pd_y, var_encoding):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     return np.array([[var_encoding[v] for v in sample] for sample in data_location_y])\n",
    "\n",
    "\n",
    "# def encode_count(data_pd_y, var_encoding):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "\n",
    "#     count_data = np.sum(data_identity_onehot_y, axis=1).reshape(-1, 1)\n",
    "#     encoder = OneHotEncoder(sparse=False)\n",
    "#     return encoder.fit_transform(count_data).astype(\"int8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4907d40e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.267165Z",
     "iopub.status.busy": "2025-12-28T16:51:40.266973Z",
     "iopub.status.idle": "2025-12-28T16:51:40.273498Z",
     "shell.execute_reply": "2025-12-28T16:51:40.272989Z"
    },
    "papermill": {
     "duration": 0.015234,
     "end_time": "2025-12-28T16:51:40.274475",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.259241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          load_data.py\n",
    "# [description]   load annotation file and CSI amplitude, and encode labels\n",
    "# \"\"\"\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # =========================================================\n",
    "# # انتخاب نوع دیتای ورودی مدل:\n",
    "# # \"raw\"     : amp خام\n",
    "# # \"lowrank\" : خروجی Low-rank (L) از RPCA\n",
    "# # \"sparse\"  : خروجی Sparse (S) از RPCA\n",
    "# CSI_INPUT_MODE = \"sparse\"   # <-- raw / lowrank / sparse\n",
    "\n",
    "# # ابعاد مورد انتظار CSI\n",
    "# TX = 3\n",
    "# RX = 3\n",
    "# SC = 30\n",
    "\n",
    "# # RPCA (IALM) تنظیمات سریع‌تر\n",
    "# RPCA_MAX_ITER = 60\n",
    "# RPCA_TOL      = 1e-5\n",
    "# RPCA_RHO      = 1.5\n",
    "# RPCA_MU_INIT  = None\n",
    "# RPCA_LAMBDA   = None     # None -> 1/sqrt(max(m,n))\n",
    "\n",
    "# # Cache (خیلی مهم برای سرعت)\n",
    "# CACHE_ENABLED = True\n",
    "# CACHE_ROOT    = \"/kaggle/working/csi_cache_pairwise\"  # خروجی‌ها اینجا ذخیره میشن\n",
    "# # =========================================================\n",
    "\n",
    "\n",
    "# def _soft_threshold(X, tau):\n",
    "#     return np.sign(X) * np.maximum(np.abs(X) - tau, 0.0)\n",
    "\n",
    "# def _svt(X, tau):\n",
    "#     # Singular Value Thresholding\n",
    "#     U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "#     s = np.maximum(s - tau, 0.0)\n",
    "#     if np.all(s == 0):\n",
    "#         return np.zeros_like(X)\n",
    "#     return (U * s) @ Vt\n",
    "\n",
    "# def _rpca_ialm(M, lam=None, mu=None, rho=1.5, max_iter=60, tol=1e-5):\n",
    "#     \"\"\"\n",
    "#     Robust PCA via Inexact Augmented Lagrange Multiplier (IALM)\n",
    "#     Decompose: M = L + S\n",
    "#     M shape: (T, SC) = (3000, 30)\n",
    "#     \"\"\"\n",
    "#     M = M.astype(np.float64, copy=False)\n",
    "#     m, n = M.shape\n",
    "\n",
    "#     if lam is None:\n",
    "#         lam = 1.0 / np.sqrt(max(m, n))\n",
    "\n",
    "#     if mu is None:\n",
    "#         # top singular value as spectral norm approximation\n",
    "#         s0 = np.linalg.svd(M, compute_uv=False, full_matrices=False)[0] if M.size else 1.0\n",
    "#         mu = 1.25 / (s0 + 1e-12)\n",
    "\n",
    "#     L = np.zeros_like(M)\n",
    "#     S = np.zeros_like(M)\n",
    "#     Y = np.zeros_like(M)\n",
    "\n",
    "#     normM = np.linalg.norm(M, ord=\"fro\") + 1e-12\n",
    "\n",
    "#     for _ in range(max_iter):\n",
    "#         L = _svt(M - S + (1.0 / mu) * Y, 1.0 / mu)\n",
    "#         S = _soft_threshold(M - L + (1.0 / mu) * Y, lam / mu)\n",
    "\n",
    "#         R = M - L - S\n",
    "#         Y = Y + mu * R\n",
    "\n",
    "#         if (np.linalg.norm(R, ord=\"fro\") / normM) < tol:\n",
    "#             break\n",
    "\n",
    "#         mu *= rho\n",
    "\n",
    "#     return L.astype(np.float32), S.astype(np.float32)\n",
    "\n",
    "\n",
    "# def _ensure_shape_4d(data_csi):\n",
    "#     \"\"\"\n",
    "#     Ensure CSI shape is (T, TX, RX, SC).\n",
    "#     If input is (T, 270) we reshape to (T,3,3,30).\n",
    "#     \"\"\"\n",
    "#     if data_csi.ndim == 4:\n",
    "#         return data_csi\n",
    "\n",
    "#     if data_csi.ndim == 2 and data_csi.shape[1] == TX * RX * SC:\n",
    "#         T = data_csi.shape[0]\n",
    "#         return data_csi.reshape(T, TX, RX, SC)\n",
    "\n",
    "#     raise ValueError(\n",
    "#         f\"Unexpected CSI shape {data_csi.shape}. Expected (T,{TX},{RX},{SC}) or (T,{TX*RX*SC}).\"\n",
    "#     )\n",
    "\n",
    "\n",
    "# def _cache_path(label, mode):\n",
    "#     # mode: \"lowrank\" or \"sparse\"\n",
    "#     return os.path.join(CACHE_ROOT, mode, f\"{label}.npy\")\n",
    "\n",
    "\n",
    "# def _rpca_pairwise_9links(data_csi_4d):\n",
    "#     \"\"\"\n",
    "#     data_csi_4d: (T, TX, RX, SC)\n",
    "#     Run RPCA on each (tx,rx) separately on matrix (T, SC) and reassemble.\n",
    "#     Output shape stays (T, TX, RX, SC).\n",
    "#     \"\"\"\n",
    "#     T = data_csi_4d.shape[0]\n",
    "#     out = np.empty((T, TX, RX, SC), dtype=np.float32)\n",
    "\n",
    "#     # 9 times RPCA: for each tx-rx link\n",
    "#     for tx in range(TX):\n",
    "#         for rx in range(RX):\n",
    "#             M = data_csi_4d[:, tx, rx, :]  # (T, SC) => (3000,30)\n",
    "#             L, S = _rpca_ialm(\n",
    "#                 M,\n",
    "#                 lam=RPCA_LAMBDA,\n",
    "#                 mu=RPCA_MU_INIT,\n",
    "#                 rho=RPCA_RHO,\n",
    "#                 max_iter=RPCA_MAX_ITER,\n",
    "#                 tol=RPCA_TOL\n",
    "#             )\n",
    "#             if CSI_INPUT_MODE == \"lowrank\":\n",
    "#                 out[:, tx, rx, :] = L\n",
    "#             else:  # \"sparse\"\n",
    "#                 out[:, tx, rx, :] = S\n",
    "\n",
    "#     return out\n",
    "\n",
    "\n",
    "# def _apply_mode_with_cache(data_csi, label):\n",
    "#     \"\"\"\n",
    "#     Apply raw/lowrank/sparse. For lowrank/sparse use pairwise RPCA (9 links of 3000x30).\n",
    "#     Keeps the original 4D shape (T,3,3,30).\n",
    "#     \"\"\"\n",
    "#     data_csi = _ensure_shape_4d(np.asarray(data_csi, dtype=np.float32))\n",
    "\n",
    "#     if CSI_INPUT_MODE == \"raw\":\n",
    "#         return data_csi.astype(np.float32, copy=False)\n",
    "\n",
    "#     mode = CSI_INPUT_MODE\n",
    "#     if CACHE_ENABLED:\n",
    "#         os.makedirs(os.path.join(CACHE_ROOT, mode), exist_ok=True)\n",
    "#         p = _cache_path(label, mode)\n",
    "#         if os.path.exists(p):\n",
    "#             cached = np.load(p)\n",
    "#             return _ensure_shape_4d(cached).astype(np.float32, copy=False)\n",
    "\n",
    "#     out = _rpca_pairwise_9links(data_csi)\n",
    "\n",
    "#     if CACHE_ENABLED:\n",
    "#         np.save(p, out.astype(np.float32))\n",
    "\n",
    "#     return out.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "# def load_data_y(var_path_data_y,\n",
    "#                 var_environment=None, \n",
    "#                 var_wifi_band=None, \n",
    "#                 var_num_users=None):\n",
    "#     \"\"\"\n",
    "#     Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n",
    "#     \"\"\"\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list):\n",
    "#     \"\"\"\n",
    "#     Load CSI amplitude (*.npy) files based on a label list.\n",
    "#     \"\"\"\n",
    "#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "#     data_x = []\n",
    "#     for var_label, var_path in zip(var_label_list, var_path_list):\n",
    "#         data_csi = np.load(var_path)\n",
    "\n",
    "#         # ✅ NEW: RPCA روی 9 لینک جداگانه (3000x30) و بعد چسباندن\n",
    "#         data_csi = _apply_mode_with_cache(data_csi, var_label)\n",
    "\n",
    "#         var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n",
    "#         data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n",
    "#         data_x.append(data_csi_pad)\n",
    "\n",
    "#     return np.array(data_x)\n",
    "\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     \"\"\"\n",
    "#     Encode labels according to specific task.\n",
    "#     \"\"\"\n",
    "#     if var_task == \"identity\":\n",
    "#         data_y = encode_identity(data_pd_y)\n",
    "#     elif var_task == \"activity\":\n",
    "#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     elif var_task == \"location\":\n",
    "#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     elif var_task == \"count\":\n",
    "#         data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     return data_y\n",
    "\n",
    "\n",
    "# def encode_identity(data_pd_y):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     return data_identity_onehot_y\n",
    "\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for activity labels.\n",
    "#     \"\"\"\n",
    "#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n",
    "#                                     \"user_3_activity\", \"user_4_activity\", \n",
    "#                                     \"user_5_activity\", \"user_6_activity\"]]\n",
    "#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n",
    "#     return data_activity_onehot_y\n",
    "\n",
    "\n",
    "# def encode_location(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for location labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n",
    "#     return data_location_onehot_y\n",
    "\n",
    "\n",
    "# def encode_count(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     count_data = np.sum(data_identity_onehot_y, axis=1)\n",
    "#     count_data = count_data.reshape(-1, 1)\n",
    "#     encoder = OneHotEncoder(sparse=False)\n",
    "#     count_data_onehot = encoder.fit_transform(count_data).astype(\"int8\")\n",
    "#     return count_data_onehot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b1d15",
   "metadata": {
    "papermill": {
     "duration": 0.006744,
     "end_time": "2025-12-28T16:51:40.288310",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.281566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "rpca\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8ab910",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.304588Z",
     "iopub.status.busy": "2025-12-28T16:51:40.304124Z",
     "iopub.status.idle": "2025-12-28T16:51:40.309899Z",
     "shell.execute_reply": "2025-12-28T16:51:40.309413Z"
    },
    "papermill": {
     "duration": 0.014462,
     "end_time": "2025-12-28T16:51:40.310890",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.296428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          load_data.py\n",
    "# [description]   load annotation file and CSI amplitude, and encode labels\n",
    "# \"\"\"\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # =========================================================\n",
    "# # انتخاب ورودی مدل:\n",
    "# # \"raw\"     : همون amp خام\n",
    "# # \"lowrank\" : مؤلفه Low-rank از RPCA (L)\n",
    "# # \"sparse\"  : مؤلفه Sparse از RPCA (S)\n",
    "# CSI_INPUT_MODE = \"lowrank\"   # <-- raw / lowrank / sparse\n",
    "\n",
    "# # RPCA (IALM) تنظیمات سریع‌تر\n",
    "# RPCA_MAX_ITER = 80\n",
    "# RPCA_TOL      = 1e-5\n",
    "# RPCA_RHO      = 1.5\n",
    "# RPCA_MU_INIT  = None\n",
    "# RPCA_LAMBDA   = None     # None -> 1/sqrt(max(m,n))\n",
    "\n",
    "# # Cache (خیلی مهم برای سرعت)\n",
    "# CACHE_ENABLED = True\n",
    "# CACHE_ROOT    = \"/kaggle/working/csi_cache\"  # خروجی‌ها اینجا ذخیره میشن\n",
    "# # =========================================================\n",
    "\n",
    "\n",
    "# def _soft_threshold(X, tau):\n",
    "#     return np.sign(X) * np.maximum(np.abs(X) - tau, 0.0)\n",
    "\n",
    "# def _svt(X, tau):\n",
    "#     U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "#     s = np.maximum(s - tau, 0.0)\n",
    "#     if np.all(s == 0):\n",
    "#         return np.zeros_like(X)\n",
    "#     return (U * s) @ Vt\n",
    "\n",
    "# def _rpca_ialm(M, lam=None, mu=None, rho=1.5, max_iter=80, tol=1e-5):\n",
    "#     M = M.astype(np.float64, copy=False)\n",
    "#     m, n = M.shape\n",
    "\n",
    "#     if lam is None:\n",
    "#         lam = 1.0 / np.sqrt(max(m, n))\n",
    "\n",
    "#     if mu is None:\n",
    "#         s0 = np.linalg.svd(M, compute_uv=False, full_matrices=False)[0] if M.size else 1.0\n",
    "#         mu = 1.25 / (s0 + 1e-12)\n",
    "\n",
    "#     L = np.zeros_like(M)\n",
    "#     S = np.zeros_like(M)\n",
    "#     Y = np.zeros_like(M)\n",
    "\n",
    "#     normM = np.linalg.norm(M, ord=\"fro\") + 1e-12\n",
    "\n",
    "#     for _ in range(max_iter):\n",
    "#         L = _svt(M - S + (1.0 / mu) * Y, 1.0 / mu)\n",
    "#         S = _soft_threshold(M - L + (1.0 / mu) * Y, lam / mu)\n",
    "\n",
    "#         R = M - L - S\n",
    "#         Y = Y + mu * R\n",
    "\n",
    "#         if (np.linalg.norm(R, ord=\"fro\") / normM) < tol:\n",
    "#             break\n",
    "#         mu *= rho\n",
    "\n",
    "#     return L.astype(np.float32), S.astype(np.float32)\n",
    "\n",
    "\n",
    "# def _rpca_keep_shape(X):\n",
    "#     \"\"\"RPCA روی (T,F) و بازگرداندن دقیقاً به shape اولیه\"\"\"\n",
    "#     X = np.asarray(X, dtype=np.float32)\n",
    "#     if X.ndim == 1:\n",
    "#         M = X[:, None]\n",
    "#         L, S = _rpca_ialm(M, RPCA_LAMBDA, RPCA_MU_INIT, RPCA_RHO, RPCA_MAX_ITER, RPCA_TOL)\n",
    "#         return L[:, 0], S[:, 0]\n",
    "\n",
    "#     T = X.shape[0]\n",
    "#     F = int(np.prod(X.shape[1:]))\n",
    "#     M = X.reshape(T, F)\n",
    "\n",
    "#     L, S = _rpca_ialm(M, RPCA_LAMBDA, RPCA_MU_INIT, RPCA_RHO, RPCA_MAX_ITER, RPCA_TOL)\n",
    "#     return L.reshape(X.shape), S.reshape(X.shape)\n",
    "\n",
    "\n",
    "# def _cache_path(label, mode):\n",
    "#     # mode: \"lowrank\" or \"sparse\"\n",
    "#     # فایل خروجی: /kaggle/working/csi_cache/lowrank/<label>.npy\n",
    "#     return os.path.join(CACHE_ROOT, mode, f\"{label}.npy\")\n",
    "\n",
    "\n",
    "# def _apply_mode_with_cache(data_csi, label):\n",
    "#     if CSI_INPUT_MODE == \"raw\":\n",
    "#         return data_csi.astype(np.float32, copy=False)\n",
    "\n",
    "#     # lowrank یا sparse\n",
    "#     mode = CSI_INPUT_MODE\n",
    "#     if CACHE_ENABLED:\n",
    "#         os.makedirs(os.path.join(CACHE_ROOT, mode), exist_ok=True)\n",
    "#         p = _cache_path(label, mode)\n",
    "#         if os.path.exists(p):\n",
    "#             return np.load(p).astype(np.float32, copy=False)\n",
    "\n",
    "#     L, S = _rpca_keep_shape(data_csi)\n",
    "#     out = L if mode == \"lowrank\" else S\n",
    "\n",
    "#     if CACHE_ENABLED:\n",
    "#         np.save(p, out.astype(np.float32))\n",
    "\n",
    "#     return out.astype(np.float32, copy=False)\n",
    "\n",
    "\n",
    "# def load_data_y(var_path_data_y,\n",
    "#                 var_environment=None, \n",
    "#                 var_wifi_band=None, \n",
    "#                 var_num_users=None):\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list):\n",
    "#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "#     data_x = []\n",
    "#     for var_label, var_path in zip(var_label_list, var_path_list):\n",
    "#         data_csi = np.load(var_path)\n",
    "\n",
    "#         # ✅ RPCA lowrank/sparse بدون تغییر shape + با cache\n",
    "#         data_csi = _apply_mode_with_cache(data_csi, var_label)\n",
    "\n",
    "#         var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n",
    "#         data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n",
    "#         data_x.append(data_csi_pad)\n",
    "\n",
    "#     return np.array(data_x)\n",
    "\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     if var_task == \"identity\":\n",
    "#         data_y = encode_identity(data_pd_y)\n",
    "#     elif var_task == \"activity\":\n",
    "#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     elif var_task == \"location\":\n",
    "#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     elif var_task == \"count\":\n",
    "#         data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     return data_y\n",
    "\n",
    "\n",
    "# def encode_identity(data_pd_y):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     return data_identity_y.astype(\"int8\")\n",
    "\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\",\n",
    "#                                     \"user_3_activity\", \"user_4_activity\",\n",
    "#                                     \"user_5_activity\", \"user_6_activity\"]]\n",
    "#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     return np.array([[var_encoding[v] for v in sample] for sample in data_activity_y])\n",
    "\n",
    "\n",
    "# def encode_location(data_pd_y, var_encoding):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     return np.array([[var_encoding[v] for v in sample] for sample in data_location_y])\n",
    "\n",
    "\n",
    "# def encode_count(data_pd_y, var_encoding):\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\",\n",
    "#                                     \"user_3_location\", \"user_4_location\",\n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "\n",
    "#     count_data = np.sum(data_identity_onehot_y, axis=1).reshape(-1, 1)\n",
    "#     encoder = OneHotEncoder(sparse=False)\n",
    "#     return encoder.fit_transform(count_data).astype(\"int8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4fdf54",
   "metadata": {
    "papermill": {
     "duration": 0.006845,
     "end_time": "2025-12-28T16:51:40.324844",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.317999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "svd\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c023b07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.339924Z",
     "iopub.status.busy": "2025-12-28T16:51:40.339680Z",
     "iopub.status.idle": "2025-12-28T16:51:40.347226Z",
     "shell.execute_reply": "2025-12-28T16:51:40.346544Z"
    },
    "papermill": {
     "duration": 0.016465,
     "end_time": "2025-12-28T16:51:40.348297",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.331832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          load_data.py\n",
    "# [description]   load annotation file and CSI amplitude, and encode labels\n",
    "# \"\"\"\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # Note: All necessary libraries (os, numpy, pandas, etc.) are imported in Cell 1.\n",
    "# # from preset import preset   --> preset is already defined in Cell 2.\n",
    "\n",
    "# # =========================================================\n",
    "# # 🔧 NEW: Choose CSI representation mode here (ONLY EDIT THIS)\n",
    "# # ---------------------------------------------------------\n",
    "# # \"raw\"     : use original CSI amplitude as-is\n",
    "# # \"lowrank\" : use low-rank approximation (SVD)\n",
    "# # \"sparse\"  : keep only large-magnitude entries (dense array with many zeros)\n",
    "# CSI_INPUT_MODE = \"sparse\"     # <-- set to: \"raw\" / \"lowrank\" / \"sparse\"\n",
    "\n",
    "# # Low-rank settings\n",
    "# LOW_RANK_ENERGY = 0.95     # keep enough singular values to preserve this energy\n",
    "# LOW_RANK_RANK   = None     # if set to an int (e.g., 10), it overrides ENERGY\n",
    "\n",
    "# # Sparse settings\n",
    "# SPARSE_KEEP_RATIO = 0.10   # keep top 10% magnitudes (globally per sample)\n",
    "# SPARSE_MIN_ABS    = None   # if set (e.g., 0.5), keeps |x|>=threshold instead of keep_ratio\n",
    "# # =========================================================\n",
    "\n",
    "\n",
    "# def _low_rank_approx_keep_shape(X, rank=None, energy=0.95):\n",
    "#     \"\"\"\n",
    "#     Low-rank approximation using SVD while preserving the original shape.\n",
    "#     Works for 1D/2D/ND by flattening all non-time dims into features.\n",
    "#     Assumes first axis is time.\n",
    "#     \"\"\"\n",
    "#     X = np.asarray(X, dtype=np.float32)\n",
    "\n",
    "#     if X.ndim == 1:\n",
    "#         M = X[:, None]  # (T,1)\n",
    "#         U, S, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "#         if rank is None:\n",
    "#             s2 = S**2\n",
    "#             cum = np.cumsum(s2) / (np.sum(s2) + 1e-12)\n",
    "#             rank = int(np.searchsorted(cum, energy) + 1)\n",
    "#         rank = max(1, min(rank, S.shape[0]))\n",
    "#         M_lr = (U[:, :rank] * S[:rank]) @ Vt[:rank, :]\n",
    "#         return M_lr[:, 0].astype(np.float32)\n",
    "\n",
    "#     # ND: reshape to (T, F)\n",
    "#     T = X.shape[0]\n",
    "#     F = int(np.prod(X.shape[1:]))\n",
    "#     M = X.reshape(T, F)\n",
    "\n",
    "#     U, S, Vt = np.linalg.svd(M, full_matrices=False)\n",
    "\n",
    "#     if rank is None:\n",
    "#         s2 = S**2\n",
    "#         cum = np.cumsum(s2) / (np.sum(s2) + 1e-12)\n",
    "#         rank = int(np.searchsorted(cum, energy) + 1)\n",
    "\n",
    "#     rank = max(1, min(rank, S.shape[0]))\n",
    "#     M_lr = (U[:, :rank] * S[:rank]) @ Vt[:rank, :]\n",
    "\n",
    "#     return M_lr.reshape(X.shape).astype(np.float32)\n",
    "\n",
    "\n",
    "# def _to_sparse_dense_keep_shape(X, keep_ratio=0.10, min_abs=None):\n",
    "#     \"\"\"\n",
    "#     Makes X sparse-in-content (many zeros) but keeps it as a dense numpy array\n",
    "#     so the rest of the pipeline (np.save/np.load/pad/model) doesn't change.\n",
    "#     Keeps the same shape.\n",
    "#     \"\"\"\n",
    "#     X = np.asarray(X, dtype=np.float32)\n",
    "#     flat = X.ravel()\n",
    "#     if flat.size == 0:\n",
    "#         return X.astype(np.float32)\n",
    "\n",
    "#     absflat = np.abs(flat)\n",
    "\n",
    "#     if min_abs is not None:\n",
    "#         thr = float(min_abs)\n",
    "#         mask = absflat >= thr\n",
    "#     else:\n",
    "#         k = int(np.ceil(keep_ratio * flat.size))\n",
    "#         k = max(1, min(k, flat.size))\n",
    "#         if k == flat.size:\n",
    "#             mask = np.ones_like(absflat, dtype=bool)\n",
    "#         else:\n",
    "#             thr = np.partition(absflat, -k)[-k]\n",
    "#             mask = absflat >= thr\n",
    "\n",
    "#     out = np.zeros_like(flat, dtype=np.float32)\n",
    "#     out[mask] = flat[mask]\n",
    "#     return out.reshape(X.shape).astype(np.float32)\n",
    "\n",
    "\n",
    "# def _apply_csi_mode(data_csi):\n",
    "#     \"\"\"\n",
    "#     Apply selected CSI_INPUT_MODE to a single sample array.\n",
    "#     \"\"\"\n",
    "#     if CSI_INPUT_MODE == \"raw\":\n",
    "#         return data_csi.astype(np.float32, copy=False)\n",
    "\n",
    "#     elif CSI_INPUT_MODE == \"lowrank\":\n",
    "#         return _low_rank_approx_keep_shape(\n",
    "#             data_csi,\n",
    "#             rank=LOW_RANK_RANK,\n",
    "#             energy=LOW_RANK_ENERGY\n",
    "#         )\n",
    "\n",
    "#     elif CSI_INPUT_MODE == \"sparse\":\n",
    "#         return _to_sparse_dense_keep_shape(\n",
    "#             data_csi,\n",
    "#             keep_ratio=SPARSE_KEEP_RATIO,\n",
    "#             min_abs=SPARSE_MIN_ABS\n",
    "#         )\n",
    "\n",
    "#     else:\n",
    "#         raise ValueError(f\"Unknown CSI_INPUT_MODE: {CSI_INPUT_MODE}. Use 'raw', 'lowrank', or 'sparse'.\")\n",
    "\n",
    "\n",
    "# def load_data_y(var_path_data_y,\n",
    "#                 var_environment=None, \n",
    "#                 var_wifi_band=None, \n",
    "#                 var_num_users=None):\n",
    "#     \"\"\"\n",
    "#     Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n",
    "#     \"\"\"\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list):\n",
    "#     \"\"\"\n",
    "#     Load CSI amplitude (*.npy) files based on a label list.\n",
    "#     \"\"\"\n",
    "#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "#     data_x = []\n",
    "#     for var_path in var_path_list:\n",
    "#         data_csi = np.load(var_path)\n",
    "\n",
    "#         # ✅ NEW: convert input CSI according to selected mode (raw/lowrank/sparse)\n",
    "#         data_csi = _apply_csi_mode(data_csi)\n",
    "\n",
    "#         var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n",
    "#         data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n",
    "#         data_x.append(data_csi_pad)\n",
    "#     data_x = np.array(data_x)\n",
    "#     return data_x\n",
    "\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     \"\"\"\n",
    "#     Encode labels according to specific task.\n",
    "#     \"\"\"\n",
    "#     if var_task == \"identity\":\n",
    "#         data_y = encode_identity(data_pd_y)\n",
    "#     elif var_task == \"activity\":\n",
    "#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     elif var_task == \"location\":\n",
    "#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     elif var_task == \"count\":\n",
    "#         data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     return data_y\n",
    "\n",
    "\n",
    "# def encode_identity(data_pd_y):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     return data_identity_onehot_y\n",
    "\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for activity labels.\n",
    "#     \"\"\"\n",
    "#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n",
    "#                                     \"user_3_activity\", \"user_4_activity\", \n",
    "#                                     \"user_5_activity\", \"user_6_activity\"]]\n",
    "#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n",
    "#     return data_activity_onehot_y\n",
    "\n",
    "\n",
    "# def encode_location(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for location labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n",
    "#     return data_location_onehot_y\n",
    "\n",
    "\n",
    "# def encode_count(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     print(\"data_identity_onehot_y\",data_identity_onehot_y.shape)\n",
    "#     count_data = np.sum(data_identity_onehot_y, axis=1)\n",
    "#     print(\"count_data\",count_data.shape)\n",
    "#     count_data = count_data.reshape(-1, 1)  # shape = (11286, 1)\n",
    "#     encoder = OneHotEncoder(sparse=False)  \n",
    "#     count_data_onehot = encoder.fit_transform(count_data)\n",
    "#     print(count_data_onehot.shape)  \n",
    "#     count_data_onehot = count_data_onehot.astype(\"int8\")\n",
    "\n",
    "#     return count_data_onehot\n",
    "\n",
    "\n",
    "# # Test functions (optional)\n",
    "# def test_load_data_y():\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"classroom\"]).describe())\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"]).describe())\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=[\"1\", \"2\", \"3\"]).describe())\n",
    "\n",
    "# def test_load_data_x():\n",
    "#     data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=None)\n",
    "#     var_label_list = data_pd_y[\"label\"].to_list()\n",
    "#     data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n",
    "#     print(data_x.shape)\n",
    "\n",
    "# def test_encode_identity():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_identity_onehot_y = encode_identity(data_pd_y)\n",
    "#     print(data_identity_onehot_y.shape)\n",
    "#     print(data_identity_onehot_y[2000])\n",
    "\n",
    "# def test_encode_activity():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     print(data_activity_onehot_y.shape)\n",
    "#     print(data_activity_onehot_y[1560])\n",
    "\n",
    "# def test_encode_location():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     print(data_location_onehot_y.shape)\n",
    "#     print(data_location_onehot_y[1560])\n",
    "\n",
    "# def test_encode_count():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_count_onehot_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     print(data_count_onehot_y.shape)\n",
    "#     print(data_count_onehot_y[20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53eec5fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.363208Z",
     "iopub.status.busy": "2025-12-28T16:51:40.363013Z",
     "iopub.status.idle": "2025-12-28T16:51:40.368017Z",
     "shell.execute_reply": "2025-12-28T16:51:40.367492Z"
    },
    "papermill": {
     "duration": 0.013626,
     "end_time": "2025-12-28T16:51:40.368936",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.355310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# [file]          load_data.py\n",
    "# [description]   load annotation file and CSI amplitude, and encode labels\n",
    "# \"\"\"\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# import numpy as np\n",
    "\n",
    "# # Note: All necessary libraries (os, numpy, pandas, etc.) are imported in Cell 1.\n",
    "# # from preset import preset   --> preset is already defined in Cell 2.\n",
    "\n",
    "# def load_data_y(var_path_data_y,\n",
    "#                 var_environment=None, \n",
    "#                 var_wifi_band=None, \n",
    "#                 var_num_users=None):\n",
    "#     \"\"\"\n",
    "#     Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n",
    "#     \"\"\"\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None:\n",
    "#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list):\n",
    "#     \"\"\"\n",
    "#     Load CSI amplitude (*.npy) files based on a label list.\n",
    "#     \"\"\"\n",
    "#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "#     data_x = []\n",
    "#     for var_path in var_path_list:\n",
    "#         data_csi = np.load(var_path)\n",
    "#         var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n",
    "#         data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n",
    "#         data_x.append(data_csi_pad)\n",
    "#     data_x = np.array(data_x)\n",
    "#     return data_x\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     \"\"\"\n",
    "#     Encode labels according to specific task.\n",
    "#     \"\"\"\n",
    "#     if var_task == \"identity\":\n",
    "#         data_y = encode_identity(data_pd_y)\n",
    "#     elif var_task == \"activity\":\n",
    "#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     elif var_task == \"location\":\n",
    "#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     elif var_task == \"count\":\n",
    "#         data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     return data_y\n",
    "\n",
    "# def encode_identity(data_pd_y):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     return data_identity_onehot_y\n",
    "\n",
    "\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for activity labels.\n",
    "#     \"\"\"\n",
    "#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n",
    "#                                     \"user_3_activity\", \"user_4_activity\", \n",
    "#                                     \"user_5_activity\", \"user_6_activity\"]]\n",
    "#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n",
    "#     return data_activity_onehot_y\n",
    "\n",
    "# def encode_location(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for location labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n",
    "#     return data_location_onehot_y\n",
    "\n",
    "# # Test functions (optional)\n",
    "# def test_load_data_y():\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"classroom\"]).describe())\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"]).describe())\n",
    "#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=[\"1\", \"2\", \"3\"]).describe())\n",
    "\n",
    "# def test_load_data_x():\n",
    "#     data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=None)\n",
    "#     var_label_list = data_pd_y[\"label\"].to_list()\n",
    "#     data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n",
    "#     print(data_x.shape)\n",
    "\n",
    "# def test_encode_identity():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_identity_onehot_y = encode_identity(data_pd_y)\n",
    "#     print(data_identity_onehot_y.shape)\n",
    "#     print(data_identity_onehot_y[2000])\n",
    "\n",
    "# def test_encode_activity():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     print(data_activity_onehot_y.shape)\n",
    "#     print(data_activity_onehot_y[1560])\n",
    "\n",
    "# def test_encode_location():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "#     print(data_location_onehot_y.shape)\n",
    "#     print(data_location_onehot_y[1560])\n",
    "\n",
    "# def encode_count(data_pd_y, var_encoding):\n",
    "#     \"\"\"\n",
    "#     Onehot encoding for identity labels.\n",
    "#     \"\"\"\n",
    "#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "#                                     \"user_3_location\", \"user_4_location\", \n",
    "#                                     \"user_5_location\", \"user_6_location\"]]\n",
    "#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n",
    "#     data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "#     data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "#     print(\"data_identity_onehot_y\",data_identity_onehot_y.shape)\n",
    "#     count_data = np.sum(data_identity_onehot_y, axis=1)\n",
    "#     print(\"count_data\",count_data.shape)\n",
    "#     count_data = count_data.reshape(-1, 1)  # shape = (11286, 1)\n",
    "#     encoder = OneHotEncoder(sparse=False)  \n",
    "#     count_data_onehot = encoder.fit_transform(count_data)\n",
    "#     print(count_data_onehot.shape)  \n",
    "#     count_data_onehot = count_data_onehot.astype(\"int8\")\n",
    "\n",
    "#     return count_data_onehot\n",
    "\n",
    "\n",
    "# def test_encode_count():\n",
    "#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n",
    "#     data_count_onehot_y = encode_count(data_pd_y)\n",
    "#     print(data_count_onehot_y.shape)\n",
    "#     print(data_count_onehot_y[20])\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     test_encode_count()\n",
    "# #     test_load_data_y()\n",
    "# #     test_load_data_x()\n",
    "# #     test_encode_identity()\n",
    "# #     test_encode_activity()\n",
    "# #     test_encode_location()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036da851",
   "metadata": {
    "papermill": {
     "duration": 0.006833,
     "end_time": "2025-12-28T16:51:40.382695",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.375862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 4: preprocess.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d9128f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.397461Z",
     "iopub.status.busy": "2025-12-28T16:51:40.397267Z",
     "iopub.status.idle": "2025-12-28T16:51:40.411397Z",
     "shell.execute_reply": "2025-12-28T16:51:40.410868Z"
    },
    "papermill": {
     "duration": 0.022773,
     "end_time": "2025-12-28T16:51:40.412368",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.389595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[file]          preprocess.py\n",
    "[description]   preprocess WiFi CSI data\n",
    "\"\"\"\n",
    "\n",
    "# All necessary libraries are already imported in Cell 1.\n",
    "\n",
    "# def mat_to_amp(data_mat):\n",
    "#     \"\"\"\n",
    "#     Calculate amplitude of raw WiFi CSI data.\n",
    "#     \"\"\"\n",
    "#     var_length = data_mat[\"trace\"].shape[0]\n",
    "#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n",
    "#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n",
    "#     return data_csi_amp\n",
    "\n",
    "def extract_csi_amp(var_dir_mat, var_dir_amp):\n",
    "    \"\"\"\n",
    "    Read raw WiFi CSI (*.mat) files, calculate CSI amplitude, and save as (*.npy).\n",
    "    \"\"\"\n",
    "    var_path_mat = os.listdir(var_dir_mat)\n",
    "    for var_c, var_path in enumerate(var_path_mat):\n",
    "        data_mat = scio.loadmat(os.path.join(var_dir_mat, var_path))\n",
    "        data_csi_amp = mat_to_amp(data_mat)\n",
    "        # print(var_c, data_csi_amp.shape)\n",
    "        var_path_save = os.path.join(var_dir_amp, var_path.replace(\".mat\", \".npy\"))\n",
    "        with open(var_path_save, \"wb\") as var_file:\n",
    "            np.save(var_file, data_csi_amp)\n",
    "\n",
    "\n",
    "\n",
    "# # تنظیمات low-rank (بدون تغییر ورودی mat_to_amp)\n",
    "# LOW_RANK_ENERGY = 0.95   # مثلاً 95% انرژی\n",
    "# LOW_RANK_RANK = None     # اگر عدد بذاری (مثلاً 5)، به جای ENERGY از rank ثابت استفاده میشه\n",
    "\n",
    "# def _low_rank_approx(X, rank=None, energy=0.95):\n",
    "#     X = np.asarray(X)\n",
    "\n",
    "#     was_1d = (X.ndim == 1)\n",
    "#     if was_1d:\n",
    "#         X = X[:, None]\n",
    "\n",
    "#     U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "\n",
    "#     if rank is None:\n",
    "#         s2 = S**2\n",
    "#         cum = np.cumsum(s2) / (np.sum(s2) + 1e-12)\n",
    "#         rank = int(np.searchsorted(cum, energy) + 1)\n",
    "\n",
    "#     rank = max(1, min(rank, S.shape[0]))\n",
    "#     X_lr = (U[:, :rank] * S[:rank]) @ Vt[:rank, :]\n",
    "\n",
    "#     if was_1d:\n",
    "#         X_lr = X_lr[:, 0]\n",
    "\n",
    "#     return X_lr.astype(np.float32)\n",
    "\n",
    "# def mat_to_amp(data_mat):\n",
    "#     \"\"\"\n",
    "#     Calculate amplitude of raw WiFi CSI data, then return its low-rank approximation.\n",
    "#     (ورودی تابع تغییر نکرده)\n",
    "#     \"\"\"\n",
    "#     var_length = data_mat[\"trace\"].shape[0]\n",
    "#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n",
    "#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n",
    "\n",
    "#     # خروجی low-rank با همان ابعاد\n",
    "#     data_csi_amp_lr = _low_rank_approx(\n",
    "#         data_csi_amp,\n",
    "#         rank=LOW_RANK_RANK,\n",
    "#         energy=LOW_RANK_ENERGY\n",
    "#     )\n",
    "#     return data_csi_amp_lr\n",
    "\n",
    "\n",
    "\n",
    "# # تنظیمات sparsity (بدون تغییر ورودی mat_to_amp)\n",
    "# SPARSE_KEEP_RATIO = 0.10   # مثلا فقط 10% بزرگترین مقادیر نگه داشته بشن\n",
    "# SPARSE_MIN_ABS = None      # اگر عدد بذاری (مثلا 0.5)، به جای keep_ratio آستانه ثابت میشه\n",
    "\n",
    "# def _to_sparse(X, keep_ratio=0.10, min_abs=None):\n",
    "#     \"\"\"\n",
    "#     Convert X to a sparse representation by keeping only large-magnitude entries.\n",
    "#     Returns:\n",
    "#       - scipy.sparse.csr_matrix if SciPy is available\n",
    "#       - otherwise returns a dense array with many zeros (still \"sparse\" in content)\n",
    "#     \"\"\"\n",
    "#     X = np.asarray(X)\n",
    "#     flat = X.ravel()\n",
    "#     absflat = np.abs(flat)\n",
    "\n",
    "#     if flat.size == 0:\n",
    "#         return X.astype(np.float32)\n",
    "\n",
    "#     # انتخاب آستانه\n",
    "#     if min_abs is not None:\n",
    "#         thr = float(min_abs)\n",
    "#         mask = absflat >= thr\n",
    "#     else:\n",
    "#         k = int(np.ceil(keep_ratio * flat.size))\n",
    "#         k = max(1, min(k, flat.size))\n",
    "#         if k == flat.size:\n",
    "#             mask = np.ones_like(absflat, dtype=bool)\n",
    "#         else:\n",
    "#             thr = np.partition(absflat, -k)[-k]  # kth largest magnitude\n",
    "#             mask = absflat >= thr\n",
    "\n",
    "#     idx = np.nonzero(mask)[0]\n",
    "#     data = flat[idx].astype(np.float32)\n",
    "\n",
    "#     # اگر SciPy هست: sparse واقعی بساز\n",
    "#     try:\n",
    "#         # معمولاً تو Cell1 یا از قبل import شده؛ اگر هم نشده باشه اینجا تلاش می‌کنه.\n",
    "#         import scipy.sparse as sp\n",
    "\n",
    "#         if X.ndim == 1:\n",
    "#             rows = idx\n",
    "#             cols = np.zeros_like(rows)\n",
    "#             shape = (X.shape[0], 1)\n",
    "#         else:\n",
    "#             rows, cols = np.unravel_index(idx, X.shape)\n",
    "#             shape = X.shape\n",
    "\n",
    "#         return sp.coo_matrix((data, (rows, cols)), shape=shape).tocsr()\n",
    "\n",
    "#     except Exception:\n",
    "#         # fallback: آرایه‌ی dense با صفرهای زیاد\n",
    "#         out = np.zeros_like(flat, dtype=np.float32)\n",
    "#         out[idx] = data\n",
    "#         return out.reshape(X.shape)\n",
    "\n",
    "def mat_to_amp(data_mat):\n",
    "    \"\"\"\n",
    "    Calculate amplitude of raw WiFi CSI data, then return its sparse version.\n",
    "    (ورودی تابع تغییر نکرده)\n",
    "    \"\"\"\n",
    "    var_length = data_mat[\"trace\"].shape[0]\n",
    "    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n",
    "    data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n",
    "\n",
    "    # خروجی sparse (CSR اگر SciPy باشد)\n",
    "    return _to_sparse(data_csi_amp, keep_ratio=SPARSE_KEEP_RATIO, min_abs=SPARSE_MIN_ABS)\n",
    "\n",
    "# تنظیمات RPCA (می‌تونی عوضشون کنی)\n",
    "RPCA_MAX_ITER = 500\n",
    "RPCA_TOL = 1e-7\n",
    "RPCA_RHO = 1.5\n",
    "RPCA_MU_INIT = None     # None یعنی خودکار\n",
    "RPCA_LAMBDA = None      # None یعنی 1/sqrt(max(m,n))\n",
    "\n",
    "def _soft_threshold(X, tau):\n",
    "    return np.sign(X) * np.maximum(np.abs(X) - tau, 0.0)\n",
    "\n",
    "def _svt(X, tau):\n",
    "    # Singular Value Thresholding\n",
    "    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    s_thr = np.maximum(s - tau, 0.0)\n",
    "    # اگر همه صفر شد، سریع برگرد\n",
    "    if np.all(s_thr == 0):\n",
    "        return np.zeros_like(X)\n",
    "    return (U * s_thr) @ Vt\n",
    "\n",
    "def _rpca_ialm(M, lam=None, mu=None, rho=1.5, max_iter=500, tol=1e-7):\n",
    "    \"\"\"\n",
    "    Robust PCA via Inexact Augmented Lagrange Multiplier (IALM)\n",
    "    Decompose: M = L + S\n",
    "    Returns: L, S (same shape as M)\n",
    "    \"\"\"\n",
    "    M = M.astype(np.float64, copy=False)\n",
    "    m, n = M.shape\n",
    "\n",
    "    if lam is None:\n",
    "        lam = 1.0 / np.sqrt(max(m, n))\n",
    "\n",
    "    # mu پیشنهادی (خودکار)\n",
    "    if mu is None:\n",
    "        # ||M||_2 تقریباً بزرگ‌ترین singular value است\n",
    "        norm2 = np.linalg.svd(M, compute_uv=False)[0] if M.size else 1.0\n",
    "        mu = 1.25 / (norm2 + 1e-12)\n",
    "\n",
    "    L = np.zeros_like(M)\n",
    "    S = np.zeros_like(M)\n",
    "    Y = np.zeros_like(M)\n",
    "\n",
    "    normM = np.linalg.norm(M, ord='fro') + 1e-12\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        # L update\n",
    "        L = _svt(M - S + (1.0/mu)*Y, 1.0/mu)\n",
    "\n",
    "        # S update (sparse)\n",
    "        S = _soft_threshold(M - L + (1.0/mu)*Y, lam/mu)\n",
    "\n",
    "        # dual update\n",
    "        R = M - L - S\n",
    "        Y = Y + mu * R\n",
    "\n",
    "        # stop\n",
    "        err = np.linalg.norm(R, ord='fro') / normM\n",
    "        if err < tol:\n",
    "            break\n",
    "\n",
    "        mu *= rho\n",
    "\n",
    "    return L.astype(np.float32), S.astype(np.float32)\n",
    "\n",
    "# def mat_to_amp(data_mat):\n",
    "#     \"\"\"\n",
    "#     Calculate amplitude of raw WiFi CSI data, then return RPCA sparse component S.\n",
    "#     (ورودی تابع تغییر نکرده)\n",
    "#     \"\"\"\n",
    "#     var_length = data_mat[\"trace\"].shape[0]\n",
    "#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n",
    "#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n",
    "\n",
    "#     was_1d = (data_csi_amp.ndim == 1)\n",
    "#     M = data_csi_amp[:, None] if was_1d else data_csi_amp\n",
    "\n",
    "#     _, S = _rpca_ialm(\n",
    "#         M,\n",
    "#         lam=RPCA_LAMBDA,\n",
    "#         mu=RPCA_MU_INIT,\n",
    "#         rho=RPCA_RHO,\n",
    "#         max_iter=RPCA_MAX_ITER,\n",
    "#         tol=RPCA_TOL\n",
    "#     )\n",
    "\n",
    "#     if was_1d:\n",
    "#         S = S[:, 0]\n",
    "\n",
    "#     return S\n",
    "\n",
    "def mat_to_amp(data_mat):\n",
    "    \"\"\"\n",
    "    Calculate amplitude of raw WiFi CSI data, then return RPCA low-rank component L.\n",
    "    (ورودی تابع تغییر نکرده)\n",
    "    \"\"\"\n",
    "    var_length = data_mat[\"trace\"].shape[0]\n",
    "    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n",
    "    data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n",
    "\n",
    "    was_1d = (data_csi_amp.ndim == 1)\n",
    "    M = data_csi_amp[:, None] if was_1d else data_csi_amp\n",
    "\n",
    "    L, _ = _rpca_ialm(\n",
    "        M,\n",
    "        lam=RPCA_LAMBDA,\n",
    "        mu=RPCA_MU_INIT,\n",
    "        rho=RPCA_RHO,\n",
    "        max_iter=RPCA_MAX_ITER,\n",
    "        tol=RPCA_TOL\n",
    "    )\n",
    "\n",
    "    if was_1d:\n",
    "        L = L[:, 0]\n",
    "\n",
    "    return L\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    Parse arguments from input.\n",
    "    \"\"\"\n",
    "    var_args = argparse.ArgumentParser()\n",
    "    var_args.add_argument(\"--dir_mat\", default=\"/kaggle/input/wimans/wifi_csi/mat\", type=str)\n",
    "    var_args.add_argument(\"--dir_amp\", default=\"/kaggle/input/wimans/wifi_csi/amp\", type=str)\n",
    "    return var_args.parse_args()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     var_args = parse_args()\n",
    "#     extract_csi_amp(var_dir_mat=var_args.dir_mat, var_dir_amp=var_args.dir_amp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a21a4e",
   "metadata": {
    "papermill": {
     "duration": 0.006817,
     "end_time": "2025-12-28T16:51:40.426082",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.419265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 5: that.py (WiFi-based Model THAT)\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1538cc4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.440890Z",
     "iopub.status.busy": "2025-12-28T16:51:40.440692Z",
     "iopub.status.idle": "2025-12-28T16:51:40.464628Z",
     "shell.execute_reply": "2025-12-28T16:51:40.464096Z"
    },
    "papermill": {
     "duration": 0.032649,
     "end_time": "2025-12-28T16:51:40.465636",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.432987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[file]          that.py\n",
    "[description]   implement and evaluate WiFi-based model THAT\n",
    "                https://github.com/windofshadow/THAT\n",
    "\"\"\"\n",
    "\n",
    "# All necessary libraries are imported in Cell 1.\n",
    "# from train import train   --> Defined in Cell 6.\n",
    "# from preset import preset --> Defined in Cell 2.\n",
    "\n",
    "class Gaussian_Position(torch.nn.Module):\n",
    "    def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n",
    "        super(Gaussian_Position, self).__init__()\n",
    "        var_embedding = torch.zeros([var_num_gaussian, var_dim_feature], dtype=torch.float)\n",
    "        self.var_embedding = torch.nn.Parameter(var_embedding, requires_grad=True)\n",
    "        torch.nn.init.xavier_uniform_(self.var_embedding)\n",
    "        var_position = torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian)\n",
    "        self.var_position = torch.nn.Parameter(var_position, requires_grad=False)\n",
    "        var_mu = torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0)\n",
    "        self.var_mu = torch.nn.Parameter(var_mu, requires_grad=True)\n",
    "        var_sigma = torch.tensor([50.0] * var_num_gaussian).unsqueeze(0)\n",
    "        self.var_sigma = torch.nn.Parameter(var_sigma, requires_grad=True)\n",
    "\n",
    "    def calculate_pdf(self, var_position, var_mu, var_sigma):\n",
    "        var_pdf = var_position - var_mu\n",
    "        var_pdf = - var_pdf * var_pdf\n",
    "        var_pdf = var_pdf / var_sigma / var_sigma / 2\n",
    "        var_pdf = var_pdf - torch.log(var_sigma)\n",
    "        return var_pdf\n",
    "\n",
    "    def forward(self, var_input):\n",
    "        var_pdf = self.calculate_pdf(self.var_position, self.var_mu, self.var_sigma)\n",
    "        var_pdf = torch.softmax(var_pdf, dim=-1)\n",
    "        var_position_encoding = torch.matmul(var_pdf, self.var_embedding)\n",
    "        var_output = var_input + var_position_encoding.unsqueeze(0)\n",
    "        return var_output\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n",
    "        self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n",
    "        self.layer_dropout_0 = torch.nn.Dropout(0.1)\n",
    "        self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n",
    "        layer_cnn = []\n",
    "        for var_size in var_size_cnn:\n",
    "            layer = torch.nn.Sequential(\n",
    "                torch.nn.Conv1d(var_dim_feature, var_dim_feature, var_size, padding=\"same\"),\n",
    "                torch.nn.BatchNorm1d(var_dim_feature),\n",
    "                torch.nn.Dropout(0.1),\n",
    "                torch.nn.LeakyReLU()\n",
    "            )\n",
    "            layer_cnn.append(layer)\n",
    "        self.layer_cnn = torch.nn.ModuleList(layer_cnn)\n",
    "        self.layer_dropout_1 = torch.nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, var_input):\n",
    "        var_t = var_input\n",
    "        var_t = self.layer_norm_0(var_t)\n",
    "        var_t, _ = self.layer_attention(var_t, var_t, var_t)\n",
    "        var_t = self.layer_dropout_0(var_t)\n",
    "        var_t = var_t + var_input\n",
    "        var_s = self.layer_norm_1(var_t)\n",
    "        var_s = torch.permute(var_s, (0, 2, 1))\n",
    "        var_c = torch.stack([layer(var_s) for layer in self.layer_cnn], dim=0)\n",
    "        var_s = torch.sum(var_c, dim=0) / len(self.layer_cnn)\n",
    "        var_s = self.layer_dropout_1(var_s)\n",
    "        var_s = torch.permute(var_s, (0, 2, 1))\n",
    "        var_output = var_s + var_t\n",
    "        return var_output\n",
    "\n",
    "class THAT(torch.nn.Module):\n",
    "    def __init__(self, var_x_shape, var_y_shape):\n",
    "        super(THAT, self).__init__()\n",
    "        var_dim_feature = var_x_shape[-1]\n",
    "        var_dim_time = var_x_shape[-2]\n",
    "        var_dim_output = var_y_shape[-1]\n",
    "        # Left branch\n",
    "        self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "        self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n",
    "        var_num_left = 4\n",
    "        var_dim_left = var_dim_feature\n",
    "        self.layer_left_encoder = torch.nn.ModuleList([\n",
    "            Encoder(var_dim_feature=var_dim_left, var_num_head=10, var_size_cnn=[1, 3, 5])\n",
    "            for _ in range(var_num_left)\n",
    "        ])\n",
    "        self.layer_left_norm = torch.nn.LayerNorm(var_dim_left, eps=1e-6)\n",
    "        self.layer_left_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=8)\n",
    "        self.layer_left_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=16)\n",
    "        self.layer_left_dropout = torch.nn.Dropout(0.5)\n",
    "        # Right branch\n",
    "        self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "        var_num_right = 1\n",
    "        var_dim_right = var_dim_time // 20\n",
    "        self.layer_right_encoder = torch.nn.ModuleList([\n",
    "            Encoder(var_dim_feature=var_dim_right, var_num_head=10, var_size_cnn=[1, 2, 3])\n",
    "            for _ in range(var_num_right)\n",
    "        ])\n",
    "        self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n",
    "        self.layer_right_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=2)\n",
    "        self.layer_right_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=4)\n",
    "        self.layer_right_dropout = torch.nn.Dropout(0.5)\n",
    "        self.layer_leakyrelu = torch.nn.LeakyReLU()\n",
    "        self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n",
    "\n",
    "    def forward(self, var_input):\n",
    "        var_t = var_input  # shape: (batch_size, time_steps, features)\n",
    "        # Left branch\n",
    "        var_left = torch.permute(var_t, (0, 2, 1))\n",
    "        var_left = self.layer_left_pooling(var_left)\n",
    "        var_left = torch.permute(var_left, (0, 2, 1))\n",
    "        var_left = self.layer_left_gaussian(var_left)\n",
    "        for layer in self.layer_left_encoder:\n",
    "            var_left = layer(var_left)\n",
    "        var_left = self.layer_left_norm(var_left)\n",
    "        var_left = torch.permute(var_left, (0, 2, 1))\n",
    "        var_left_0 = self.layer_leakyrelu(self.layer_left_cnn_0(var_left))\n",
    "        var_left_1 = self.layer_leakyrelu(self.layer_left_cnn_1(var_left))\n",
    "        var_left_0 = torch.sum(var_left_0, dim=-1)\n",
    "        var_left_1 = torch.sum(var_left_1, dim=-1)\n",
    "        var_left = torch.concat([var_left_0, var_left_1], dim=-1)\n",
    "        var_left = self.layer_left_dropout(var_left)\n",
    "        # Right branch\n",
    "        var_right = torch.permute(var_t, (0, 2, 1))\n",
    "        var_right = self.layer_right_pooling(var_right)\n",
    "        for layer in self.layer_right_encoder:\n",
    "            var_right = layer(var_right)\n",
    "        var_right = self.layer_right_norm(var_right)\n",
    "        var_right = torch.permute(var_right, (0, 2, 1))\n",
    "        var_right_0 = self.layer_leakyrelu(self.layer_right_cnn_0(var_right))\n",
    "        var_right_1 = self.layer_leakyrelu(self.layer_right_cnn_1(var_right))\n",
    "        var_right_0 = torch.sum(var_right_0, dim=-1)\n",
    "        var_right_1 = torch.sum(var_right_1, dim=-1)\n",
    "        var_right = torch.concat([var_right_0, var_right_1], dim=-1)\n",
    "        var_right = self.layer_right_dropout(var_right)\n",
    "        # Concatenate branches\n",
    "        var_t = torch.concat([var_left, var_right], dim=-1)\n",
    "        var_output = self.layer_output(var_t)\n",
    "        return var_output\n",
    "\n",
    "def run_that(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n",
    "    \"\"\"\n",
    "    Run WiFi-based model THAT.\n",
    "    \"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    data_train_x = data_train_x.reshape(data_train_x.shape[0], data_train_x.shape[1], -1)\n",
    "    data_test_x = data_test_x.reshape(data_test_x.shape[0], data_test_x.shape[1], -1)\n",
    "    var_x_shape, var_y_shape = data_train_x[0].shape, data_train_y[0].reshape(-1).shape\n",
    "    data_train_set = TensorDataset(torch.from_numpy(data_train_x), torch.from_numpy(data_train_y))\n",
    "    data_test_set = TensorDataset(torch.from_numpy(data_test_x), torch.from_numpy(data_test_y))\n",
    "    \n",
    "    result = {}\n",
    "    result_accuracy = []\n",
    "    result_time_train = []\n",
    "    result_time_test = []\n",
    "    \n",
    "    # var_macs, var_params = get_model_complexity_info(THAT(var_x_shape, var_y_shape), var_x_shape, as_strings=False)\n",
    "    # print(\"Parameters:\", var_params, \"- FLOPs:\", var_macs * 2)\n",
    "    \n",
    "    for var_r in range(var_repeat):\n",
    "        print(\"Repeat\", var_r)\n",
    "        torch.random.manual_seed(var_r + 39)\n",
    "        if init_model is not None:\n",
    "            model_that = init_model\n",
    "            lr2 = preset[\"nn\"][\"lr\"] /10\n",
    "        else:\n",
    "            model_that = THAT(var_x_shape, var_y_shape).to(device)\n",
    "            lr2 = preset[\"nn\"][\"lr\"]\n",
    "\n",
    "        optimizer = torch.optim.Adam(model_that.parameters(), lr=lr2, weight_decay=0)\n",
    "        loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4] * var_y_shape[-1]).to(device))\n",
    "        var_time_0 = time.time()\n",
    "        \n",
    "        # Train\n",
    "        var_best_weight = train(model=model_that, optimizer=optimizer, loss=loss, \n",
    "                                  data_train_set=data_train_set, data_test_set=data_test_set,\n",
    "                                  var_threshold=preset[\"nn\"][\"threshold\"],\n",
    "                                  var_batch_size=preset[\"nn\"][\"batch_size\"],\n",
    "                                  var_epochs=preset[\"nn\"][\"epoch\"],\n",
    "                                  device=device)\n",
    "        var_time_1 = time.time()\n",
    "        \n",
    "        # Test\n",
    "        model_that.load_state_dict(var_best_weight)\n",
    "        with torch.no_grad():\n",
    "            predict_test_y = model_that(torch.from_numpy(data_test_x).to(device))\n",
    "        predict_test_y = (torch.sigmoid(predict_test_y) > preset[\"nn\"][\"threshold\"]).float()\n",
    "        predict_test_y = predict_test_y.detach().cpu().numpy()\n",
    "        var_time_2 = time.time()\n",
    "        \n",
    "        # Evaluate\n",
    "        data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "        predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "        result_acc = accuracy_score(data_test_y_c.astype(int), predict_test_y_c.astype(int))\n",
    "        result_dict = classification_report(data_test_y_c, predict_test_y_c, digits=6, zero_division=0, output_dict=True)\n",
    "        result[\"repeat_\" + str(var_r)] = result_dict\n",
    "        result_accuracy.append(result_acc)\n",
    "        result_time_train.append(var_time_1 - var_time_0)\n",
    "        result_time_test.append(var_time_2 - var_time_1)\n",
    "        print(\"repeat_\" + str(var_r), result_accuracy)\n",
    "        print(result)\n",
    "    \n",
    "    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n",
    "    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n",
    "    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n",
    "    # result[\"complexity\"] = {\"parameter\": var_params, \"flops\": var_macs * 2}\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7c59c6",
   "metadata": {
    "papermill": {
     "duration": 0.006875,
     "end_time": "2025-12-28T16:51:40.479750",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.472875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c20b731",
   "metadata": {
    "papermill": {
     "duration": 0.006827,
     "end_time": "2025-12-28T16:51:40.493477",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.486650",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell7: for RESNET18 Model\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "620a5a71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.508279Z",
     "iopub.status.busy": "2025-12-28T16:51:40.508044Z",
     "iopub.status.idle": "2025-12-28T16:51:40.514872Z",
     "shell.execute_reply": "2025-12-28T16:51:40.514237Z"
    },
    "papermill": {
     "duration": 0.015841,
     "end_time": "2025-12-28T16:51:40.516036",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.500195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "# import torch._dynamo\n",
    "# torch._dynamo.config.suppress_errors = True\n",
    "# import time\n",
    "# import torch\n",
    "# torch.cuda.empty_cache()\n",
    "# import numpy as np\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# import torchvision.models as models\n",
    "# from copy import deepcopy\n",
    "\n",
    "# torch.set_float32_matmul_precision(\"high\")\n",
    "# torch._dynamo.config.cache_size_limit = 65536\n",
    "\n",
    "# # فرض می‌کنیم preset قبلاً تعریف شده باشه\n",
    "# # preset = { \"nn\": {\"lr\": 1e-3, \"epoch\": 10, \"batch_size\": 4, \"threshold\": 0.5}, ... }\n",
    "\n",
    "# class ResNet18Model(torch.nn.Module):\n",
    "#     def __init__(self, var_x_shape, var_y_shape):\n",
    "#         super(ResNet18Model, self).__init__()\n",
    "#         model_resnet = models.resnet18(weights=None)\n",
    "#         model_resnet.conv1 = torch.nn.Conv2d(1, 64, 7, 3, 2, bias=False)\n",
    "#         in_features_fc = model_resnet.fc.in_features  # معمولاً 512\n",
    "#         out_features_fc = var_y_shape[-1]\n",
    "#         model_resnet.fc = torch.nn.Linear(in_features_fc, out_features_fc)\n",
    "#         self.resnet = model_resnet\n",
    "\n",
    "#     def forward(self, var_input):\n",
    "#         var_input = var_input.reshape(var_input.size(0), 1, 3000, 270)\n",
    "#         return self.resnet(var_input)\n",
    "\n",
    "# def run_resnet(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     var_x_shape = data_train_x[0].shape\n",
    "#     var_y_shape = data_train_y[0].reshape(-1).shape\n",
    "\n",
    "#     # تغییر شکل داده‌ها روی CPU\n",
    "#     data_train_x = data_train_x.reshape(data_train_x.shape[0], 1, data_train_x.shape[1],\n",
    "#                                         data_train_x.shape[2]*data_train_x.shape[3]*data_train_x.shape[4])\n",
    "#     data_test_x  = data_test_x.reshape(data_test_x.shape[0], 1, data_test_x.shape[1],\n",
    "#                                        data_test_x.shape[2]*data_test_x.shape[3]*data_test_x.shape[4])\n",
    "    \n",
    "#     # دیتاست‌ها روی CPU\n",
    "#     data_train_set = TensorDataset(torch.from_numpy(data_train_x).float(),\n",
    "#                                    torch.from_numpy(data_train_y).float())\n",
    "#     data_test_set  = TensorDataset(torch.from_numpy(data_test_x).float(),\n",
    "#                                    torch.from_numpy(data_test_y).float())\n",
    "    \n",
    "#     result = {}\n",
    "#     result_accuracy = []\n",
    "#     result_time_train = []\n",
    "#     result_time_test = []\n",
    "    \n",
    "#     for var_r in range(var_repeat):\n",
    "#         print(\"Repeat\", var_r)\n",
    "#         torch.random.manual_seed(var_r + 39)\n",
    "        \n",
    "#         # ساخت مدل و انتقال به GPU\n",
    "#         if init_model is not None:\n",
    "#             model_resnet = init_model\n",
    "#             lr2 = preset[\"nn\"][\"lr\"] /10\n",
    "            \n",
    "#         else:\n",
    "#             model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n",
    "#             lr2 = preset[\"nn\"][\"lr\"]\n",
    "\n",
    "#         optimizer = torch.optim.Adam(model_resnet.parameters(), lr=lr2, weight_decay=0)\n",
    "#         loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6] * var_y_shape[-1]).to(device))\n",
    "        \n",
    "#         # تابع آموزش داخلی؛ دیتا روی CPU باقی می‌مونه و فقط هنگام محاسبه batch به GPU میره\n",
    "#         def train_inner():\n",
    "#             train_loader = DataLoader(data_train_set, preset[\"nn\"][\"batch_size\"], shuffle=True, pin_memory=False)\n",
    "#             test_loader = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n",
    "#             best_accuracy = 0\n",
    "#             best_weight = None\n",
    "            \n",
    "#             for epoch in range(preset[\"nn\"][\"epoch\"]):\n",
    "#                 t0 = time.time()\n",
    "#                 model_resnet.train()\n",
    "#                 # متغیرهای مربوط به آخرین batch آموزش\n",
    "#                 last_train_loss = None\n",
    "#                 last_train_acc = None\n",
    "#                 for batch in train_loader:\n",
    "#                     batch_x, batch_y = batch\n",
    "#                     batch_x = batch_x.to(device)\n",
    "#                     batch_y = batch_y.to(device)\n",
    "#                     outputs = model_resnet(batch_x)\n",
    "#                     loss_val = loss_func(outputs, batch_y.reshape(batch_y.shape[0], -1).float())\n",
    "#                     optimizer.zero_grad()\n",
    "#                     loss_val.backward()\n",
    "#                     optimizer.step()\n",
    "#                     last_train_loss = loss_val.item()\n",
    "#                     # محاسبه دقت آخرین batch آموزش\n",
    "#                     train_preds = (torch.sigmoid(outputs) > preset[\"nn\"][\"threshold\"]).float()\n",
    "#                     last_train_acc = accuracy_score(batch_y.reshape(batch_y.shape[0], -1).detach().cpu().numpy().astype(int),\n",
    "#                                                     train_preds.detach().cpu().numpy().astype(int))\n",
    "                \n",
    "#                 # ارزیابی روی دیتاست تست به صورت batch به batch\n",
    "#                 model_resnet.eval()\n",
    "#                 all_preds = []\n",
    "#                 all_labels = []\n",
    "#                 test_loss_val = None\n",
    "#                 with torch.no_grad():\n",
    "#                     for t_batch in test_loader:\n",
    "#                         t_x, t_y = t_batch\n",
    "#                         t_x = t_x.to(device)\n",
    "#                         outputs_test = model_resnet(t_x)\n",
    "#                         outputs_test = (torch.sigmoid(outputs_test) > preset[\"nn\"][\"threshold\"]).float()\n",
    "#                         all_preds.append(outputs_test.detach().cpu().numpy())\n",
    "#                         all_labels.append(t_y.cpu().numpy())  # اینجا تغییر دادیم\n",
    "#                 preds_cat = np.vstack(all_preds)\n",
    "#                 labels_cat = np.vstack(all_labels)\n",
    "#                 print(\"preds_cat\",preds_cat.shape)\n",
    "#                 # تبدیل به شکل (n, 6, 5)\n",
    "                \n",
    "#                 # preds_cat = preds_cat.reshape(-1, 6, 5)\n",
    "#                 # labels_cat = labels_cat.reshape(-1, 6, 5)\n",
    "\n",
    "#                 preds_cat = preds_cat.reshape(-1, 6)\n",
    "#                 labels_cat = labels_cat.reshape(-1, 6)\n",
    "                \n",
    "#                 # برای محاسبه دقت، مسطح می‌کنیم\n",
    "#                 test_acc = accuracy_score(labels_cat.reshape(labels_cat.shape[0], -1).astype(int),\n",
    "#                                           preds_cat.reshape(preds_cat.shape[0], -1).astype(int))\n",
    "#                 epoch_time = time.time() - t0\n",
    "#                 print(f\"Epoch {epoch}/{preset['nn']['epoch']} - \"\n",
    "#                       f\"Train Loss: {(last_train_loss if last_train_loss is not None else 0.0):.6f}, \"\n",
    "#                       f\"Train Acc: {(last_train_acc if last_train_acc is not None else 0.0):.6f}, \"\n",
    "#                       f\"Test Loss: {(test_loss_val if test_loss_val is not None else 0.0):.6f}, \"\n",
    "#                       f\"Test Acc: {(test_acc if test_acc is not None else 0.0):.6f} - \"\n",
    "#                       f\"Time: {epoch_time:.4f}s\")\n",
    "\n",
    "#                 if test_acc > best_accuracy:\n",
    "#                     best_accuracy = test_acc\n",
    "#                     print('-----***-----')\n",
    "#                     print(best_accuracy)\n",
    "#                     best_weight = deepcopy(model_resnet.state_dict())\n",
    "#             return best_weight\n",
    "        \n",
    "#         t0_run = time.time()\n",
    "#         best_weight = train_inner()\n",
    "#         t1_run = time.time()\n",
    "        \n",
    "#         torch.save(model_resnet.state_dict(), f\"{name_run}_model_final.pt\")\n",
    "#         model_resnet.load_state_dict(best_weight)\n",
    "#         torch.save(model_resnet.state_dict(), f\"{name_run}_best_model.pt\")\n",
    "\n",
    "#         # bad age niaz bod load koni\n",
    "#         # model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n",
    "#         # model_resnet.load_state_dict(torch.load(\"resnet_model_repeat0.pt\"))\n",
    "#         # model_resnet.eval()\n",
    "\n",
    "        \n",
    "#         # ارزیابی نهایی مدل روی دیتاست تست (استفاده از batchهای کوچک)\n",
    "#         model_resnet.eval()\n",
    "#         all_preds = []\n",
    "#         test_loader_final = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n",
    "#         with torch.no_grad():\n",
    "#             for batch in test_loader_final:\n",
    "#                 batch_x, _ = batch\n",
    "#                 batch_x = batch_x.to(device)\n",
    "#                 all_preds.append(model_resnet(batch_x))\n",
    "#         preds_all = torch.cat(all_preds, dim=0)\n",
    "#         preds_final = (torch.sigmoid(preds_all) > preset[\"nn\"][\"threshold\"]).float().detach().cpu().numpy()\n",
    "#         t2_run = time.time()\n",
    "        \n",
    "#         data_test_y_np = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "#         preds_final = preds_final.reshape(-1, data_test_y.shape[-1])\n",
    "#         acc_final = accuracy_score(data_test_y_np.astype(int), preds_final.astype(int))\n",
    "#         result[f\"repeat_{var_r}\"] = {\"accuracy\": acc_final}\n",
    "#         result_accuracy.append(acc_final)\n",
    "#         result_time_train.append(t1_run - t0_run)\n",
    "#         result_time_test.append(t2_run - t1_run)\n",
    "#         print(\"Repeat\", var_r, \"Final Test Accuracy:\", acc_final)\n",
    "    \n",
    "#     result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n",
    "#     result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n",
    "#     result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b00e6a",
   "metadata": {
    "papermill": {
     "duration": 0.006841,
     "end_time": "2025-12-28T16:51:40.529884",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.523043",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 9: train.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70183677",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:40.544423Z",
     "iopub.status.busy": "2025-12-28T16:51:40.544223Z",
     "iopub.status.idle": "2025-12-28T16:51:41.063176Z",
     "shell.execute_reply": "2025-12-28T16:51:41.062588Z"
    },
    "papermill": {
     "duration": 0.527748,
     "end_time": "2025-12-28T16:51:41.064456",
     "exception": false,
     "start_time": "2025-12-28T16:51:40.536708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[file]          train.py\n",
    "[description]   function to train WiFi-based models\n",
    "\"\"\"\n",
    "\n",
    "# All necessary libraries are imported in Cell 1.\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch._dynamo.config.cache_size_limit = 65536\n",
    "\n",
    "def train(model, optimizer, loss, data_train_set, data_test_set, var_threshold, var_batch_size, var_epochs, device):\n",
    "    \"\"\"\n",
    "    Generic training function for WiFi-based models.\n",
    "    \"\"\"\n",
    "    # دیتا رو روی CPU نگه می‌داریم (pin_memory=False)\n",
    "    data_train_loader = DataLoader(data_train_set, var_batch_size, shuffle=True, pin_memory=False)\n",
    "    data_test_loader = DataLoader(data_test_set, batch_size=len(data_test_set), shuffle=False, pin_memory=False)\n",
    "    \n",
    "    var_best_accuracy = -1.0\n",
    "    var_best_weight   = deepcopy(model.state_dict())\n",
    "    \n",
    "    \n",
    "    for var_epoch in range(var_epochs):\n",
    "        var_time_e0 = time.time()\n",
    "        model.train()\n",
    "        for data_batch in data_train_loader:\n",
    "            data_batch_x, data_batch_y = data_batch\n",
    "            # انتقال موقتی داده به GPU فقط برای forward pass\n",
    "            data_batch_x = data_batch_x.to(device)\n",
    "            data_batch_y = data_batch_y.to(device)\n",
    "            predict_train_y = model(data_batch_x)\n",
    "            var_loss_train = loss(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n",
    "            optimizer.zero_grad()\n",
    "            var_loss_train.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # محاسبه دقت روی آخرین batch و انتقال نتایج به CPU\n",
    "        predict_train_y = (torch.sigmoid(predict_train_y) > var_threshold).float()\n",
    "        data_batch_y = data_batch_y.detach().cpu().numpy()\n",
    "        predict_train_y = predict_train_y.detach().cpu().numpy()\n",
    "        \n",
    "        predict_train_y = predict_train_y.reshape(-1, data_batch_y.shape[-1])\n",
    "        data_batch_y = data_batch_y.reshape(-1, data_batch_y.shape[-1])\n",
    "        var_accuracy_train = accuracy_score(data_batch_y.astype(int), predict_train_y.astype(int))\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            data_test_x, data_test_y = next(iter(data_test_loader))\n",
    "            # انتقال موقتی دیتا تست به GPU برای محاسبات\n",
    "            data_test_x = data_test_x.to(device)\n",
    "            data_test_y = data_test_y.to(device)\n",
    "            \n",
    "            predict_test_y = model(data_test_x)\n",
    "            var_loss_test = loss(predict_test_y, data_test_y.reshape(data_test_y.shape[0], -1).float())\n",
    "            \n",
    "            predict_test_y = (torch.sigmoid(predict_test_y) > var_threshold).float()\n",
    "            \n",
    "            # انتقال نتایج به CPU برای ارزیابی\n",
    "            data_test_y = data_test_y.detach().cpu().numpy()\n",
    "            predict_test_y = predict_test_y.detach().cpu().numpy()\n",
    "            \n",
    "            predict_test_y = predict_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "            data_test_y = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "            var_accuracy_test = accuracy_score(data_test_y.astype(int), predict_test_y.astype(int))\n",
    "        \n",
    "        print(f\"Epoch {var_epoch}/{var_epochs}\",\n",
    "              \"- %.6fs\"%(time.time() - var_time_e0),\n",
    "              \"- Loss %.6f\"%var_loss_train.cpu(),\n",
    "              \"- Accuracy %.6f\"%var_accuracy_train,\n",
    "              \"- Test Loss %.6f\"%var_loss_test.cpu(),\n",
    "              \"- Test Accuracy %.6f\"%var_accuracy_test)\n",
    "            \n",
    "        if var_accuracy_test > var_best_accuracy:\n",
    "            var_best_accuracy = var_accuracy_test\n",
    "            print('-----***-----')\n",
    "            print(var_best_accuracy)\n",
    "            var_best_weight = deepcopy(model.state_dict())\n",
    "\n",
    "    torch.save(model.state_dict(), f\"{name_run}_model_final.pt\")\n",
    "    torch.save(var_best_weight, f\"{name_run}_best_model.pt\")\n",
    "\n",
    "    \n",
    "    return var_best_weight\n",
    "\n",
    "\n",
    "\n",
    "# === importsِ لازم را یک‌بار بالای فایل اضافه کن ===\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- تابع کمکی ----------\n",
    "def save_confusion_matrix(model, data_loader, threshold, device, pdf_path):\n",
    "    \"\"\"\n",
    "    Runs the model on `data_loader`, builds a confusion matrix and writes it to `pdf_path`.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in data_loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "\n",
    "            preds = (torch.sigmoid(logits) > threshold).float().cpu().numpy().ravel()\n",
    "            yb    = yb.cpu().numpy().ravel()\n",
    "\n",
    "            y_true.extend(yb)\n",
    "            y_pred.extend(preds)\n",
    "\n",
    "    cm  = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay(cm).plot(ax=ax)\n",
    "    ax.set_title(\"Confusion Matrix – Test\")\n",
    "\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "# ---------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e34f67",
   "metadata": {
    "papermill": {
     "duration": 0.007043,
     "end_time": "2025-12-28T16:51:41.079025",
     "exception": false,
     "start_time": "2025-12-28T16:51:41.071982",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 11: run.py\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b86deb62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T16:51:41.094149Z",
     "iopub.status.busy": "2025-12-28T16:51:41.093707Z",
     "iopub.status.idle": "2025-12-28T18:53:43.507435Z",
     "shell.execute_reply": "2025-12-28T18:53:43.506501Z"
    },
    "papermill": {
     "duration": 7322.423249,
     "end_time": "2025-12-28T18:53:43.509121",
     "exception": false,
     "start_time": "2025-12-28T16:51:41.085872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "\n",
      "[DEBUG] First loaded AMP sample: act_1_1\n",
      "[DEBUG] shape=(2835, 3, 3, 30), dtype=float32, complex=False\n",
      "[DEBUG] ==> Input is REAL -> amplitude-only (no true phase).\n",
      "\n",
      "Running model: THAT\n",
      "Repeat 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1036.)\n",
      "  return F.conv1d(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000 - 6.256345s - Loss 23.009678 - Accuracy 0.000000 - Test Loss 15.876498 - Test Accuracy 0.000000\n",
      "-----***-----\n",
      "0.0\n",
      "Epoch 1/1000 - 5.057798s - Loss 20.901386 - Accuracy 0.000000 - Test Loss 14.429099 - Test Accuracy 0.000000\n",
      "Epoch 2/1000 - 5.020100s - Loss 19.562012 - Accuracy 0.000000 - Test Loss 13.137087 - Test Accuracy 0.000000\n",
      "Epoch 3/1000 - 5.040955s - Loss 18.394449 - Accuracy 0.005208 - Test Loss 11.986968 - Test Accuracy 0.002210\n",
      "-----***-----\n",
      "0.0022104332449160036\n",
      "Epoch 4/1000 - 5.022768s - Loss 16.394665 - Accuracy 0.005208 - Test Loss 10.976893 - Test Accuracy 0.002653\n",
      "-----***-----\n",
      "0.002652519893899204\n",
      "Epoch 5/1000 - 5.036402s - Loss 15.129914 - Accuracy 0.005208 - Test Loss 10.071714 - Test Accuracy 0.004421\n",
      "-----***-----\n",
      "0.004420866489832007\n",
      "Epoch 6/1000 - 5.021710s - Loss 15.298329 - Accuracy 0.005208 - Test Loss 9.295197 - Test Accuracy 0.007958\n",
      "-----***-----\n",
      "0.007957559681697613\n",
      "Epoch 7/1000 - 5.028368s - Loss 15.672078 - Accuracy 0.005208 - Test Loss 8.621930 - Test Accuracy 0.011494\n",
      "-----***-----\n",
      "0.011494252873563218\n",
      "Epoch 8/1000 - 5.022402s - Loss 14.280947 - Accuracy 0.010417 - Test Loss 8.046945 - Test Accuracy 0.015915\n",
      "-----***-----\n",
      "0.015915119363395226\n",
      "Epoch 9/1000 - 5.017781s - Loss 13.052667 - Accuracy 0.010417 - Test Loss 7.561539 - Test Accuracy 0.022104\n",
      "-----***-----\n",
      "0.022104332449160036\n",
      "Epoch 10/1000 - 5.019909s - Loss 13.022560 - Accuracy 0.005208 - Test Loss 7.138610 - Test Accuracy 0.028736\n",
      "-----***-----\n",
      "0.028735632183908046\n",
      "Epoch 11/1000 - 5.031371s - Loss 12.964721 - Accuracy 0.015625 - Test Loss 6.769908 - Test Accuracy 0.038462\n",
      "-----***-----\n",
      "0.038461538461538464\n",
      "Epoch 12/1000 - 5.031084s - Loss 13.065360 - Accuracy 0.010417 - Test Loss 6.440363 - Test Accuracy 0.048630\n",
      "-----***-----\n",
      "0.04862953138815208\n",
      "Epoch 13/1000 - 5.030412s - Loss 10.973701 - Accuracy 0.026042 - Test Loss 6.142363 - Test Accuracy 0.061450\n",
      "-----***-----\n",
      "0.0614500442086649\n",
      "Epoch 14/1000 - 5.023300s - Loss 10.856109 - Accuracy 0.020833 - Test Loss 5.887574 - Test Accuracy 0.072060\n",
      "-----***-----\n",
      "0.07206012378426171\n",
      "Epoch 15/1000 - 5.033718s - Loss 11.941941 - Accuracy 0.026042 - Test Loss 5.665226 - Test Accuracy 0.088859\n",
      "-----***-----\n",
      "0.08885941644562334\n",
      "Epoch 16/1000 - 5.021408s - Loss 12.271067 - Accuracy 0.005208 - Test Loss 5.454266 - Test Accuracy 0.103448\n",
      "-----***-----\n",
      "0.10344827586206896\n",
      "Epoch 17/1000 - 5.029709s - Loss 12.236445 - Accuracy 0.010417 - Test Loss 5.266043 - Test Accuracy 0.115385\n",
      "-----***-----\n",
      "0.11538461538461539\n",
      "Epoch 18/1000 - 5.035984s - Loss 11.937408 - Accuracy 0.015625 - Test Loss 5.111334 - Test Accuracy 0.123342\n",
      "-----***-----\n",
      "0.123342175066313\n",
      "Epoch 19/1000 - 5.033885s - Loss 10.090325 - Accuracy 0.010417 - Test Loss 4.950099 - Test Accuracy 0.131300\n",
      "-----***-----\n",
      "0.1312997347480106\n",
      "Epoch 20/1000 - 5.025710s - Loss 11.390232 - Accuracy 0.041667 - Test Loss 4.809274 - Test Accuracy 0.139257\n",
      "-----***-----\n",
      "0.13925729442970822\n",
      "Epoch 21/1000 - 5.024889s - Loss 8.812180 - Accuracy 0.010417 - Test Loss 4.684973 - Test Accuracy 0.148983\n",
      "-----***-----\n",
      "0.14898320070733864\n",
      "Epoch 22/1000 - 5.024816s - Loss 8.664680 - Accuracy 0.052083 - Test Loss 4.571599 - Test Accuracy 0.158267\n",
      "-----***-----\n",
      "0.15826702033598586\n",
      "Epoch 23/1000 - 5.029913s - Loss 10.997520 - Accuracy 0.031250 - Test Loss 4.467540 - Test Accuracy 0.161804\n",
      "-----***-----\n",
      "0.16180371352785147\n",
      "Epoch 24/1000 - 5.020625s - Loss 8.725469 - Accuracy 0.036458 - Test Loss 4.369093 - Test Accuracy 0.173740\n",
      "-----***-----\n",
      "0.17374005305039789\n",
      "Epoch 25/1000 - 5.027006s - Loss 9.479031 - Accuracy 0.000000 - Test Loss 4.282013 - Test Accuracy 0.184792\n",
      "-----***-----\n",
      "0.1847922192749779\n",
      "Epoch 26/1000 - 5.021775s - Loss 9.329172 - Accuracy 0.026042 - Test Loss 4.198537 - Test Accuracy 0.187445\n",
      "-----***-----\n",
      "0.1874447391688771\n",
      "Epoch 27/1000 - 5.021776s - Loss 9.127588 - Accuracy 0.046875 - Test Loss 4.119945 - Test Accuracy 0.196286\n",
      "-----***-----\n",
      "0.1962864721485411\n",
      "Epoch 28/1000 - 5.019046s - Loss 9.576538 - Accuracy 0.026042 - Test Loss 4.046984 - Test Accuracy 0.204686\n",
      "-----***-----\n",
      "0.20468611847922194\n",
      "Epoch 29/1000 - 5.035433s - Loss 9.206242 - Accuracy 0.041667 - Test Loss 3.975490 - Test Accuracy 0.211760\n",
      "-----***-----\n",
      "0.21175950486295314\n",
      "Epoch 30/1000 - 5.020820s - Loss 8.809492 - Accuracy 0.036458 - Test Loss 3.908629 - Test Accuracy 0.216180\n",
      "-----***-----\n",
      "0.21618037135278514\n",
      "Epoch 31/1000 - 5.034461s - Loss 7.716249 - Accuracy 0.031250 - Test Loss 3.847192 - Test Accuracy 0.222812\n",
      "-----***-----\n",
      "0.22281167108753316\n",
      "Epoch 32/1000 - 5.023581s - Loss 7.872492 - Accuracy 0.052083 - Test Loss 3.792692 - Test Accuracy 0.229885\n",
      "-----***-----\n",
      "0.22988505747126436\n",
      "Epoch 33/1000 - 5.037341s - Loss 8.554244 - Accuracy 0.031250 - Test Loss 3.729857 - Test Accuracy 0.233864\n",
      "-----***-----\n",
      "0.2338638373121132\n",
      "Epoch 34/1000 - 5.021286s - Loss 8.947474 - Accuracy 0.010417 - Test Loss 3.674115 - Test Accuracy 0.242706\n",
      "-----***-----\n",
      "0.2427055702917772\n",
      "Epoch 35/1000 - 5.024719s - Loss 7.827073 - Accuracy 0.067708 - Test Loss 3.623753 - Test Accuracy 0.247569\n",
      "-----***-----\n",
      "0.2475685234305924\n",
      "Epoch 36/1000 - 5.028732s - Loss 7.681603 - Accuracy 0.078125 - Test Loss 3.574440 - Test Accuracy 0.254200\n",
      "-----***-----\n",
      "0.2541998231653404\n",
      "Epoch 37/1000 - 5.047674s - Loss 7.439884 - Accuracy 0.041667 - Test Loss 3.535451 - Test Accuracy 0.257737\n",
      "-----***-----\n",
      "0.257736516357206\n",
      "Epoch 38/1000 - 5.034264s - Loss 7.997415 - Accuracy 0.067708 - Test Loss 3.495460 - Test Accuracy 0.262157\n",
      "-----***-----\n",
      "0.26215738284703805\n",
      "Epoch 39/1000 - 5.032504s - Loss 7.737267 - Accuracy 0.057292 - Test Loss 3.452096 - Test Accuracy 0.262599\n",
      "-----***-----\n",
      "0.2625994694960212\n",
      "Epoch 40/1000 - 5.015874s - Loss 7.195288 - Accuracy 0.062500 - Test Loss 3.412401 - Test Accuracy 0.267020\n",
      "-----***-----\n",
      "0.26702033598585323\n",
      "Epoch 41/1000 - 5.043021s - Loss 7.819210 - Accuracy 0.052083 - Test Loss 3.375127 - Test Accuracy 0.269231\n",
      "-----***-----\n",
      "0.2692307692307692\n",
      "Epoch 42/1000 - 5.026298s - Loss 8.342989 - Accuracy 0.046875 - Test Loss 3.339827 - Test Accuracy 0.275862\n",
      "-----***-----\n",
      "0.27586206896551724\n",
      "Epoch 43/1000 - 5.029042s - Loss 6.543349 - Accuracy 0.057292 - Test Loss 3.306773 - Test Accuracy 0.277188\n",
      "-----***-----\n",
      "0.27718832891246686\n",
      "Epoch 44/1000 - 5.016831s - Loss 7.053971 - Accuracy 0.052083 - Test Loss 3.271676 - Test Accuracy 0.282493\n",
      "-----***-----\n",
      "0.28249336870026526\n",
      "Epoch 45/1000 - 5.044639s - Loss 6.729138 - Accuracy 0.031250 - Test Loss 3.232583 - Test Accuracy 0.286472\n",
      "-----***-----\n",
      "0.2864721485411141\n",
      "Epoch 46/1000 - 5.026984s - Loss 6.298934 - Accuracy 0.057292 - Test Loss 3.197204 - Test Accuracy 0.294430\n",
      "-----***-----\n",
      "0.29442970822281167\n",
      "Epoch 47/1000 - 5.037671s - Loss 8.589314 - Accuracy 0.026042 - Test Loss 3.169359 - Test Accuracy 0.298851\n",
      "-----***-----\n",
      "0.2988505747126437\n",
      "Epoch 48/1000 - 5.025802s - Loss 7.527813 - Accuracy 0.046875 - Test Loss 3.145948 - Test Accuracy 0.301945\n",
      "-----***-----\n",
      "0.3019451812555261\n",
      "Epoch 49/1000 - 5.033240s - Loss 7.010113 - Accuracy 0.052083 - Test Loss 3.122151 - Test Accuracy 0.301945\n",
      "Epoch 50/1000 - 5.025465s - Loss 7.953188 - Accuracy 0.031250 - Test Loss 3.091928 - Test Accuracy 0.302829\n",
      "-----***-----\n",
      "0.30282935455349247\n",
      "Epoch 51/1000 - 5.038219s - Loss 5.969191 - Accuracy 0.057292 - Test Loss 3.063312 - Test Accuracy 0.306366\n",
      "-----***-----\n",
      "0.3063660477453581\n",
      "Epoch 52/1000 - 5.032867s - Loss 7.424435 - Accuracy 0.036458 - Test Loss 3.035772 - Test Accuracy 0.312113\n",
      "-----***-----\n",
      "0.3121131741821397\n",
      "Epoch 53/1000 - 5.043279s - Loss 7.277008 - Accuracy 0.057292 - Test Loss 3.016946 - Test Accuracy 0.310787\n",
      "Epoch 54/1000 - 5.041584s - Loss 6.918050 - Accuracy 0.036458 - Test Loss 2.996243 - Test Accuracy 0.317418\n",
      "-----***-----\n",
      "0.31741821396993813\n",
      "Epoch 55/1000 - 5.046875s - Loss 7.352501 - Accuracy 0.062500 - Test Loss 2.971547 - Test Accuracy 0.319187\n",
      "-----***-----\n",
      "0.3191865605658709\n",
      "Epoch 56/1000 - 5.036752s - Loss 6.205722 - Accuracy 0.052083 - Test Loss 2.950488 - Test Accuracy 0.322723\n",
      "-----***-----\n",
      "0.32272325375773653\n",
      "Epoch 57/1000 - 5.062105s - Loss 6.627688 - Accuracy 0.072917 - Test Loss 2.931567 - Test Accuracy 0.322723\n",
      "Epoch 58/1000 - 5.031168s - Loss 7.040722 - Accuracy 0.083333 - Test Loss 2.907923 - Test Accuracy 0.323607\n",
      "-----***-----\n",
      "0.32360742705570295\n",
      "Epoch 59/1000 - 5.040331s - Loss 5.855069 - Accuracy 0.072917 - Test Loss 2.889999 - Test Accuracy 0.328912\n",
      "-----***-----\n",
      "0.32891246684350134\n",
      "Epoch 60/1000 - 5.030278s - Loss 5.444850 - Accuracy 0.093750 - Test Loss 2.865055 - Test Accuracy 0.328912\n",
      "Epoch 61/1000 - 5.057325s - Loss 6.127146 - Accuracy 0.104167 - Test Loss 2.844300 - Test Accuracy 0.331123\n",
      "-----***-----\n",
      "0.3311229000884173\n",
      "Epoch 62/1000 - 5.043140s - Loss 5.933831 - Accuracy 0.057292 - Test Loss 2.822769 - Test Accuracy 0.332891\n",
      "-----***-----\n",
      "0.3328912466843501\n",
      "Epoch 63/1000 - 5.062281s - Loss 6.854627 - Accuracy 0.062500 - Test Loss 2.802445 - Test Accuracy 0.337312\n",
      "-----***-----\n",
      "0.33731211317418214\n",
      "Epoch 64/1000 - 5.052685s - Loss 6.391992 - Accuracy 0.052083 - Test Loss 2.784432 - Test Accuracy 0.338196\n",
      "-----***-----\n",
      "0.33819628647214856\n",
      "Epoch 65/1000 - 5.038425s - Loss 5.896593 - Accuracy 0.072917 - Test Loss 2.765812 - Test Accuracy 0.336428\n",
      "Epoch 66/1000 - 5.044283s - Loss 6.261476 - Accuracy 0.062500 - Test Loss 2.746652 - Test Accuracy 0.339523\n",
      "-----***-----\n",
      "0.3395225464190981\n",
      "Epoch 67/1000 - 5.035402s - Loss 6.409527 - Accuracy 0.046875 - Test Loss 2.730068 - Test Accuracy 0.343059\n",
      "-----***-----\n",
      "0.34305923961096374\n",
      "Epoch 68/1000 - 5.042822s - Loss 5.833133 - Accuracy 0.062500 - Test Loss 2.715616 - Test Accuracy 0.341291\n",
      "Epoch 69/1000 - 5.047113s - Loss 6.026062 - Accuracy 0.057292 - Test Loss 2.698478 - Test Accuracy 0.348806\n",
      "-----***-----\n",
      "0.34880636604774534\n",
      "Epoch 70/1000 - 5.038893s - Loss 5.633880 - Accuracy 0.072917 - Test Loss 2.680875 - Test Accuracy 0.352343\n",
      "-----***-----\n",
      "0.35234305923961096\n",
      "Epoch 71/1000 - 5.060424s - Loss 6.207699 - Accuracy 0.072917 - Test Loss 2.664889 - Test Accuracy 0.350575\n",
      "Epoch 72/1000 - 5.046999s - Loss 5.079421 - Accuracy 0.072917 - Test Loss 2.646257 - Test Accuracy 0.353669\n",
      "-----***-----\n",
      "0.3536693191865606\n",
      "Epoch 73/1000 - 5.066491s - Loss 5.845572 - Accuracy 0.057292 - Test Loss 2.629973 - Test Accuracy 0.355438\n",
      "-----***-----\n",
      "0.35543766578249336\n",
      "Epoch 74/1000 - 5.045605s - Loss 4.083502 - Accuracy 0.093750 - Test Loss 2.611125 - Test Accuracy 0.355880\n",
      "-----***-----\n",
      "0.35587975243147657\n",
      "Epoch 75/1000 - 5.060685s - Loss 4.996949 - Accuracy 0.067708 - Test Loss 2.593204 - Test Accuracy 0.356322\n",
      "-----***-----\n",
      "0.3563218390804598\n",
      "Epoch 76/1000 - 5.040935s - Loss 5.094873 - Accuracy 0.083333 - Test Loss 2.576194 - Test Accuracy 0.358974\n",
      "-----***-----\n",
      "0.358974358974359\n",
      "Epoch 77/1000 - 5.055866s - Loss 5.227695 - Accuracy 0.088542 - Test Loss 2.563145 - Test Accuracy 0.361627\n",
      "-----***-----\n",
      "0.3616268788682582\n",
      "Epoch 78/1000 - 5.063641s - Loss 5.190100 - Accuracy 0.067708 - Test Loss 2.547372 - Test Accuracy 0.360743\n",
      "Epoch 79/1000 - 5.052158s - Loss 5.693362 - Accuracy 0.052083 - Test Loss 2.538006 - Test Accuracy 0.360743\n",
      "Epoch 80/1000 - 5.054464s - Loss 6.100757 - Accuracy 0.057292 - Test Loss 2.524962 - Test Accuracy 0.362511\n",
      "-----***-----\n",
      "0.3625110521662246\n",
      "Epoch 81/1000 - 5.038355s - Loss 4.744292 - Accuracy 0.093750 - Test Loss 2.507832 - Test Accuracy 0.363395\n",
      "-----***-----\n",
      "0.363395225464191\n",
      "Epoch 82/1000 - 5.067513s - Loss 5.417522 - Accuracy 0.067708 - Test Loss 2.490292 - Test Accuracy 0.364279\n",
      "-----***-----\n",
      "0.36427939876215737\n",
      "Epoch 83/1000 - 5.053409s - Loss 5.475107 - Accuracy 0.098958 - Test Loss 2.470657 - Test Accuracy 0.364721\n",
      "-----***-----\n",
      "0.3647214854111406\n",
      "Epoch 84/1000 - 5.068378s - Loss 5.300919 - Accuracy 0.114583 - Test Loss 2.458333 - Test Accuracy 0.366490\n",
      "-----***-----\n",
      "0.3664898320070734\n",
      "Epoch 85/1000 - 5.042214s - Loss 4.985148 - Accuracy 0.041667 - Test Loss 2.441737 - Test Accuracy 0.366490\n",
      "Epoch 86/1000 - 5.075447s - Loss 5.088217 - Accuracy 0.072917 - Test Loss 2.424934 - Test Accuracy 0.367816\n",
      "-----***-----\n",
      "0.367816091954023\n",
      "Epoch 87/1000 - 5.042233s - Loss 5.324661 - Accuracy 0.072917 - Test Loss 2.415389 - Test Accuracy 0.371795\n",
      "-----***-----\n",
      "0.3717948717948718\n",
      "Epoch 88/1000 - 5.068454s - Loss 4.991786 - Accuracy 0.098958 - Test Loss 2.402753 - Test Accuracy 0.378426\n",
      "-----***-----\n",
      "0.3784261715296198\n",
      "Epoch 89/1000 - 5.047575s - Loss 5.243283 - Accuracy 0.062500 - Test Loss 2.389006 - Test Accuracy 0.377100\n",
      "Epoch 90/1000 - 5.061248s - Loss 4.619000 - Accuracy 0.072917 - Test Loss 2.379592 - Test Accuracy 0.374889\n",
      "Epoch 91/1000 - 5.041115s - Loss 5.059298 - Accuracy 0.046875 - Test Loss 2.363986 - Test Accuracy 0.375774\n",
      "Epoch 92/1000 - 5.044843s - Loss 5.540489 - Accuracy 0.046875 - Test Loss 2.348511 - Test Accuracy 0.377542\n",
      "Epoch 93/1000 - 5.051864s - Loss 5.894771 - Accuracy 0.088542 - Test Loss 2.333610 - Test Accuracy 0.379310\n",
      "-----***-----\n",
      "0.3793103448275862\n",
      "Epoch 94/1000 - 5.044690s - Loss 5.332002 - Accuracy 0.072917 - Test Loss 2.320374 - Test Accuracy 0.380195\n",
      "-----***-----\n",
      "0.3801945181255526\n",
      "Epoch 95/1000 - 5.040567s - Loss 5.206182 - Accuracy 0.098958 - Test Loss 2.308313 - Test Accuracy 0.381963\n",
      "-----***-----\n",
      "0.3819628647214854\n",
      "Epoch 96/1000 - 5.046191s - Loss 5.198038 - Accuracy 0.062500 - Test Loss 2.296239 - Test Accuracy 0.382847\n",
      "-----***-----\n",
      "0.3828470380194518\n",
      "Epoch 97/1000 - 5.036963s - Loss 4.931056 - Accuracy 0.083333 - Test Loss 2.284215 - Test Accuracy 0.381079\n",
      "Epoch 98/1000 - 5.057476s - Loss 4.707376 - Accuracy 0.057292 - Test Loss 2.269630 - Test Accuracy 0.381521\n",
      "Epoch 99/1000 - 5.039291s - Loss 4.402805 - Accuracy 0.104167 - Test Loss 2.261897 - Test Accuracy 0.384615\n",
      "-----***-----\n",
      "0.38461538461538464\n",
      "Epoch 100/1000 - 5.071613s - Loss 4.956904 - Accuracy 0.067708 - Test Loss 2.247612 - Test Accuracy 0.386384\n",
      "-----***-----\n",
      "0.3863837312113174\n",
      "Epoch 101/1000 - 5.043333s - Loss 5.476546 - Accuracy 0.088542 - Test Loss 2.239660 - Test Accuracy 0.387268\n",
      "-----***-----\n",
      "0.38726790450928383\n",
      "Epoch 102/1000 - 5.060425s - Loss 5.121802 - Accuracy 0.072917 - Test Loss 2.225065 - Test Accuracy 0.387710\n",
      "-----***-----\n",
      "0.38770999115826704\n",
      "Epoch 103/1000 - 5.034057s - Loss 4.543068 - Accuracy 0.062500 - Test Loss 2.218064 - Test Accuracy 0.386826\n",
      "Epoch 104/1000 - 5.039594s - Loss 4.814395 - Accuracy 0.093750 - Test Loss 2.209072 - Test Accuracy 0.388594\n",
      "-----***-----\n",
      "0.3885941644562334\n",
      "Epoch 105/1000 - 5.036332s - Loss 3.916824 - Accuracy 0.114583 - Test Loss 2.196140 - Test Accuracy 0.388152\n",
      "Epoch 106/1000 - 5.055216s - Loss 4.295823 - Accuracy 0.083333 - Test Loss 2.186589 - Test Accuracy 0.391247\n",
      "-----***-----\n",
      "0.3912466843501326\n",
      "Epoch 107/1000 - 5.042365s - Loss 4.255246 - Accuracy 0.078125 - Test Loss 2.171751 - Test Accuracy 0.392573\n",
      "-----***-----\n",
      "0.3925729442970822\n",
      "Epoch 108/1000 - 5.053391s - Loss 4.732893 - Accuracy 0.088542 - Test Loss 2.156631 - Test Accuracy 0.389478\n",
      "Epoch 109/1000 - 5.035917s - Loss 4.799653 - Accuracy 0.119792 - Test Loss 2.146856 - Test Accuracy 0.391689\n",
      "Epoch 110/1000 - 5.062210s - Loss 4.579484 - Accuracy 0.109375 - Test Loss 2.133451 - Test Accuracy 0.394341\n",
      "-----***-----\n",
      "0.394341290893015\n",
      "Epoch 111/1000 - 5.040651s - Loss 4.074148 - Accuracy 0.125000 - Test Loss 2.120490 - Test Accuracy 0.392573\n",
      "Epoch 112/1000 - 5.050744s - Loss 4.406229 - Accuracy 0.078125 - Test Loss 2.107261 - Test Accuracy 0.393899\n",
      "Epoch 113/1000 - 5.037381s - Loss 4.493266 - Accuracy 0.125000 - Test Loss 2.099408 - Test Accuracy 0.396994\n",
      "-----***-----\n",
      "0.39699381078691426\n",
      "Epoch 114/1000 - 5.038815s - Loss 4.267896 - Accuracy 0.052083 - Test Loss 2.088971 - Test Accuracy 0.398320\n",
      "-----***-----\n",
      "0.39832007073386383\n",
      "Epoch 115/1000 - 5.039899s - Loss 3.630856 - Accuracy 0.135417 - Test Loss 2.079064 - Test Accuracy 0.401415\n",
      "-----***-----\n",
      "0.40141467727674623\n",
      "Epoch 116/1000 - 5.067188s - Loss 3.838472 - Accuracy 0.093750 - Test Loss 2.067580 - Test Accuracy 0.401415\n",
      "Epoch 117/1000 - 5.036274s - Loss 4.529381 - Accuracy 0.109375 - Test Loss 2.058379 - Test Accuracy 0.402741\n",
      "-----***-----\n",
      "0.40274093722369586\n",
      "Epoch 118/1000 - 5.067334s - Loss 3.953187 - Accuracy 0.072917 - Test Loss 2.051021 - Test Accuracy 0.406720\n",
      "-----***-----\n",
      "0.40671971706454463\n",
      "Epoch 119/1000 - 5.041570s - Loss 4.531018 - Accuracy 0.109375 - Test Loss 2.042293 - Test Accuracy 0.405836\n",
      "Epoch 120/1000 - 5.046627s - Loss 4.115385 - Accuracy 0.156250 - Test Loss 2.033285 - Test Accuracy 0.407162\n",
      "-----***-----\n",
      "0.40716180371352784\n",
      "Epoch 121/1000 - 5.044014s - Loss 3.924087 - Accuracy 0.093750 - Test Loss 2.023993 - Test Accuracy 0.407162\n",
      "Epoch 122/1000 - 5.048150s - Loss 3.776696 - Accuracy 0.114583 - Test Loss 2.014314 - Test Accuracy 0.406278\n",
      "Epoch 123/1000 - 5.058838s - Loss 3.495821 - Accuracy 0.161458 - Test Loss 2.004366 - Test Accuracy 0.409814\n",
      "-----***-----\n",
      "0.40981432360742703\n",
      "Epoch 124/1000 - 5.082221s - Loss 3.758769 - Accuracy 0.135417 - Test Loss 1.991261 - Test Accuracy 0.410698\n",
      "-----***-----\n",
      "0.41069849690539345\n",
      "Epoch 125/1000 - 5.063279s - Loss 3.832032 - Accuracy 0.093750 - Test Loss 1.990242 - Test Accuracy 0.414677\n",
      "-----***-----\n",
      "0.4146772767462423\n",
      "Epoch 126/1000 - 5.070223s - Loss 4.030848 - Accuracy 0.088542 - Test Loss 1.981936 - Test Accuracy 0.416888\n",
      "-----***-----\n",
      "0.41688770999115826\n",
      "Epoch 127/1000 - 5.051270s - Loss 4.545514 - Accuracy 0.078125 - Test Loss 1.971675 - Test Accuracy 0.415561\n",
      "Epoch 128/1000 - 5.062252s - Loss 4.322984 - Accuracy 0.078125 - Test Loss 1.960444 - Test Accuracy 0.412909\n",
      "Epoch 129/1000 - 5.046632s - Loss 4.032352 - Accuracy 0.109375 - Test Loss 1.945214 - Test Accuracy 0.409372\n",
      "Epoch 130/1000 - 5.061103s - Loss 4.029840 - Accuracy 0.114583 - Test Loss 1.936743 - Test Accuracy 0.411583\n",
      "Epoch 131/1000 - 5.048572s - Loss 3.926268 - Accuracy 0.109375 - Test Loss 1.928649 - Test Accuracy 0.411583\n",
      "Epoch 132/1000 - 5.051656s - Loss 4.259169 - Accuracy 0.140625 - Test Loss 1.919392 - Test Accuracy 0.412909\n",
      "Epoch 133/1000 - 5.034945s - Loss 3.410039 - Accuracy 0.104167 - Test Loss 1.908649 - Test Accuracy 0.412467\n",
      "Epoch 134/1000 - 5.047284s - Loss 3.349600 - Accuracy 0.135417 - Test Loss 1.898333 - Test Accuracy 0.415561\n",
      "Epoch 135/1000 - 5.035613s - Loss 3.576617 - Accuracy 0.083333 - Test Loss 1.887815 - Test Accuracy 0.414677\n",
      "Epoch 136/1000 - 5.049049s - Loss 3.310293 - Accuracy 0.135417 - Test Loss 1.879642 - Test Accuracy 0.416446\n",
      "Epoch 137/1000 - 5.049434s - Loss 2.829593 - Accuracy 0.140625 - Test Loss 1.873479 - Test Accuracy 0.416888\n",
      "Epoch 138/1000 - 5.054772s - Loss 3.742027 - Accuracy 0.109375 - Test Loss 1.867809 - Test Accuracy 0.417330\n",
      "-----***-----\n",
      "0.41732979664014147\n",
      "Epoch 139/1000 - 5.035524s - Loss 3.885675 - Accuracy 0.125000 - Test Loss 1.856858 - Test Accuracy 0.416004\n",
      "Epoch 140/1000 - 5.063993s - Loss 3.272673 - Accuracy 0.104167 - Test Loss 1.848411 - Test Accuracy 0.417772\n",
      "-----***-----\n",
      "0.4177718832891247\n",
      "Epoch 141/1000 - 5.051372s - Loss 3.434389 - Accuracy 0.072917 - Test Loss 1.837043 - Test Accuracy 0.414235\n",
      "Epoch 142/1000 - 5.050862s - Loss 3.395306 - Accuracy 0.088542 - Test Loss 1.828748 - Test Accuracy 0.419098\n",
      "-----***-----\n",
      "0.41909814323607425\n",
      "Epoch 143/1000 - 5.046607s - Loss 4.069451 - Accuracy 0.114583 - Test Loss 1.816779 - Test Accuracy 0.421309\n",
      "-----***-----\n",
      "0.4213085764809903\n",
      "Epoch 144/1000 - 5.063697s - Loss 2.854108 - Accuracy 0.171875 - Test Loss 1.805609 - Test Accuracy 0.415561\n",
      "Epoch 145/1000 - 5.043927s - Loss 3.301132 - Accuracy 0.104167 - Test Loss 1.797201 - Test Accuracy 0.420424\n",
      "Epoch 146/1000 - 5.048913s - Loss 2.896590 - Accuracy 0.109375 - Test Loss 1.791358 - Test Accuracy 0.419098\n",
      "Epoch 147/1000 - 5.040675s - Loss 3.757140 - Accuracy 0.078125 - Test Loss 1.782107 - Test Accuracy 0.422193\n",
      "-----***-----\n",
      "0.42219274977895666\n",
      "Epoch 148/1000 - 5.048989s - Loss 3.675943 - Accuracy 0.088542 - Test Loss 1.774799 - Test Accuracy 0.423077\n",
      "-----***-----\n",
      "0.4230769230769231\n",
      "Epoch 149/1000 - 5.039036s - Loss 3.285704 - Accuracy 0.125000 - Test Loss 1.768867 - Test Accuracy 0.423519\n",
      "-----***-----\n",
      "0.4235190097259063\n",
      "Epoch 150/1000 - 5.057411s - Loss 2.756303 - Accuracy 0.130208 - Test Loss 1.759489 - Test Accuracy 0.425729\n",
      "-----***-----\n",
      "0.42572944297082227\n",
      "Epoch 151/1000 - 5.054455s - Loss 3.278859 - Accuracy 0.125000 - Test Loss 1.751221 - Test Accuracy 0.427056\n",
      "-----***-----\n",
      "0.4270557029177719\n",
      "Epoch 152/1000 - 5.056072s - Loss 3.836966 - Accuracy 0.067708 - Test Loss 1.741369 - Test Accuracy 0.424403\n",
      "Epoch 153/1000 - 5.037260s - Loss 3.123151 - Accuracy 0.098958 - Test Loss 1.731466 - Test Accuracy 0.426172\n",
      "Epoch 154/1000 - 5.052894s - Loss 2.969594 - Accuracy 0.119792 - Test Loss 1.722543 - Test Accuracy 0.429266\n",
      "-----***-----\n",
      "0.4292661361626879\n",
      "Epoch 155/1000 - 5.040291s - Loss 3.726458 - Accuracy 0.114583 - Test Loss 1.715869 - Test Accuracy 0.430150\n",
      "-----***-----\n",
      "0.4301503094606543\n",
      "Epoch 156/1000 - 5.041080s - Loss 3.446948 - Accuracy 0.078125 - Test Loss 1.706901 - Test Accuracy 0.427498\n",
      "Epoch 157/1000 - 5.072964s - Loss 3.874136 - Accuracy 0.135417 - Test Loss 1.700175 - Test Accuracy 0.428824\n",
      "Epoch 158/1000 - 5.060442s - Loss 3.300159 - Accuracy 0.088542 - Test Loss 1.692374 - Test Accuracy 0.424845\n",
      "Epoch 159/1000 - 5.043372s - Loss 2.943080 - Accuracy 0.119792 - Test Loss 1.684570 - Test Accuracy 0.425729\n",
      "Epoch 160/1000 - 5.056291s - Loss 3.155047 - Accuracy 0.109375 - Test Loss 1.678719 - Test Accuracy 0.431034\n",
      "-----***-----\n",
      "0.43103448275862066\n",
      "Epoch 161/1000 - 5.064457s - Loss 2.978882 - Accuracy 0.151042 - Test Loss 1.669475 - Test Accuracy 0.428824\n",
      "Epoch 162/1000 - 5.064242s - Loss 3.467641 - Accuracy 0.130208 - Test Loss 1.662367 - Test Accuracy 0.430150\n",
      "Epoch 163/1000 - 5.056460s - Loss 3.101710 - Accuracy 0.187500 - Test Loss 1.655584 - Test Accuracy 0.431477\n",
      "-----***-----\n",
      "0.43147656940760387\n",
      "Epoch 164/1000 - 5.048629s - Loss 2.962069 - Accuracy 0.161458 - Test Loss 1.646914 - Test Accuracy 0.431477\n",
      "Epoch 165/1000 - 5.056020s - Loss 3.742005 - Accuracy 0.114583 - Test Loss 1.637609 - Test Accuracy 0.429708\n",
      "Epoch 166/1000 - 5.038026s - Loss 2.675563 - Accuracy 0.130208 - Test Loss 1.629964 - Test Accuracy 0.432361\n",
      "-----***-----\n",
      "0.4323607427055703\n",
      "Epoch 167/1000 - 5.042849s - Loss 2.923628 - Accuracy 0.145833 - Test Loss 1.622250 - Test Accuracy 0.431034\n",
      "Epoch 168/1000 - 5.052569s - Loss 3.482536 - Accuracy 0.067708 - Test Loss 1.615202 - Test Accuracy 0.431477\n",
      "Epoch 169/1000 - 5.053979s - Loss 2.659686 - Accuracy 0.182292 - Test Loss 1.605969 - Test Accuracy 0.429708\n",
      "Epoch 170/1000 - 5.035408s - Loss 3.550029 - Accuracy 0.135417 - Test Loss 1.601987 - Test Accuracy 0.429266\n",
      "Epoch 171/1000 - 5.049921s - Loss 3.439482 - Accuracy 0.109375 - Test Loss 1.596607 - Test Accuracy 0.433245\n",
      "-----***-----\n",
      "0.4332449160035367\n",
      "Epoch 172/1000 - 5.045272s - Loss 3.357428 - Accuracy 0.104167 - Test Loss 1.588469 - Test Accuracy 0.435013\n",
      "-----***-----\n",
      "0.4350132625994695\n",
      "Epoch 173/1000 - 5.064195s - Loss 2.963507 - Accuracy 0.130208 - Test Loss 1.581029 - Test Accuracy 0.432803\n",
      "Epoch 174/1000 - 5.051132s - Loss 3.167279 - Accuracy 0.072917 - Test Loss 1.574348 - Test Accuracy 0.434129\n",
      "Epoch 175/1000 - 5.074535s - Loss 2.588242 - Accuracy 0.104167 - Test Loss 1.564882 - Test Accuracy 0.432803\n",
      "Epoch 176/1000 - 5.035210s - Loss 2.826869 - Accuracy 0.151042 - Test Loss 1.553784 - Test Accuracy 0.432361\n",
      "Epoch 177/1000 - 5.095262s - Loss 2.435123 - Accuracy 0.182292 - Test Loss 1.546737 - Test Accuracy 0.433245\n",
      "Epoch 178/1000 - 5.044141s - Loss 2.566123 - Accuracy 0.135417 - Test Loss 1.540240 - Test Accuracy 0.433245\n",
      "Epoch 179/1000 - 5.061375s - Loss 2.708652 - Accuracy 0.166667 - Test Loss 1.533862 - Test Accuracy 0.435455\n",
      "-----***-----\n",
      "0.4354553492484527\n",
      "Epoch 180/1000 - 5.048524s - Loss 2.763454 - Accuracy 0.109375 - Test Loss 1.528001 - Test Accuracy 0.434571\n",
      "Epoch 181/1000 - 5.046150s - Loss 2.734766 - Accuracy 0.151042 - Test Loss 1.521957 - Test Accuracy 0.437666\n",
      "-----***-----\n",
      "0.4376657824933687\n",
      "Epoch 182/1000 - 5.043393s - Loss 2.574178 - Accuracy 0.151042 - Test Loss 1.514160 - Test Accuracy 0.433245\n",
      "Epoch 183/1000 - 5.040534s - Loss 2.964286 - Accuracy 0.119792 - Test Loss 1.507565 - Test Accuracy 0.434129\n",
      "Epoch 184/1000 - 5.043185s - Loss 2.697703 - Accuracy 0.130208 - Test Loss 1.499136 - Test Accuracy 0.435897\n",
      "Epoch 185/1000 - 5.054815s - Loss 2.756562 - Accuracy 0.098958 - Test Loss 1.491771 - Test Accuracy 0.437224\n",
      "Epoch 186/1000 - 5.052880s - Loss 2.185619 - Accuracy 0.166667 - Test Loss 1.487755 - Test Accuracy 0.437666\n",
      "Epoch 187/1000 - 5.079596s - Loss 2.633054 - Accuracy 0.109375 - Test Loss 1.480739 - Test Accuracy 0.436782\n",
      "Epoch 188/1000 - 5.036886s - Loss 2.913114 - Accuracy 0.109375 - Test Loss 1.471224 - Test Accuracy 0.438550\n",
      "-----***-----\n",
      "0.4385499557913351\n",
      "Epoch 189/1000 - 5.068929s - Loss 2.320071 - Accuracy 0.213542 - Test Loss 1.463281 - Test Accuracy 0.440318\n",
      "-----***-----\n",
      "0.4403183023872679\n",
      "Epoch 190/1000 - 5.056423s - Loss 2.441258 - Accuracy 0.161458 - Test Loss 1.457336 - Test Accuracy 0.439876\n",
      "Epoch 191/1000 - 5.061546s - Loss 2.868746 - Accuracy 0.166667 - Test Loss 1.450420 - Test Accuracy 0.437666\n",
      "Epoch 192/1000 - 5.042420s - Loss 2.534738 - Accuracy 0.135417 - Test Loss 1.443989 - Test Accuracy 0.441645\n",
      "-----***-----\n",
      "0.4416445623342175\n",
      "Epoch 193/1000 - 5.064921s - Loss 2.536850 - Accuracy 0.093750 - Test Loss 1.435828 - Test Accuracy 0.440760\n",
      "Epoch 194/1000 - 5.057720s - Loss 2.567591 - Accuracy 0.151042 - Test Loss 1.432829 - Test Accuracy 0.440318\n",
      "Epoch 195/1000 - 5.073903s - Loss 2.625416 - Accuracy 0.156250 - Test Loss 1.424708 - Test Accuracy 0.442529\n",
      "-----***-----\n",
      "0.4425287356321839\n",
      "Epoch 196/1000 - 5.053854s - Loss 1.935864 - Accuracy 0.171875 - Test Loss 1.414624 - Test Accuracy 0.440760\n",
      "Epoch 197/1000 - 5.046688s - Loss 2.515950 - Accuracy 0.114583 - Test Loss 1.412157 - Test Accuracy 0.443413\n",
      "-----***-----\n",
      "0.4434129089301503\n",
      "Epoch 198/1000 - 5.040672s - Loss 2.678368 - Accuracy 0.156250 - Test Loss 1.404805 - Test Accuracy 0.442971\n",
      "Epoch 199/1000 - 5.042142s - Loss 2.483855 - Accuracy 0.083333 - Test Loss 1.398554 - Test Accuracy 0.444739\n",
      "-----***-----\n",
      "0.4447391688770999\n",
      "Epoch 200/1000 - 5.034655s - Loss 2.341133 - Accuracy 0.187500 - Test Loss 1.387178 - Test Accuracy 0.444297\n",
      "Epoch 201/1000 - 5.082691s - Loss 2.325039 - Accuracy 0.119792 - Test Loss 1.380967 - Test Accuracy 0.442087\n",
      "Epoch 202/1000 - 5.062912s - Loss 2.534929 - Accuracy 0.119792 - Test Loss 1.374915 - Test Accuracy 0.439876\n",
      "Epoch 203/1000 - 5.064450s - Loss 1.947219 - Accuracy 0.203125 - Test Loss 1.367455 - Test Accuracy 0.440318\n",
      "Epoch 204/1000 - 5.047982s - Loss 2.268984 - Accuracy 0.182292 - Test Loss 1.361817 - Test Accuracy 0.439434\n",
      "Epoch 205/1000 - 5.088022s - Loss 2.881440 - Accuracy 0.130208 - Test Loss 1.356907 - Test Accuracy 0.442529\n",
      "Epoch 206/1000 - 5.054824s - Loss 2.533058 - Accuracy 0.145833 - Test Loss 1.351490 - Test Accuracy 0.441202\n",
      "Epoch 207/1000 - 5.051452s - Loss 2.521782 - Accuracy 0.114583 - Test Loss 1.345579 - Test Accuracy 0.439876\n",
      "Epoch 208/1000 - 5.059166s - Loss 1.989921 - Accuracy 0.119792 - Test Loss 1.339572 - Test Accuracy 0.440318\n",
      "Epoch 209/1000 - 5.046901s - Loss 2.158784 - Accuracy 0.161458 - Test Loss 1.331723 - Test Accuracy 0.442529\n",
      "Epoch 210/1000 - 5.052928s - Loss 2.185459 - Accuracy 0.234375 - Test Loss 1.326058 - Test Accuracy 0.441202\n",
      "Epoch 211/1000 - 5.066551s - Loss 2.483511 - Accuracy 0.151042 - Test Loss 1.319854 - Test Accuracy 0.438108\n",
      "Epoch 212/1000 - 5.058594s - Loss 2.666568 - Accuracy 0.182292 - Test Loss 1.316748 - Test Accuracy 0.443413\n",
      "Epoch 213/1000 - 5.057098s - Loss 2.491398 - Accuracy 0.104167 - Test Loss 1.309694 - Test Accuracy 0.440760\n",
      "Epoch 214/1000 - 5.036298s - Loss 1.675642 - Accuracy 0.182292 - Test Loss 1.301104 - Test Accuracy 0.441645\n",
      "Epoch 215/1000 - 5.058013s - Loss 1.994568 - Accuracy 0.177083 - Test Loss 1.294515 - Test Accuracy 0.440318\n",
      "Epoch 216/1000 - 5.042169s - Loss 1.969092 - Accuracy 0.135417 - Test Loss 1.288258 - Test Accuracy 0.440760\n",
      "Epoch 217/1000 - 5.075017s - Loss 2.382582 - Accuracy 0.151042 - Test Loss 1.280295 - Test Accuracy 0.438108\n",
      "Epoch 218/1000 - 5.066385s - Loss 2.548145 - Accuracy 0.151042 - Test Loss 1.276949 - Test Accuracy 0.443855\n",
      "Epoch 219/1000 - 5.048117s - Loss 2.131142 - Accuracy 0.119792 - Test Loss 1.272551 - Test Accuracy 0.447834\n",
      "-----***-----\n",
      "0.4478337754199823\n",
      "Epoch 220/1000 - 5.052845s - Loss 2.017983 - Accuracy 0.171875 - Test Loss 1.266518 - Test Accuracy 0.445181\n",
      "Epoch 221/1000 - 5.096989s - Loss 2.560431 - Accuracy 0.119792 - Test Loss 1.260373 - Test Accuracy 0.443855\n",
      "Epoch 222/1000 - 5.060258s - Loss 2.337664 - Accuracy 0.098958 - Test Loss 1.257647 - Test Accuracy 0.448718\n",
      "-----***-----\n",
      "0.44871794871794873\n",
      "Epoch 223/1000 - 5.063501s - Loss 2.329092 - Accuracy 0.130208 - Test Loss 1.250973 - Test Accuracy 0.450044\n",
      "-----***-----\n",
      "0.4500442086648983\n",
      "Epoch 224/1000 - 5.057892s - Loss 2.138271 - Accuracy 0.125000 - Test Loss 1.242607 - Test Accuracy 0.439876\n",
      "Epoch 225/1000 - 5.084642s - Loss 1.830894 - Accuracy 0.197917 - Test Loss 1.237475 - Test Accuracy 0.445181\n",
      "Epoch 226/1000 - 5.047263s - Loss 1.961138 - Accuracy 0.223958 - Test Loss 1.228999 - Test Accuracy 0.445181\n",
      "Epoch 227/1000 - 5.051273s - Loss 2.011699 - Accuracy 0.182292 - Test Loss 1.223212 - Test Accuracy 0.444297\n",
      "Epoch 228/1000 - 5.054780s - Loss 2.073403 - Accuracy 0.140625 - Test Loss 1.219902 - Test Accuracy 0.443413\n",
      "Epoch 229/1000 - 5.060480s - Loss 2.285358 - Accuracy 0.125000 - Test Loss 1.215418 - Test Accuracy 0.445181\n",
      "Epoch 230/1000 - 5.040779s - Loss 2.150493 - Accuracy 0.145833 - Test Loss 1.209846 - Test Accuracy 0.446508\n",
      "Epoch 231/1000 - 5.039419s - Loss 2.087204 - Accuracy 0.223958 - Test Loss 1.202992 - Test Accuracy 0.447392\n",
      "Epoch 232/1000 - 5.059586s - Loss 2.823143 - Accuracy 0.114583 - Test Loss 1.197303 - Test Accuracy 0.446065\n",
      "Epoch 233/1000 - 5.046702s - Loss 2.330284 - Accuracy 0.140625 - Test Loss 1.193435 - Test Accuracy 0.448276\n",
      "Epoch 234/1000 - 5.057455s - Loss 2.003306 - Accuracy 0.119792 - Test Loss 1.187048 - Test Accuracy 0.446508\n",
      "Epoch 235/1000 - 5.056200s - Loss 1.659302 - Accuracy 0.244792 - Test Loss 1.179762 - Test Accuracy 0.449160\n",
      "Epoch 236/1000 - 5.046860s - Loss 1.794959 - Accuracy 0.156250 - Test Loss 1.177305 - Test Accuracy 0.449602\n",
      "Epoch 237/1000 - 5.060971s - Loss 2.391032 - Accuracy 0.135417 - Test Loss 1.173218 - Test Accuracy 0.448718\n",
      "Epoch 238/1000 - 5.046194s - Loss 1.749318 - Accuracy 0.166667 - Test Loss 1.168227 - Test Accuracy 0.446950\n",
      "Epoch 239/1000 - 5.085004s - Loss 1.793002 - Accuracy 0.244792 - Test Loss 1.162484 - Test Accuracy 0.447834\n",
      "Epoch 240/1000 - 5.054602s - Loss 1.927520 - Accuracy 0.130208 - Test Loss 1.155858 - Test Accuracy 0.448718\n",
      "Epoch 241/1000 - 5.079769s - Loss 1.967604 - Accuracy 0.244792 - Test Loss 1.151149 - Test Accuracy 0.448718\n",
      "Epoch 242/1000 - 5.054157s - Loss 1.650460 - Accuracy 0.171875 - Test Loss 1.144049 - Test Accuracy 0.447834\n",
      "Epoch 243/1000 - 5.075848s - Loss 1.794617 - Accuracy 0.135417 - Test Loss 1.140436 - Test Accuracy 0.449160\n",
      "Epoch 244/1000 - 5.067598s - Loss 2.255839 - Accuracy 0.135417 - Test Loss 1.135675 - Test Accuracy 0.448718\n",
      "Epoch 245/1000 - 5.076755s - Loss 2.114732 - Accuracy 0.151042 - Test Loss 1.129333 - Test Accuracy 0.446508\n",
      "Epoch 246/1000 - 5.066455s - Loss 1.896523 - Accuracy 0.187500 - Test Loss 1.124706 - Test Accuracy 0.446065\n",
      "Epoch 247/1000 - 5.094150s - Loss 2.271526 - Accuracy 0.119792 - Test Loss 1.117762 - Test Accuracy 0.447834\n",
      "Epoch 248/1000 - 5.083941s - Loss 1.535557 - Accuracy 0.161458 - Test Loss 1.113487 - Test Accuracy 0.450044\n",
      "Epoch 249/1000 - 5.064647s - Loss 1.738077 - Accuracy 0.171875 - Test Loss 1.107585 - Test Accuracy 0.449160\n",
      "Epoch 250/1000 - 5.076411s - Loss 1.886420 - Accuracy 0.140625 - Test Loss 1.104728 - Test Accuracy 0.449602\n",
      "Epoch 251/1000 - 5.056377s - Loss 2.199591 - Accuracy 0.130208 - Test Loss 1.101588 - Test Accuracy 0.446065\n",
      "Epoch 252/1000 - 5.061578s - Loss 1.939563 - Accuracy 0.177083 - Test Loss 1.095228 - Test Accuracy 0.444739\n",
      "Epoch 253/1000 - 5.058122s - Loss 2.116750 - Accuracy 0.114583 - Test Loss 1.089968 - Test Accuracy 0.448276\n",
      "Epoch 254/1000 - 5.061205s - Loss 1.775918 - Accuracy 0.177083 - Test Loss 1.086082 - Test Accuracy 0.451813\n",
      "-----***-----\n",
      "0.45181255526083114\n",
      "Epoch 255/1000 - 5.065833s - Loss 1.825692 - Accuracy 0.109375 - Test Loss 1.083454 - Test Accuracy 0.452697\n",
      "-----***-----\n",
      "0.4526967285587975\n",
      "Epoch 256/1000 - 5.086727s - Loss 1.732757 - Accuracy 0.203125 - Test Loss 1.077451 - Test Accuracy 0.452255\n",
      "Epoch 257/1000 - 5.051130s - Loss 1.709422 - Accuracy 0.130208 - Test Loss 1.074800 - Test Accuracy 0.454023\n",
      "-----***-----\n",
      "0.4540229885057471\n",
      "Epoch 258/1000 - 5.090279s - Loss 1.423459 - Accuracy 0.239583 - Test Loss 1.069265 - Test Accuracy 0.452255\n",
      "Epoch 259/1000 - 5.041468s - Loss 1.832909 - Accuracy 0.182292 - Test Loss 1.066116 - Test Accuracy 0.452255\n",
      "Epoch 260/1000 - 5.078501s - Loss 1.702247 - Accuracy 0.140625 - Test Loss 1.061578 - Test Accuracy 0.454023\n",
      "Epoch 261/1000 - 5.075079s - Loss 1.691034 - Accuracy 0.151042 - Test Loss 1.056326 - Test Accuracy 0.454465\n",
      "-----***-----\n",
      "0.45446507515473034\n",
      "Epoch 262/1000 - 5.050832s - Loss 2.105373 - Accuracy 0.156250 - Test Loss 1.052148 - Test Accuracy 0.454023\n",
      "Epoch 263/1000 - 5.052138s - Loss 2.028586 - Accuracy 0.218750 - Test Loss 1.046994 - Test Accuracy 0.454907\n",
      "-----***-----\n",
      "0.45490716180371354\n",
      "Epoch 264/1000 - 5.039148s - Loss 2.183125 - Accuracy 0.130208 - Test Loss 1.042917 - Test Accuracy 0.451813\n",
      "Epoch 265/1000 - 5.049272s - Loss 1.504914 - Accuracy 0.171875 - Test Loss 1.037786 - Test Accuracy 0.454023\n",
      "Epoch 266/1000 - 5.043923s - Loss 1.266675 - Accuracy 0.234375 - Test Loss 1.035089 - Test Accuracy 0.457560\n",
      "-----***-----\n",
      "0.45755968169761274\n",
      "Epoch 267/1000 - 5.051697s - Loss 1.659735 - Accuracy 0.203125 - Test Loss 1.031458 - Test Accuracy 0.458444\n",
      "-----***-----\n",
      "0.45844385499557916\n",
      "Epoch 268/1000 - 5.085665s - Loss 1.884133 - Accuracy 0.135417 - Test Loss 1.026926 - Test Accuracy 0.453139\n",
      "Epoch 269/1000 - 5.075940s - Loss 1.631738 - Accuracy 0.166667 - Test Loss 1.023012 - Test Accuracy 0.456676\n",
      "Epoch 270/1000 - 5.062858s - Loss 1.220354 - Accuracy 0.229167 - Test Loss 1.016516 - Test Accuracy 0.454465\n",
      "Epoch 271/1000 - 5.046971s - Loss 1.687873 - Accuracy 0.171875 - Test Loss 1.013586 - Test Accuracy 0.456676\n",
      "Epoch 272/1000 - 5.064982s - Loss 1.693405 - Accuracy 0.166667 - Test Loss 1.009884 - Test Accuracy 0.457560\n",
      "Epoch 273/1000 - 5.053599s - Loss 1.357326 - Accuracy 0.213542 - Test Loss 1.005008 - Test Accuracy 0.458886\n",
      "-----***-----\n",
      "0.4588859416445623\n",
      "Epoch 274/1000 - 5.048677s - Loss 1.710992 - Accuracy 0.156250 - Test Loss 1.001480 - Test Accuracy 0.461096\n",
      "-----***-----\n",
      "0.46109637488947836\n",
      "Epoch 275/1000 - 5.049652s - Loss 1.945956 - Accuracy 0.156250 - Test Loss 0.995899 - Test Accuracy 0.457118\n",
      "Epoch 276/1000 - 5.046614s - Loss 1.140603 - Accuracy 0.276042 - Test Loss 0.990308 - Test Accuracy 0.457560\n",
      "Epoch 277/1000 - 5.055973s - Loss 1.613365 - Accuracy 0.166667 - Test Loss 0.986238 - Test Accuracy 0.457118\n",
      "Epoch 278/1000 - 5.056076s - Loss 1.788282 - Accuracy 0.192708 - Test Loss 0.982026 - Test Accuracy 0.455791\n",
      "Epoch 279/1000 - 5.043375s - Loss 1.375337 - Accuracy 0.213542 - Test Loss 0.978263 - Test Accuracy 0.456233\n",
      "Epoch 280/1000 - 5.070999s - Loss 1.425277 - Accuracy 0.229167 - Test Loss 0.973618 - Test Accuracy 0.457118\n",
      "Epoch 281/1000 - 5.053201s - Loss 1.600735 - Accuracy 0.140625 - Test Loss 0.970683 - Test Accuracy 0.458002\n",
      "Epoch 282/1000 - 5.071791s - Loss 1.469269 - Accuracy 0.255208 - Test Loss 0.967782 - Test Accuracy 0.458444\n",
      "Epoch 283/1000 - 5.051805s - Loss 1.427343 - Accuracy 0.223958 - Test Loss 0.962853 - Test Accuracy 0.457118\n",
      "Epoch 284/1000 - 5.073245s - Loss 1.753536 - Accuracy 0.135417 - Test Loss 0.960639 - Test Accuracy 0.458444\n",
      "Epoch 285/1000 - 5.052398s - Loss 1.605036 - Accuracy 0.161458 - Test Loss 0.956228 - Test Accuracy 0.458002\n",
      "Epoch 286/1000 - 5.061305s - Loss 1.659652 - Accuracy 0.156250 - Test Loss 0.950803 - Test Accuracy 0.460212\n",
      "Epoch 287/1000 - 5.051783s - Loss 1.458142 - Accuracy 0.182292 - Test Loss 0.947584 - Test Accuracy 0.460654\n",
      "Epoch 288/1000 - 5.061775s - Loss 1.831581 - Accuracy 0.145833 - Test Loss 0.944356 - Test Accuracy 0.459328\n",
      "Epoch 289/1000 - 5.049866s - Loss 1.421006 - Accuracy 0.197917 - Test Loss 0.940489 - Test Accuracy 0.459770\n",
      "Epoch 290/1000 - 5.060957s - Loss 1.649499 - Accuracy 0.197917 - Test Loss 0.936041 - Test Accuracy 0.459328\n",
      "Epoch 291/1000 - 5.060632s - Loss 1.817848 - Accuracy 0.161458 - Test Loss 0.931365 - Test Accuracy 0.460654\n",
      "Epoch 292/1000 - 5.062203s - Loss 1.454524 - Accuracy 0.182292 - Test Loss 0.927619 - Test Accuracy 0.461096\n",
      "Epoch 293/1000 - 5.072340s - Loss 1.384521 - Accuracy 0.208333 - Test Loss 0.924110 - Test Accuracy 0.459328\n",
      "Epoch 294/1000 - 5.051623s - Loss 1.278900 - Accuracy 0.140625 - Test Loss 0.921046 - Test Accuracy 0.454465\n",
      "Epoch 295/1000 - 5.059783s - Loss 1.129598 - Accuracy 0.244792 - Test Loss 0.917452 - Test Accuracy 0.458444\n",
      "Epoch 296/1000 - 5.055292s - Loss 1.137071 - Accuracy 0.229167 - Test Loss 0.914162 - Test Accuracy 0.459770\n",
      "Epoch 297/1000 - 5.045658s - Loss 1.708872 - Accuracy 0.119792 - Test Loss 0.910887 - Test Accuracy 0.458002\n",
      "Epoch 298/1000 - 5.063786s - Loss 1.371580 - Accuracy 0.161458 - Test Loss 0.907889 - Test Accuracy 0.460212\n",
      "Epoch 299/1000 - 5.054754s - Loss 1.535439 - Accuracy 0.192708 - Test Loss 0.906275 - Test Accuracy 0.461538\n",
      "-----***-----\n",
      "0.46153846153846156\n",
      "Epoch 300/1000 - 5.070454s - Loss 1.337251 - Accuracy 0.203125 - Test Loss 0.901349 - Test Accuracy 0.460654\n",
      "Epoch 301/1000 - 5.058039s - Loss 1.172531 - Accuracy 0.182292 - Test Loss 0.897870 - Test Accuracy 0.460654\n",
      "Epoch 302/1000 - 5.045609s - Loss 1.619182 - Accuracy 0.140625 - Test Loss 0.894088 - Test Accuracy 0.461096\n",
      "Epoch 303/1000 - 5.054381s - Loss 1.313322 - Accuracy 0.192708 - Test Loss 0.891924 - Test Accuracy 0.461096\n",
      "Epoch 304/1000 - 5.051566s - Loss 1.429702 - Accuracy 0.171875 - Test Loss 0.888399 - Test Accuracy 0.463749\n",
      "-----***-----\n",
      "0.46374889478337755\n",
      "Epoch 305/1000 - 5.067125s - Loss 1.167535 - Accuracy 0.213542 - Test Loss 0.886369 - Test Accuracy 0.461096\n",
      "Epoch 306/1000 - 5.064226s - Loss 1.342843 - Accuracy 0.229167 - Test Loss 0.883293 - Test Accuracy 0.461981\n",
      "Epoch 307/1000 - 5.054495s - Loss 1.376480 - Accuracy 0.192708 - Test Loss 0.878651 - Test Accuracy 0.461538\n",
      "Epoch 308/1000 - 5.056404s - Loss 1.537059 - Accuracy 0.166667 - Test Loss 0.874963 - Test Accuracy 0.464191\n",
      "-----***-----\n",
      "0.46419098143236076\n",
      "Epoch 309/1000 - 5.050431s - Loss 1.317388 - Accuracy 0.203125 - Test Loss 0.871734 - Test Accuracy 0.461096\n",
      "Epoch 310/1000 - 5.068303s - Loss 1.391345 - Accuracy 0.177083 - Test Loss 0.867477 - Test Accuracy 0.464633\n",
      "-----***-----\n",
      "0.46463306808134397\n",
      "Epoch 311/1000 - 5.045824s - Loss 1.224843 - Accuracy 0.250000 - Test Loss 0.863395 - Test Accuracy 0.465075\n",
      "-----***-----\n",
      "0.4650751547303271\n",
      "Epoch 312/1000 - 5.067831s - Loss 1.053401 - Accuracy 0.255208 - Test Loss 0.860164 - Test Accuracy 0.467286\n",
      "-----***-----\n",
      "0.46728558797524317\n",
      "Epoch 313/1000 - 5.045458s - Loss 1.829325 - Accuracy 0.192708 - Test Loss 0.857941 - Test Accuracy 0.467286\n",
      "Epoch 314/1000 - 5.070783s - Loss 1.275945 - Accuracy 0.218750 - Test Loss 0.853665 - Test Accuracy 0.465517\n",
      "Epoch 315/1000 - 5.054619s - Loss 1.244285 - Accuracy 0.234375 - Test Loss 0.850978 - Test Accuracy 0.467728\n",
      "-----***-----\n",
      "0.4677276746242264\n",
      "Epoch 316/1000 - 5.052789s - Loss 1.256285 - Accuracy 0.239583 - Test Loss 0.847221 - Test Accuracy 0.465517\n",
      "Epoch 317/1000 - 5.054820s - Loss 0.988458 - Accuracy 0.265625 - Test Loss 0.844648 - Test Accuracy 0.465517\n",
      "Epoch 318/1000 - 5.086318s - Loss 1.630810 - Accuracy 0.114583 - Test Loss 0.842189 - Test Accuracy 0.461981\n",
      "Epoch 319/1000 - 5.039280s - Loss 1.416603 - Accuracy 0.260417 - Test Loss 0.837470 - Test Accuracy 0.468612\n",
      "-----***-----\n",
      "0.46861184792219274\n",
      "Epoch 320/1000 - 5.066545s - Loss 1.051823 - Accuracy 0.296875 - Test Loss 0.834549 - Test Accuracy 0.469054\n",
      "-----***-----\n",
      "0.46905393457117595\n",
      "Epoch 321/1000 - 5.072056s - Loss 1.184569 - Accuracy 0.223958 - Test Loss 0.832405 - Test Accuracy 0.469938\n",
      "-----***-----\n",
      "0.46993810786914236\n",
      "Epoch 322/1000 - 5.074164s - Loss 1.128630 - Accuracy 0.208333 - Test Loss 0.829564 - Test Accuracy 0.470822\n",
      "-----***-----\n",
      "0.4708222811671088\n",
      "Epoch 323/1000 - 5.068732s - Loss 1.388594 - Accuracy 0.203125 - Test Loss 0.828071 - Test Accuracy 0.467286\n",
      "Epoch 324/1000 - 5.102012s - Loss 1.045517 - Accuracy 0.203125 - Test Loss 0.825984 - Test Accuracy 0.466844\n",
      "Epoch 325/1000 - 5.108384s - Loss 1.323940 - Accuracy 0.250000 - Test Loss 0.822462 - Test Accuracy 0.467728\n",
      "Epoch 326/1000 - 5.073524s - Loss 1.364677 - Accuracy 0.286458 - Test Loss 0.819127 - Test Accuracy 0.469496\n",
      "Epoch 327/1000 - 5.048757s - Loss 1.093802 - Accuracy 0.203125 - Test Loss 0.814444 - Test Accuracy 0.467728\n",
      "Epoch 328/1000 - 5.039208s - Loss 1.142501 - Accuracy 0.255208 - Test Loss 0.812230 - Test Accuracy 0.472591\n",
      "-----***-----\n",
      "0.47259062776304156\n",
      "Epoch 329/1000 - 5.041081s - Loss 1.137406 - Accuracy 0.223958 - Test Loss 0.809371 - Test Accuracy 0.470380\n",
      "Epoch 330/1000 - 5.034242s - Loss 1.404626 - Accuracy 0.177083 - Test Loss 0.808869 - Test Accuracy 0.469938\n",
      "Epoch 331/1000 - 5.046658s - Loss 1.124551 - Accuracy 0.270833 - Test Loss 0.806035 - Test Accuracy 0.473033\n",
      "-----***-----\n",
      "0.47303271441202477\n",
      "Epoch 332/1000 - 5.054620s - Loss 1.124123 - Accuracy 0.229167 - Test Loss 0.801039 - Test Accuracy 0.471264\n",
      "Epoch 333/1000 - 5.056632s - Loss 1.001454 - Accuracy 0.177083 - Test Loss 0.800428 - Test Accuracy 0.469938\n",
      "Epoch 334/1000 - 5.045522s - Loss 1.113827 - Accuracy 0.250000 - Test Loss 0.797479 - Test Accuracy 0.469938\n",
      "Epoch 335/1000 - 5.039603s - Loss 1.241181 - Accuracy 0.255208 - Test Loss 0.796126 - Test Accuracy 0.470822\n",
      "Epoch 336/1000 - 5.031893s - Loss 1.089893 - Accuracy 0.234375 - Test Loss 0.792948 - Test Accuracy 0.469054\n",
      "Epoch 337/1000 - 5.064198s - Loss 1.286717 - Accuracy 0.187500 - Test Loss 0.791745 - Test Accuracy 0.470380\n",
      "Epoch 338/1000 - 5.041988s - Loss 1.086011 - Accuracy 0.265625 - Test Loss 0.787169 - Test Accuracy 0.471264\n",
      "Epoch 339/1000 - 5.082697s - Loss 1.331797 - Accuracy 0.229167 - Test Loss 0.784471 - Test Accuracy 0.473033\n",
      "Epoch 340/1000 - 5.035777s - Loss 1.199564 - Accuracy 0.213542 - Test Loss 0.781929 - Test Accuracy 0.473917\n",
      "-----***-----\n",
      "0.4739168877099912\n",
      "Epoch 341/1000 - 5.060610s - Loss 1.154629 - Accuracy 0.192708 - Test Loss 0.779198 - Test Accuracy 0.474801\n",
      "-----***-----\n",
      "0.47480106100795755\n",
      "Epoch 342/1000 - 5.039542s - Loss 1.124351 - Accuracy 0.250000 - Test Loss 0.777309 - Test Accuracy 0.477011\n",
      "-----***-----\n",
      "0.47701149425287354\n",
      "Epoch 343/1000 - 5.074062s - Loss 1.153100 - Accuracy 0.276042 - Test Loss 0.774760 - Test Accuracy 0.476127\n",
      "Epoch 344/1000 - 5.040025s - Loss 0.956830 - Accuracy 0.312500 - Test Loss 0.771115 - Test Accuracy 0.474359\n",
      "Epoch 345/1000 - 5.036354s - Loss 1.212125 - Accuracy 0.223958 - Test Loss 0.768733 - Test Accuracy 0.476569\n",
      "Epoch 346/1000 - 5.030047s - Loss 1.280355 - Accuracy 0.260417 - Test Loss 0.767906 - Test Accuracy 0.479222\n",
      "-----***-----\n",
      "0.4792219274977896\n",
      "Epoch 347/1000 - 5.049217s - Loss 1.034050 - Accuracy 0.208333 - Test Loss 0.763881 - Test Accuracy 0.479222\n",
      "Epoch 348/1000 - 5.040245s - Loss 1.149007 - Accuracy 0.192708 - Test Loss 0.761415 - Test Accuracy 0.479664\n",
      "-----***-----\n",
      "0.4796640141467728\n",
      "Epoch 349/1000 - 5.037236s - Loss 0.960453 - Accuracy 0.270833 - Test Loss 0.758870 - Test Accuracy 0.478338\n",
      "Epoch 350/1000 - 5.039560s - Loss 0.745777 - Accuracy 0.395833 - Test Loss 0.755756 - Test Accuracy 0.477454\n",
      "Epoch 351/1000 - 5.052490s - Loss 0.874174 - Accuracy 0.281250 - Test Loss 0.752180 - Test Accuracy 0.480106\n",
      "-----***-----\n",
      "0.48010610079575594\n",
      "Epoch 352/1000 - 5.034697s - Loss 0.810513 - Accuracy 0.333333 - Test Loss 0.751304 - Test Accuracy 0.474801\n",
      "Epoch 353/1000 - 5.056103s - Loss 0.879054 - Accuracy 0.291667 - Test Loss 0.749264 - Test Accuracy 0.477896\n",
      "Epoch 354/1000 - 5.034408s - Loss 1.155565 - Accuracy 0.203125 - Test Loss 0.746563 - Test Accuracy 0.474801\n",
      "Epoch 355/1000 - 5.054549s - Loss 1.113401 - Accuracy 0.255208 - Test Loss 0.744459 - Test Accuracy 0.476127\n",
      "Epoch 356/1000 - 5.043324s - Loss 0.944811 - Accuracy 0.286458 - Test Loss 0.740951 - Test Accuracy 0.479222\n",
      "Epoch 357/1000 - 5.033820s - Loss 1.197055 - Accuracy 0.229167 - Test Loss 0.739063 - Test Accuracy 0.477011\n",
      "Epoch 358/1000 - 5.036462s - Loss 1.093189 - Accuracy 0.276042 - Test Loss 0.736708 - Test Accuracy 0.474801\n",
      "Epoch 359/1000 - 5.054945s - Loss 0.870419 - Accuracy 0.250000 - Test Loss 0.733931 - Test Accuracy 0.473917\n",
      "Epoch 360/1000 - 5.043993s - Loss 1.175655 - Accuracy 0.213542 - Test Loss 0.732590 - Test Accuracy 0.477454\n",
      "Epoch 361/1000 - 5.060476s - Loss 0.751880 - Accuracy 0.276042 - Test Loss 0.730203 - Test Accuracy 0.474359\n",
      "Epoch 362/1000 - 5.035959s - Loss 1.058953 - Accuracy 0.203125 - Test Loss 0.728380 - Test Accuracy 0.473475\n",
      "Epoch 363/1000 - 5.066232s - Loss 1.049771 - Accuracy 0.203125 - Test Loss 0.727469 - Test Accuracy 0.477896\n",
      "Epoch 364/1000 - 5.055916s - Loss 0.923477 - Accuracy 0.229167 - Test Loss 0.724862 - Test Accuracy 0.477011\n",
      "Epoch 365/1000 - 5.069182s - Loss 1.000712 - Accuracy 0.281250 - Test Loss 0.724351 - Test Accuracy 0.477011\n",
      "Epoch 366/1000 - 5.039291s - Loss 0.926206 - Accuracy 0.223958 - Test Loss 0.720886 - Test Accuracy 0.479664\n",
      "Epoch 367/1000 - 5.062098s - Loss 1.021803 - Accuracy 0.197917 - Test Loss 0.720204 - Test Accuracy 0.480990\n",
      "-----***-----\n",
      "0.48099027409372236\n",
      "Epoch 368/1000 - 5.044360s - Loss 1.130308 - Accuracy 0.208333 - Test Loss 0.718742 - Test Accuracy 0.481432\n",
      "-----***-----\n",
      "0.48143236074270557\n",
      "Epoch 369/1000 - 5.055893s - Loss 1.288818 - Accuracy 0.171875 - Test Loss 0.716886 - Test Accuracy 0.480990\n",
      "Epoch 370/1000 - 5.048371s - Loss 1.053528 - Accuracy 0.281250 - Test Loss 0.714684 - Test Accuracy 0.483643\n",
      "-----***-----\n",
      "0.48364279398762156\n",
      "Epoch 371/1000 - 5.077695s - Loss 0.907229 - Accuracy 0.260417 - Test Loss 0.711464 - Test Accuracy 0.482317\n",
      "Epoch 372/1000 - 5.056124s - Loss 0.931466 - Accuracy 0.265625 - Test Loss 0.709629 - Test Accuracy 0.481432\n",
      "Epoch 373/1000 - 5.055959s - Loss 1.003863 - Accuracy 0.229167 - Test Loss 0.707265 - Test Accuracy 0.478780\n",
      "Epoch 374/1000 - 5.046753s - Loss 0.902502 - Accuracy 0.244792 - Test Loss 0.705844 - Test Accuracy 0.479664\n",
      "Epoch 375/1000 - 5.052750s - Loss 0.759655 - Accuracy 0.265625 - Test Loss 0.702999 - Test Accuracy 0.480990\n",
      "Epoch 376/1000 - 5.049480s - Loss 1.142061 - Accuracy 0.244792 - Test Loss 0.701055 - Test Accuracy 0.478338\n",
      "Epoch 377/1000 - 5.072736s - Loss 0.863325 - Accuracy 0.296875 - Test Loss 0.698301 - Test Accuracy 0.480106\n",
      "Epoch 378/1000 - 5.054373s - Loss 0.759808 - Accuracy 0.255208 - Test Loss 0.696728 - Test Accuracy 0.481874\n",
      "Epoch 379/1000 - 5.060960s - Loss 0.936216 - Accuracy 0.213542 - Test Loss 0.694873 - Test Accuracy 0.481432\n",
      "Epoch 380/1000 - 5.056750s - Loss 0.915734 - Accuracy 0.250000 - Test Loss 0.694242 - Test Accuracy 0.482759\n",
      "Epoch 381/1000 - 5.068125s - Loss 0.945464 - Accuracy 0.239583 - Test Loss 0.691985 - Test Accuracy 0.481874\n",
      "Epoch 382/1000 - 5.053240s - Loss 0.917248 - Accuracy 0.296875 - Test Loss 0.690127 - Test Accuracy 0.482317\n",
      "Epoch 383/1000 - 5.055971s - Loss 1.006628 - Accuracy 0.234375 - Test Loss 0.687710 - Test Accuracy 0.483201\n",
      "Epoch 384/1000 - 5.046987s - Loss 1.020944 - Accuracy 0.177083 - Test Loss 0.686334 - Test Accuracy 0.484085\n",
      "-----***-----\n",
      "0.48408488063660476\n",
      "Epoch 385/1000 - 5.065713s - Loss 0.950046 - Accuracy 0.260417 - Test Loss 0.685039 - Test Accuracy 0.485853\n",
      "-----***-----\n",
      "0.4858532272325376\n",
      "Epoch 386/1000 - 5.047170s - Loss 0.976923 - Accuracy 0.281250 - Test Loss 0.682730 - Test Accuracy 0.484085\n",
      "Epoch 387/1000 - 5.043682s - Loss 0.846628 - Accuracy 0.213542 - Test Loss 0.681192 - Test Accuracy 0.484085\n",
      "Epoch 388/1000 - 5.038403s - Loss 0.888180 - Accuracy 0.276042 - Test Loss 0.679973 - Test Accuracy 0.485411\n",
      "Epoch 389/1000 - 5.071573s - Loss 0.819600 - Accuracy 0.328125 - Test Loss 0.677940 - Test Accuracy 0.484527\n",
      "Epoch 390/1000 - 5.057125s - Loss 0.827588 - Accuracy 0.239583 - Test Loss 0.676916 - Test Accuracy 0.487179\n",
      "-----***-----\n",
      "0.48717948717948717\n",
      "Epoch 391/1000 - 5.063486s - Loss 0.871369 - Accuracy 0.239583 - Test Loss 0.674992 - Test Accuracy 0.488948\n",
      "-----***-----\n",
      "0.48894783377542\n",
      "Epoch 392/1000 - 5.049832s - Loss 0.753297 - Accuracy 0.333333 - Test Loss 0.672805 - Test Accuracy 0.489390\n",
      "-----***-----\n",
      "0.48938992042440316\n",
      "Epoch 393/1000 - 5.050510s - Loss 0.839541 - Accuracy 0.281250 - Test Loss 0.670614 - Test Accuracy 0.488948\n",
      "Epoch 394/1000 - 5.048609s - Loss 0.808406 - Accuracy 0.270833 - Test Loss 0.668562 - Test Accuracy 0.486295\n",
      "Epoch 395/1000 - 5.056900s - Loss 0.931577 - Accuracy 0.213542 - Test Loss 0.667803 - Test Accuracy 0.488064\n",
      "Epoch 396/1000 - 5.049332s - Loss 0.783338 - Accuracy 0.317708 - Test Loss 0.665300 - Test Accuracy 0.488948\n",
      "Epoch 397/1000 - 5.063308s - Loss 0.853479 - Accuracy 0.343750 - Test Loss 0.664228 - Test Accuracy 0.487622\n",
      "Epoch 398/1000 - 5.063308s - Loss 0.725889 - Accuracy 0.270833 - Test Loss 0.662372 - Test Accuracy 0.488064\n",
      "Epoch 399/1000 - 5.054042s - Loss 0.926730 - Accuracy 0.276042 - Test Loss 0.660021 - Test Accuracy 0.487622\n",
      "Epoch 400/1000 - 5.047539s - Loss 0.761397 - Accuracy 0.348958 - Test Loss 0.658309 - Test Accuracy 0.487179\n",
      "Epoch 401/1000 - 5.049929s - Loss 0.879743 - Accuracy 0.260417 - Test Loss 0.657563 - Test Accuracy 0.488506\n",
      "Epoch 402/1000 - 5.046310s - Loss 0.983314 - Accuracy 0.218750 - Test Loss 0.656401 - Test Accuracy 0.490274\n",
      "-----***-----\n",
      "0.4902740937223696\n",
      "Epoch 403/1000 - 5.067564s - Loss 0.877332 - Accuracy 0.255208 - Test Loss 0.654982 - Test Accuracy 0.491600\n",
      "-----***-----\n",
      "0.4916003536693192\n",
      "Epoch 404/1000 - 5.050481s - Loss 0.794517 - Accuracy 0.229167 - Test Loss 0.652710 - Test Accuracy 0.490716\n",
      "Epoch 405/1000 - 5.049084s - Loss 0.903677 - Accuracy 0.296875 - Test Loss 0.651977 - Test Accuracy 0.489832\n",
      "Epoch 406/1000 - 5.050021s - Loss 0.766930 - Accuracy 0.265625 - Test Loss 0.648793 - Test Accuracy 0.491158\n",
      "Epoch 407/1000 - 5.050943s - Loss 0.892604 - Accuracy 0.250000 - Test Loss 0.647586 - Test Accuracy 0.490716\n",
      "Epoch 408/1000 - 5.046246s - Loss 0.881153 - Accuracy 0.260417 - Test Loss 0.647074 - Test Accuracy 0.490274\n",
      "Epoch 409/1000 - 5.062776s - Loss 0.822229 - Accuracy 0.255208 - Test Loss 0.645752 - Test Accuracy 0.492485\n",
      "-----***-----\n",
      "0.49248452696728556\n",
      "Epoch 410/1000 - 5.061496s - Loss 0.756552 - Accuracy 0.322917 - Test Loss 0.645015 - Test Accuracy 0.495137\n",
      "-----***-----\n",
      "0.4951370468611848\n",
      "Epoch 411/1000 - 5.050905s - Loss 0.987760 - Accuracy 0.213542 - Test Loss 0.643181 - Test Accuracy 0.492927\n",
      "Epoch 412/1000 - 5.041687s - Loss 0.654706 - Accuracy 0.296875 - Test Loss 0.640653 - Test Accuracy 0.494253\n",
      "Epoch 413/1000 - 5.065533s - Loss 0.730599 - Accuracy 0.338542 - Test Loss 0.639585 - Test Accuracy 0.496905\n",
      "-----***-----\n",
      "0.4969053934571176\n",
      "Epoch 414/1000 - 5.059619s - Loss 0.710179 - Accuracy 0.338542 - Test Loss 0.637994 - Test Accuracy 0.495137\n",
      "Epoch 415/1000 - 5.091381s - Loss 0.959449 - Accuracy 0.291667 - Test Loss 0.637612 - Test Accuracy 0.496463\n",
      "Epoch 416/1000 - 5.042228s - Loss 0.759552 - Accuracy 0.270833 - Test Loss 0.635719 - Test Accuracy 0.497790\n",
      "-----***-----\n",
      "0.497789566755084\n",
      "Epoch 417/1000 - 5.050112s - Loss 0.892493 - Accuracy 0.218750 - Test Loss 0.634987 - Test Accuracy 0.498232\n",
      "-----***-----\n",
      "0.4982316534040672\n",
      "Epoch 418/1000 - 5.053513s - Loss 0.805902 - Accuracy 0.265625 - Test Loss 0.632893 - Test Accuracy 0.497790\n",
      "Epoch 419/1000 - 5.048699s - Loss 0.716200 - Accuracy 0.380208 - Test Loss 0.631281 - Test Accuracy 0.497347\n",
      "Epoch 420/1000 - 5.053795s - Loss 0.683573 - Accuracy 0.281250 - Test Loss 0.630256 - Test Accuracy 0.499116\n",
      "-----***-----\n",
      "0.4991158267020336\n",
      "Epoch 421/1000 - 5.045442s - Loss 0.739377 - Accuracy 0.395833 - Test Loss 0.628859 - Test Accuracy 0.499558\n",
      "-----***-----\n",
      "0.4995579133510168\n",
      "Epoch 422/1000 - 5.052373s - Loss 0.779604 - Accuracy 0.322917 - Test Loss 0.629186 - Test Accuracy 0.500442\n",
      "-----***-----\n",
      "0.5004420866489832\n",
      "Epoch 423/1000 - 5.049083s - Loss 1.082497 - Accuracy 0.223958 - Test Loss 0.627700 - Test Accuracy 0.500000\n",
      "Epoch 424/1000 - 5.074644s - Loss 0.649969 - Accuracy 0.322917 - Test Loss 0.625206 - Test Accuracy 0.498674\n",
      "Epoch 425/1000 - 5.047913s - Loss 0.863648 - Accuracy 0.244792 - Test Loss 0.624361 - Test Accuracy 0.499558\n",
      "Epoch 426/1000 - 5.088862s - Loss 0.624617 - Accuracy 0.286458 - Test Loss 0.621881 - Test Accuracy 0.499558\n",
      "Epoch 427/1000 - 5.040824s - Loss 0.844038 - Accuracy 0.307292 - Test Loss 0.621681 - Test Accuracy 0.499116\n",
      "Epoch 428/1000 - 5.083633s - Loss 0.649836 - Accuracy 0.338542 - Test Loss 0.619417 - Test Accuracy 0.499558\n",
      "Epoch 429/1000 - 5.048819s - Loss 0.753293 - Accuracy 0.270833 - Test Loss 0.618861 - Test Accuracy 0.500442\n",
      "Epoch 430/1000 - 5.071449s - Loss 0.815861 - Accuracy 0.218750 - Test Loss 0.617937 - Test Accuracy 0.499558\n",
      "Epoch 431/1000 - 5.050488s - Loss 0.877291 - Accuracy 0.197917 - Test Loss 0.616942 - Test Accuracy 0.500884\n",
      "-----***-----\n",
      "0.5008841732979664\n",
      "Epoch 432/1000 - 5.051596s - Loss 0.767174 - Accuracy 0.213542 - Test Loss 0.614890 - Test Accuracy 0.501326\n",
      "-----***-----\n",
      "0.5013262599469496\n",
      "Epoch 433/1000 - 5.077785s - Loss 0.831577 - Accuracy 0.234375 - Test Loss 0.614048 - Test Accuracy 0.501326\n",
      "Epoch 434/1000 - 5.060489s - Loss 0.809219 - Accuracy 0.312500 - Test Loss 0.612255 - Test Accuracy 0.500884\n",
      "Epoch 435/1000 - 5.042530s - Loss 0.638642 - Accuracy 0.364583 - Test Loss 0.610509 - Test Accuracy 0.500884\n",
      "Epoch 436/1000 - 5.042544s - Loss 0.748080 - Accuracy 0.281250 - Test Loss 0.609125 - Test Accuracy 0.500884\n",
      "Epoch 437/1000 - 5.036819s - Loss 0.795251 - Accuracy 0.354167 - Test Loss 0.608241 - Test Accuracy 0.500884\n",
      "Epoch 438/1000 - 5.061191s - Loss 0.747529 - Accuracy 0.260417 - Test Loss 0.606309 - Test Accuracy 0.500442\n",
      "Epoch 439/1000 - 5.048780s - Loss 0.921327 - Accuracy 0.203125 - Test Loss 0.605692 - Test Accuracy 0.503979\n",
      "-----***-----\n",
      "0.5039787798408488\n",
      "Epoch 440/1000 - 5.052641s - Loss 0.622167 - Accuracy 0.380208 - Test Loss 0.604066 - Test Accuracy 0.501768\n",
      "Epoch 441/1000 - 5.044511s - Loss 0.716291 - Accuracy 0.343750 - Test Loss 0.602076 - Test Accuracy 0.500442\n",
      "Epoch 442/1000 - 5.069548s - Loss 0.739035 - Accuracy 0.291667 - Test Loss 0.601181 - Test Accuracy 0.500884\n",
      "Epoch 443/1000 - 5.041095s - Loss 0.895285 - Accuracy 0.208333 - Test Loss 0.599484 - Test Accuracy 0.503095\n",
      "Epoch 444/1000 - 5.049741s - Loss 0.766577 - Accuracy 0.333333 - Test Loss 0.599116 - Test Accuracy 0.499116\n",
      "Epoch 445/1000 - 5.051000s - Loss 0.625036 - Accuracy 0.364583 - Test Loss 0.597715 - Test Accuracy 0.502653\n",
      "Epoch 446/1000 - 5.043370s - Loss 0.982652 - Accuracy 0.250000 - Test Loss 0.597152 - Test Accuracy 0.501326\n",
      "Epoch 447/1000 - 5.048968s - Loss 0.896744 - Accuracy 0.286458 - Test Loss 0.596394 - Test Accuracy 0.503979\n",
      "Epoch 448/1000 - 5.053113s - Loss 0.816370 - Accuracy 0.322917 - Test Loss 0.595960 - Test Accuracy 0.506189\n",
      "-----***-----\n",
      "0.5061892130857648\n",
      "Epoch 449/1000 - 5.045367s - Loss 0.786774 - Accuracy 0.296875 - Test Loss 0.594596 - Test Accuracy 0.506189\n",
      "Epoch 450/1000 - 5.045616s - Loss 0.857441 - Accuracy 0.244792 - Test Loss 0.593314 - Test Accuracy 0.507958\n",
      "-----***-----\n",
      "0.5079575596816976\n",
      "Epoch 451/1000 - 5.031884s - Loss 0.613749 - Accuracy 0.317708 - Test Loss 0.591301 - Test Accuracy 0.506189\n",
      "Epoch 452/1000 - 5.072244s - Loss 0.715665 - Accuracy 0.291667 - Test Loss 0.590904 - Test Accuracy 0.506189\n",
      "Epoch 453/1000 - 5.041702s - Loss 0.740527 - Accuracy 0.296875 - Test Loss 0.589498 - Test Accuracy 0.507073\n",
      "Epoch 454/1000 - 5.059483s - Loss 0.661844 - Accuracy 0.307292 - Test Loss 0.588866 - Test Accuracy 0.506189\n",
      "Epoch 455/1000 - 5.033056s - Loss 0.715249 - Accuracy 0.296875 - Test Loss 0.587843 - Test Accuracy 0.506189\n",
      "Epoch 456/1000 - 5.057062s - Loss 0.613945 - Accuracy 0.328125 - Test Loss 0.587663 - Test Accuracy 0.509284\n",
      "-----***-----\n",
      "0.5092838196286472\n",
      "Epoch 457/1000 - 5.046061s - Loss 0.534703 - Accuracy 0.380208 - Test Loss 0.585878 - Test Accuracy 0.507958\n",
      "Epoch 458/1000 - 5.082213s - Loss 0.650545 - Accuracy 0.286458 - Test Loss 0.585308 - Test Accuracy 0.508842\n",
      "Epoch 459/1000 - 5.037617s - Loss 0.627760 - Accuracy 0.359375 - Test Loss 0.584062 - Test Accuracy 0.507515\n",
      "Epoch 460/1000 - 5.053663s - Loss 0.914334 - Accuracy 0.270833 - Test Loss 0.583199 - Test Accuracy 0.507073\n",
      "Epoch 461/1000 - 5.061644s - Loss 0.589060 - Accuracy 0.343750 - Test Loss 0.582189 - Test Accuracy 0.510610\n",
      "-----***-----\n",
      "0.5106100795755968\n",
      "Epoch 462/1000 - 5.047958s - Loss 0.694572 - Accuracy 0.338542 - Test Loss 0.580109 - Test Accuracy 0.509284\n",
      "Epoch 463/1000 - 5.031879s - Loss 0.755248 - Accuracy 0.250000 - Test Loss 0.579819 - Test Accuracy 0.510610\n",
      "Epoch 464/1000 - 5.053449s - Loss 0.720479 - Accuracy 0.260417 - Test Loss 0.578220 - Test Accuracy 0.508400\n",
      "Epoch 465/1000 - 5.048954s - Loss 0.673192 - Accuracy 0.369792 - Test Loss 0.577721 - Test Accuracy 0.510168\n",
      "Epoch 466/1000 - 5.048887s - Loss 0.683246 - Accuracy 0.364583 - Test Loss 0.576882 - Test Accuracy 0.511052\n",
      "-----***-----\n",
      "0.51105216622458\n",
      "Epoch 467/1000 - 5.039801s - Loss 0.613818 - Accuracy 0.380208 - Test Loss 0.575989 - Test Accuracy 0.510168\n",
      "Epoch 468/1000 - 5.062787s - Loss 0.649950 - Accuracy 0.296875 - Test Loss 0.575099 - Test Accuracy 0.510610\n",
      "Epoch 469/1000 - 5.052278s - Loss 0.812032 - Accuracy 0.244792 - Test Loss 0.574088 - Test Accuracy 0.510610\n",
      "Epoch 470/1000 - 5.043099s - Loss 0.715634 - Accuracy 0.270833 - Test Loss 0.572496 - Test Accuracy 0.509284\n",
      "Epoch 471/1000 - 5.049143s - Loss 0.719659 - Accuracy 0.307292 - Test Loss 0.572261 - Test Accuracy 0.512378\n",
      "-----***-----\n",
      "0.5123784261715296\n",
      "Epoch 472/1000 - 5.047694s - Loss 0.637928 - Accuracy 0.322917 - Test Loss 0.571430 - Test Accuracy 0.515473\n",
      "-----***-----\n",
      "0.515473032714412\n",
      "Epoch 473/1000 - 5.035197s - Loss 0.658992 - Accuracy 0.270833 - Test Loss 0.570933 - Test Accuracy 0.512821\n",
      "Epoch 474/1000 - 5.061179s - Loss 0.697397 - Accuracy 0.281250 - Test Loss 0.569952 - Test Accuracy 0.512378\n",
      "Epoch 475/1000 - 5.040475s - Loss 0.639130 - Accuracy 0.338542 - Test Loss 0.568294 - Test Accuracy 0.512821\n",
      "Epoch 476/1000 - 5.063723s - Loss 0.645083 - Accuracy 0.302083 - Test Loss 0.568129 - Test Accuracy 0.515473\n",
      "Epoch 477/1000 - 5.060846s - Loss 0.547024 - Accuracy 0.348958 - Test Loss 0.567352 - Test Accuracy 0.513705\n",
      "Epoch 478/1000 - 5.076729s - Loss 0.710118 - Accuracy 0.286458 - Test Loss 0.566422 - Test Accuracy 0.514589\n",
      "Epoch 479/1000 - 5.059933s - Loss 0.688914 - Accuracy 0.281250 - Test Loss 0.564831 - Test Accuracy 0.515915\n",
      "-----***-----\n",
      "0.5159151193633952\n",
      "Epoch 480/1000 - 5.059683s - Loss 0.613342 - Accuracy 0.369792 - Test Loss 0.564138 - Test Accuracy 0.515915\n",
      "Epoch 481/1000 - 5.049447s - Loss 0.625568 - Accuracy 0.328125 - Test Loss 0.562884 - Test Accuracy 0.514147\n",
      "Epoch 482/1000 - 5.044235s - Loss 0.673889 - Accuracy 0.364583 - Test Loss 0.562231 - Test Accuracy 0.514589\n",
      "Epoch 483/1000 - 5.050722s - Loss 0.671674 - Accuracy 0.328125 - Test Loss 0.561848 - Test Accuracy 0.515473\n",
      "Epoch 484/1000 - 5.055624s - Loss 0.660189 - Accuracy 0.312500 - Test Loss 0.560498 - Test Accuracy 0.515473\n",
      "Epoch 485/1000 - 5.040817s - Loss 0.680367 - Accuracy 0.250000 - Test Loss 0.559564 - Test Accuracy 0.515473\n",
      "Epoch 486/1000 - 5.066071s - Loss 0.626027 - Accuracy 0.302083 - Test Loss 0.559076 - Test Accuracy 0.516799\n",
      "-----***-----\n",
      "0.5167992926613616\n",
      "Epoch 487/1000 - 5.042101s - Loss 0.605190 - Accuracy 0.348958 - Test Loss 0.557331 - Test Accuracy 0.516357\n",
      "Epoch 488/1000 - 5.046144s - Loss 0.563984 - Accuracy 0.385417 - Test Loss 0.556492 - Test Accuracy 0.515915\n",
      "Epoch 489/1000 - 5.051853s - Loss 0.618074 - Accuracy 0.322917 - Test Loss 0.556232 - Test Accuracy 0.516799\n",
      "Epoch 490/1000 - 5.055033s - Loss 0.828020 - Accuracy 0.380208 - Test Loss 0.555623 - Test Accuracy 0.514589\n",
      "Epoch 491/1000 - 5.035669s - Loss 0.705605 - Accuracy 0.281250 - Test Loss 0.555770 - Test Accuracy 0.515915\n",
      "Epoch 492/1000 - 5.065162s - Loss 0.606161 - Accuracy 0.354167 - Test Loss 0.554665 - Test Accuracy 0.515915\n",
      "Epoch 493/1000 - 5.071724s - Loss 0.748454 - Accuracy 0.317708 - Test Loss 0.553991 - Test Accuracy 0.515473\n",
      "Epoch 494/1000 - 5.061021s - Loss 0.651923 - Accuracy 0.239583 - Test Loss 0.553304 - Test Accuracy 0.518126\n",
      "-----***-----\n",
      "0.5181255526083113\n",
      "Epoch 495/1000 - 5.055087s - Loss 0.597329 - Accuracy 0.286458 - Test Loss 0.553195 - Test Accuracy 0.519452\n",
      "-----***-----\n",
      "0.5194518125552609\n",
      "Epoch 496/1000 - 5.053423s - Loss 0.809586 - Accuracy 0.333333 - Test Loss 0.552189 - Test Accuracy 0.519010\n",
      "Epoch 497/1000 - 5.049483s - Loss 0.661629 - Accuracy 0.338542 - Test Loss 0.550028 - Test Accuracy 0.515915\n",
      "Epoch 498/1000 - 5.074069s - Loss 0.883098 - Accuracy 0.281250 - Test Loss 0.550371 - Test Accuracy 0.518568\n",
      "Epoch 499/1000 - 5.045927s - Loss 0.571442 - Accuracy 0.375000 - Test Loss 0.549782 - Test Accuracy 0.522104\n",
      "-----***-----\n",
      "0.52210433244916\n",
      "Epoch 500/1000 - 5.058760s - Loss 0.610032 - Accuracy 0.333333 - Test Loss 0.548647 - Test Accuracy 0.519452\n",
      "Epoch 501/1000 - 5.056481s - Loss 0.815123 - Accuracy 0.250000 - Test Loss 0.547297 - Test Accuracy 0.518568\n",
      "Epoch 502/1000 - 5.061637s - Loss 0.697627 - Accuracy 0.322917 - Test Loss 0.547407 - Test Accuracy 0.520778\n",
      "Epoch 503/1000 - 5.043042s - Loss 0.564514 - Accuracy 0.395833 - Test Loss 0.545052 - Test Accuracy 0.521220\n",
      "Epoch 504/1000 - 5.078073s - Loss 0.687513 - Accuracy 0.338542 - Test Loss 0.544716 - Test Accuracy 0.522104\n",
      "Epoch 505/1000 - 5.036910s - Loss 0.740198 - Accuracy 0.328125 - Test Loss 0.544359 - Test Accuracy 0.522989\n",
      "-----***-----\n",
      "0.5229885057471264\n",
      "Epoch 506/1000 - 5.044356s - Loss 0.628556 - Accuracy 0.338542 - Test Loss 0.544417 - Test Accuracy 0.524315\n",
      "-----***-----\n",
      "0.5243147656940761\n",
      "Epoch 507/1000 - 5.040624s - Loss 0.636760 - Accuracy 0.354167 - Test Loss 0.544030 - Test Accuracy 0.525641\n",
      "-----***-----\n",
      "0.5256410256410257\n",
      "Epoch 508/1000 - 5.045539s - Loss 0.577006 - Accuracy 0.338542 - Test Loss 0.542711 - Test Accuracy 0.523431\n",
      "Epoch 509/1000 - 5.051738s - Loss 0.568901 - Accuracy 0.375000 - Test Loss 0.541238 - Test Accuracy 0.522546\n",
      "Epoch 510/1000 - 5.034726s - Loss 0.585758 - Accuracy 0.395833 - Test Loss 0.540624 - Test Accuracy 0.522546\n",
      "Epoch 511/1000 - 5.045480s - Loss 0.623360 - Accuracy 0.390625 - Test Loss 0.540430 - Test Accuracy 0.522104\n",
      "Epoch 512/1000 - 5.031910s - Loss 0.598529 - Accuracy 0.447917 - Test Loss 0.539981 - Test Accuracy 0.522989\n",
      "Epoch 513/1000 - 5.058257s - Loss 0.763343 - Accuracy 0.265625 - Test Loss 0.540424 - Test Accuracy 0.522989\n",
      "Epoch 514/1000 - 5.038116s - Loss 0.574494 - Accuracy 0.385417 - Test Loss 0.539129 - Test Accuracy 0.526083\n",
      "-----***-----\n",
      "0.5260831122900088\n",
      "Epoch 515/1000 - 5.074360s - Loss 0.641777 - Accuracy 0.322917 - Test Loss 0.538113 - Test Accuracy 0.526967\n",
      "-----***-----\n",
      "0.5269672855879752\n",
      "Epoch 516/1000 - 5.063981s - Loss 0.698260 - Accuracy 0.343750 - Test Loss 0.536849 - Test Accuracy 0.526083\n",
      "Epoch 517/1000 - 5.059930s - Loss 0.677454 - Accuracy 0.281250 - Test Loss 0.536143 - Test Accuracy 0.526967\n",
      "Epoch 518/1000 - 5.040605s - Loss 0.619184 - Accuracy 0.302083 - Test Loss 0.535560 - Test Accuracy 0.526525\n",
      "Epoch 519/1000 - 5.062248s - Loss 0.621359 - Accuracy 0.296875 - Test Loss 0.534934 - Test Accuracy 0.523873\n",
      "Epoch 520/1000 - 5.035405s - Loss 0.548625 - Accuracy 0.395833 - Test Loss 0.533814 - Test Accuracy 0.521220\n",
      "Epoch 521/1000 - 5.063720s - Loss 0.543325 - Accuracy 0.406250 - Test Loss 0.532795 - Test Accuracy 0.522104\n",
      "Epoch 522/1000 - 5.042777s - Loss 0.653161 - Accuracy 0.364583 - Test Loss 0.533230 - Test Accuracy 0.524315\n",
      "Epoch 523/1000 - 5.037154s - Loss 0.660423 - Accuracy 0.307292 - Test Loss 0.532999 - Test Accuracy 0.525641\n",
      "Epoch 524/1000 - 5.050553s - Loss 0.672237 - Accuracy 0.286458 - Test Loss 0.532341 - Test Accuracy 0.525641\n",
      "Epoch 525/1000 - 5.059385s - Loss 0.601497 - Accuracy 0.421875 - Test Loss 0.531964 - Test Accuracy 0.528294\n",
      "-----***-----\n",
      "0.5282935455349248\n",
      "Epoch 526/1000 - 5.027293s - Loss 0.675607 - Accuracy 0.369792 - Test Loss 0.531236 - Test Accuracy 0.529620\n",
      "-----***-----\n",
      "0.5296198054818745\n",
      "Epoch 527/1000 - 5.039443s - Loss 0.661192 - Accuracy 0.380208 - Test Loss 0.530324 - Test Accuracy 0.529178\n",
      "Epoch 528/1000 - 5.032009s - Loss 0.533633 - Accuracy 0.312500 - Test Loss 0.529853 - Test Accuracy 0.528736\n",
      "Epoch 529/1000 - 5.041207s - Loss 0.611198 - Accuracy 0.375000 - Test Loss 0.529392 - Test Accuracy 0.527409\n",
      "Epoch 530/1000 - 5.020452s - Loss 0.615624 - Accuracy 0.307292 - Test Loss 0.529210 - Test Accuracy 0.530504\n",
      "-----***-----\n",
      "0.5305039787798409\n",
      "Epoch 531/1000 - 5.042133s - Loss 0.620135 - Accuracy 0.364583 - Test Loss 0.528481 - Test Accuracy 0.528736\n",
      "Epoch 532/1000 - 5.042337s - Loss 0.511157 - Accuracy 0.416667 - Test Loss 0.526998 - Test Accuracy 0.530946\n",
      "-----***-----\n",
      "0.530946065428824\n",
      "Epoch 533/1000 - 5.053236s - Loss 0.494137 - Accuracy 0.447917 - Test Loss 0.526720 - Test Accuracy 0.530504\n",
      "Epoch 534/1000 - 5.040745s - Loss 0.571049 - Accuracy 0.437500 - Test Loss 0.526448 - Test Accuracy 0.530504\n",
      "Epoch 535/1000 - 5.035266s - Loss 0.570622 - Accuracy 0.380208 - Test Loss 0.525332 - Test Accuracy 0.529178\n",
      "Epoch 536/1000 - 5.035412s - Loss 0.560868 - Accuracy 0.343750 - Test Loss 0.524178 - Test Accuracy 0.526525\n",
      "Epoch 537/1000 - 5.040511s - Loss 0.605274 - Accuracy 0.286458 - Test Loss 0.523728 - Test Accuracy 0.530062\n",
      "Epoch 538/1000 - 5.040782s - Loss 0.545142 - Accuracy 0.390625 - Test Loss 0.522957 - Test Accuracy 0.528736\n",
      "Epoch 539/1000 - 5.036154s - Loss 0.695487 - Accuracy 0.312500 - Test Loss 0.522870 - Test Accuracy 0.529178\n",
      "Epoch 540/1000 - 5.039849s - Loss 0.574415 - Accuracy 0.375000 - Test Loss 0.522911 - Test Accuracy 0.531388\n",
      "-----***-----\n",
      "0.5313881520778072\n",
      "Epoch 541/1000 - 5.045646s - Loss 0.590244 - Accuracy 0.359375 - Test Loss 0.521614 - Test Accuracy 0.530062\n",
      "Epoch 542/1000 - 5.028141s - Loss 0.583964 - Accuracy 0.333333 - Test Loss 0.520301 - Test Accuracy 0.530062\n",
      "Epoch 543/1000 - 5.035284s - Loss 0.470998 - Accuracy 0.427083 - Test Loss 0.519510 - Test Accuracy 0.530504\n",
      "Epoch 544/1000 - 5.027059s - Loss 0.537367 - Accuracy 0.447917 - Test Loss 0.519638 - Test Accuracy 0.530946\n",
      "Epoch 545/1000 - 5.052187s - Loss 0.565231 - Accuracy 0.364583 - Test Loss 0.519170 - Test Accuracy 0.529178\n",
      "Epoch 546/1000 - 5.034229s - Loss 0.652273 - Accuracy 0.343750 - Test Loss 0.518381 - Test Accuracy 0.529620\n",
      "Epoch 547/1000 - 5.047743s - Loss 0.609089 - Accuracy 0.343750 - Test Loss 0.517873 - Test Accuracy 0.531830\n",
      "-----***-----\n",
      "0.5318302387267905\n",
      "Epoch 548/1000 - 5.018985s - Loss 0.560396 - Accuracy 0.359375 - Test Loss 0.517435 - Test Accuracy 0.530062\n",
      "Epoch 549/1000 - 5.073165s - Loss 0.595838 - Accuracy 0.390625 - Test Loss 0.516615 - Test Accuracy 0.531388\n",
      "Epoch 550/1000 - 5.063747s - Loss 0.530509 - Accuracy 0.473958 - Test Loss 0.515816 - Test Accuracy 0.533599\n",
      "-----***-----\n",
      "0.5335985853227233\n",
      "Epoch 551/1000 - 5.061832s - Loss 0.570850 - Accuracy 0.348958 - Test Loss 0.515201 - Test Accuracy 0.533156\n",
      "Epoch 552/1000 - 5.052689s - Loss 0.638707 - Accuracy 0.354167 - Test Loss 0.515907 - Test Accuracy 0.534041\n",
      "-----***-----\n",
      "0.5340406719717065\n",
      "Epoch 553/1000 - 5.216136s - Loss 0.560162 - Accuracy 0.364583 - Test Loss 0.514766 - Test Accuracy 0.533599\n",
      "Epoch 554/1000 - 5.064499s - Loss 0.469131 - Accuracy 0.427083 - Test Loss 0.514696 - Test Accuracy 0.533599\n",
      "Epoch 555/1000 - 5.065099s - Loss 0.662767 - Accuracy 0.312500 - Test Loss 0.514168 - Test Accuracy 0.534041\n",
      "Epoch 556/1000 - 5.055035s - Loss 0.697970 - Accuracy 0.255208 - Test Loss 0.513471 - Test Accuracy 0.533156\n",
      "Epoch 557/1000 - 5.066431s - Loss 0.591272 - Accuracy 0.343750 - Test Loss 0.512383 - Test Accuracy 0.534041\n",
      "Epoch 558/1000 - 5.046965s - Loss 0.473165 - Accuracy 0.395833 - Test Loss 0.512148 - Test Accuracy 0.533156\n",
      "Epoch 559/1000 - 5.047493s - Loss 0.425974 - Accuracy 0.458333 - Test Loss 0.512617 - Test Accuracy 0.534041\n",
      "Epoch 560/1000 - 5.041351s - Loss 0.522057 - Accuracy 0.416667 - Test Loss 0.511998 - Test Accuracy 0.535367\n",
      "-----***-----\n",
      "0.535366931918656\n",
      "Epoch 561/1000 - 5.063179s - Loss 0.519028 - Accuracy 0.380208 - Test Loss 0.511568 - Test Accuracy 0.534483\n",
      "Epoch 562/1000 - 5.044121s - Loss 0.532532 - Accuracy 0.437500 - Test Loss 0.510796 - Test Accuracy 0.534041\n",
      "Epoch 563/1000 - 5.051740s - Loss 0.475244 - Accuracy 0.416667 - Test Loss 0.510103 - Test Accuracy 0.533599\n",
      "Epoch 564/1000 - 5.050953s - Loss 0.538058 - Accuracy 0.328125 - Test Loss 0.509713 - Test Accuracy 0.534041\n",
      "Epoch 565/1000 - 5.057272s - Loss 0.495763 - Accuracy 0.369792 - Test Loss 0.509214 - Test Accuracy 0.533599\n",
      "Epoch 566/1000 - 5.051426s - Loss 0.526423 - Accuracy 0.364583 - Test Loss 0.508802 - Test Accuracy 0.534483\n",
      "Epoch 567/1000 - 5.056101s - Loss 0.544680 - Accuracy 0.401042 - Test Loss 0.509771 - Test Accuracy 0.536251\n",
      "-----***-----\n",
      "0.5362511052166224\n",
      "Epoch 568/1000 - 5.036357s - Loss 0.575229 - Accuracy 0.333333 - Test Loss 0.508696 - Test Accuracy 0.534925\n",
      "Epoch 569/1000 - 5.050348s - Loss 0.616691 - Accuracy 0.338542 - Test Loss 0.508117 - Test Accuracy 0.536693\n",
      "-----***-----\n",
      "0.5366931918656057\n",
      "Epoch 570/1000 - 5.049415s - Loss 0.546637 - Accuracy 0.338542 - Test Loss 0.506802 - Test Accuracy 0.535809\n",
      "Epoch 571/1000 - 5.066046s - Loss 0.546794 - Accuracy 0.385417 - Test Loss 0.506108 - Test Accuracy 0.534925\n",
      "Epoch 572/1000 - 5.037303s - Loss 0.523013 - Accuracy 0.401042 - Test Loss 0.504904 - Test Accuracy 0.536251\n",
      "Epoch 573/1000 - 5.041796s - Loss 0.431287 - Accuracy 0.494792 - Test Loss 0.505013 - Test Accuracy 0.536251\n",
      "Epoch 574/1000 - 5.037033s - Loss 0.603804 - Accuracy 0.322917 - Test Loss 0.505529 - Test Accuracy 0.537577\n",
      "-----***-----\n",
      "0.537577365163572\n",
      "Epoch 575/1000 - 5.039073s - Loss 0.585426 - Accuracy 0.375000 - Test Loss 0.505696 - Test Accuracy 0.537577\n",
      "Epoch 576/1000 - 5.048848s - Loss 0.576049 - Accuracy 0.364583 - Test Loss 0.504332 - Test Accuracy 0.538904\n",
      "-----***-----\n",
      "0.5389036251105217\n",
      "Epoch 577/1000 - 5.045565s - Loss 0.569483 - Accuracy 0.322917 - Test Loss 0.503596 - Test Accuracy 0.537135\n",
      "Epoch 578/1000 - 5.044589s - Loss 0.567953 - Accuracy 0.359375 - Test Loss 0.503391 - Test Accuracy 0.537577\n",
      "Epoch 579/1000 - 5.047435s - Loss 0.461361 - Accuracy 0.437500 - Test Loss 0.502939 - Test Accuracy 0.539788\n",
      "-----***-----\n",
      "0.5397877984084881\n",
      "Epoch 580/1000 - 5.051571s - Loss 0.474469 - Accuracy 0.447917 - Test Loss 0.503159 - Test Accuracy 0.539346\n",
      "Epoch 581/1000 - 5.070567s - Loss 0.508163 - Accuracy 0.416667 - Test Loss 0.503091 - Test Accuracy 0.539788\n",
      "Epoch 582/1000 - 5.040669s - Loss 0.623742 - Accuracy 0.322917 - Test Loss 0.503732 - Test Accuracy 0.541998\n",
      "-----***-----\n",
      "0.5419982316534041\n",
      "Epoch 583/1000 - 5.053653s - Loss 0.480724 - Accuracy 0.406250 - Test Loss 0.502060 - Test Accuracy 0.539346\n",
      "Epoch 584/1000 - 5.033150s - Loss 0.572955 - Accuracy 0.447917 - Test Loss 0.502147 - Test Accuracy 0.540672\n",
      "Epoch 585/1000 - 5.043634s - Loss 0.612402 - Accuracy 0.364583 - Test Loss 0.501464 - Test Accuracy 0.538462\n",
      "Epoch 586/1000 - 5.034200s - Loss 0.491166 - Accuracy 0.401042 - Test Loss 0.501345 - Test Accuracy 0.539788\n",
      "Epoch 587/1000 - 5.060153s - Loss 0.602080 - Accuracy 0.375000 - Test Loss 0.501180 - Test Accuracy 0.540672\n",
      "Epoch 588/1000 - 5.061849s - Loss 0.607390 - Accuracy 0.401042 - Test Loss 0.500873 - Test Accuracy 0.543767\n",
      "-----***-----\n",
      "0.5437665782493368\n",
      "Epoch 589/1000 - 5.060340s - Loss 0.500719 - Accuracy 0.395833 - Test Loss 0.500416 - Test Accuracy 0.541998\n",
      "Epoch 590/1000 - 5.033530s - Loss 0.581988 - Accuracy 0.369792 - Test Loss 0.499799 - Test Accuracy 0.541556\n",
      "Epoch 591/1000 - 5.060239s - Loss 0.490542 - Accuracy 0.421875 - Test Loss 0.500165 - Test Accuracy 0.541998\n",
      "Epoch 592/1000 - 5.049080s - Loss 0.520244 - Accuracy 0.375000 - Test Loss 0.498971 - Test Accuracy 0.543324\n",
      "Epoch 593/1000 - 5.055806s - Loss 0.522657 - Accuracy 0.354167 - Test Loss 0.499249 - Test Accuracy 0.541556\n",
      "Epoch 594/1000 - 5.038302s - Loss 0.545279 - Accuracy 0.369792 - Test Loss 0.497856 - Test Accuracy 0.541998\n",
      "Epoch 595/1000 - 5.055471s - Loss 0.456636 - Accuracy 0.447917 - Test Loss 0.497208 - Test Accuracy 0.543324\n",
      "Epoch 596/1000 - 5.048221s - Loss 0.495582 - Accuracy 0.369792 - Test Loss 0.496544 - Test Accuracy 0.543767\n",
      "Epoch 597/1000 - 5.056773s - Loss 0.499311 - Accuracy 0.453125 - Test Loss 0.496604 - Test Accuracy 0.545093\n",
      "-----***-----\n",
      "0.5450928381962865\n",
      "Epoch 598/1000 - 5.053962s - Loss 0.522196 - Accuracy 0.375000 - Test Loss 0.495952 - Test Accuracy 0.546419\n",
      "-----***-----\n",
      "0.5464190981432361\n",
      "Epoch 599/1000 - 5.068926s - Loss 0.497402 - Accuracy 0.375000 - Test Loss 0.495975 - Test Accuracy 0.548187\n",
      "-----***-----\n",
      "0.5481874447391689\n",
      "Epoch 600/1000 - 5.057735s - Loss 0.477065 - Accuracy 0.427083 - Test Loss 0.495365 - Test Accuracy 0.546861\n",
      "Epoch 601/1000 - 5.037477s - Loss 0.541293 - Accuracy 0.369792 - Test Loss 0.495799 - Test Accuracy 0.546861\n",
      "Epoch 602/1000 - 5.032474s - Loss 0.592478 - Accuracy 0.369792 - Test Loss 0.494728 - Test Accuracy 0.547303\n",
      "Epoch 603/1000 - 5.037350s - Loss 0.642489 - Accuracy 0.291667 - Test Loss 0.495086 - Test Accuracy 0.547745\n",
      "Epoch 604/1000 - 5.052088s - Loss 0.517333 - Accuracy 0.484375 - Test Loss 0.494801 - Test Accuracy 0.549514\n",
      "-----***-----\n",
      "0.5495137046861185\n",
      "Epoch 605/1000 - 5.035664s - Loss 0.567882 - Accuracy 0.390625 - Test Loss 0.494325 - Test Accuracy 0.547303\n",
      "Epoch 606/1000 - 5.053303s - Loss 0.552654 - Accuracy 0.447917 - Test Loss 0.493706 - Test Accuracy 0.546419\n",
      "Epoch 607/1000 - 5.048168s - Loss 0.622753 - Accuracy 0.354167 - Test Loss 0.493185 - Test Accuracy 0.547303\n",
      "Epoch 608/1000 - 5.061154s - Loss 0.516868 - Accuracy 0.369792 - Test Loss 0.493031 - Test Accuracy 0.548630\n",
      "Epoch 609/1000 - 5.060650s - Loss 0.597587 - Accuracy 0.369792 - Test Loss 0.492957 - Test Accuracy 0.549514\n",
      "Epoch 610/1000 - 5.053650s - Loss 0.460518 - Accuracy 0.484375 - Test Loss 0.493050 - Test Accuracy 0.549956\n",
      "-----***-----\n",
      "0.5499557913351016\n",
      "Epoch 611/1000 - 5.062120s - Loss 0.565152 - Accuracy 0.395833 - Test Loss 0.491019 - Test Accuracy 0.549072\n",
      "Epoch 612/1000 - 5.078539s - Loss 0.519040 - Accuracy 0.385417 - Test Loss 0.491448 - Test Accuracy 0.549072\n",
      "Epoch 613/1000 - 5.040402s - Loss 0.472949 - Accuracy 0.390625 - Test Loss 0.491446 - Test Accuracy 0.549956\n",
      "Epoch 614/1000 - 5.065379s - Loss 0.643574 - Accuracy 0.385417 - Test Loss 0.491310 - Test Accuracy 0.548187\n",
      "Epoch 615/1000 - 5.043320s - Loss 0.473104 - Accuracy 0.468750 - Test Loss 0.490533 - Test Accuracy 0.547745\n",
      "Epoch 616/1000 - 5.075460s - Loss 0.471177 - Accuracy 0.479167 - Test Loss 0.490601 - Test Accuracy 0.550398\n",
      "-----***-----\n",
      "0.5503978779840849\n",
      "Epoch 617/1000 - 5.059163s - Loss 0.487385 - Accuracy 0.395833 - Test Loss 0.490122 - Test Accuracy 0.550840\n",
      "-----***-----\n",
      "0.5508399646330681\n",
      "Epoch 618/1000 - 5.040482s - Loss 0.548051 - Accuracy 0.427083 - Test Loss 0.489025 - Test Accuracy 0.551282\n",
      "-----***-----\n",
      "0.5512820512820513\n",
      "Epoch 619/1000 - 5.033300s - Loss 0.495732 - Accuracy 0.432292 - Test Loss 0.488921 - Test Accuracy 0.550398\n",
      "Epoch 620/1000 - 5.060541s - Loss 0.483985 - Accuracy 0.453125 - Test Loss 0.488056 - Test Accuracy 0.553492\n",
      "-----***-----\n",
      "0.5534924845269673\n",
      "Epoch 621/1000 - 5.044127s - Loss 0.541606 - Accuracy 0.416667 - Test Loss 0.487757 - Test Accuracy 0.549514\n",
      "Epoch 622/1000 - 5.046249s - Loss 0.538686 - Accuracy 0.375000 - Test Loss 0.487927 - Test Accuracy 0.551282\n",
      "Epoch 623/1000 - 5.047942s - Loss 0.519470 - Accuracy 0.437500 - Test Loss 0.487903 - Test Accuracy 0.550840\n",
      "Epoch 624/1000 - 5.058113s - Loss 0.465655 - Accuracy 0.536458 - Test Loss 0.486668 - Test Accuracy 0.551724\n",
      "Epoch 625/1000 - 5.051875s - Loss 0.440377 - Accuracy 0.458333 - Test Loss 0.486827 - Test Accuracy 0.552166\n",
      "Epoch 626/1000 - 5.057237s - Loss 0.437764 - Accuracy 0.489583 - Test Loss 0.487192 - Test Accuracy 0.551282\n",
      "Epoch 627/1000 - 5.056697s - Loss 0.511785 - Accuracy 0.421875 - Test Loss 0.487279 - Test Accuracy 0.551282\n",
      "Epoch 628/1000 - 5.056323s - Loss 0.510141 - Accuracy 0.432292 - Test Loss 0.486203 - Test Accuracy 0.553050\n",
      "Epoch 629/1000 - 5.047138s - Loss 0.594827 - Accuracy 0.364583 - Test Loss 0.485608 - Test Accuracy 0.554377\n",
      "-----***-----\n",
      "0.5543766578249337\n",
      "Epoch 630/1000 - 5.058661s - Loss 0.451170 - Accuracy 0.473958 - Test Loss 0.485658 - Test Accuracy 0.554377\n",
      "Epoch 631/1000 - 5.042599s - Loss 0.568365 - Accuracy 0.359375 - Test Loss 0.485688 - Test Accuracy 0.553492\n",
      "Epoch 632/1000 - 5.061514s - Loss 0.590391 - Accuracy 0.333333 - Test Loss 0.484945 - Test Accuracy 0.552608\n",
      "Epoch 633/1000 - 5.050419s - Loss 0.464732 - Accuracy 0.479167 - Test Loss 0.485027 - Test Accuracy 0.551724\n",
      "Epoch 634/1000 - 5.050455s - Loss 0.521296 - Accuracy 0.427083 - Test Loss 0.484489 - Test Accuracy 0.552166\n",
      "Epoch 635/1000 - 5.058976s - Loss 0.523641 - Accuracy 0.406250 - Test Loss 0.483973 - Test Accuracy 0.553935\n",
      "Epoch 636/1000 - 5.077323s - Loss 0.477422 - Accuracy 0.458333 - Test Loss 0.483494 - Test Accuracy 0.553492\n",
      "Epoch 637/1000 - 5.047703s - Loss 0.545178 - Accuracy 0.385417 - Test Loss 0.482988 - Test Accuracy 0.553492\n",
      "Epoch 638/1000 - 5.065602s - Loss 0.452553 - Accuracy 0.473958 - Test Loss 0.482879 - Test Accuracy 0.552166\n",
      "Epoch 639/1000 - 5.038559s - Loss 0.490002 - Accuracy 0.427083 - Test Loss 0.482586 - Test Accuracy 0.553492\n",
      "Epoch 640/1000 - 5.051816s - Loss 0.483972 - Accuracy 0.390625 - Test Loss 0.482018 - Test Accuracy 0.551724\n",
      "Epoch 641/1000 - 5.057113s - Loss 0.467580 - Accuracy 0.354167 - Test Loss 0.482467 - Test Accuracy 0.549956\n",
      "Epoch 642/1000 - 5.048964s - Loss 0.479596 - Accuracy 0.395833 - Test Loss 0.481728 - Test Accuracy 0.553492\n",
      "Epoch 643/1000 - 5.039825s - Loss 0.517228 - Accuracy 0.406250 - Test Loss 0.481443 - Test Accuracy 0.556587\n",
      "-----***-----\n",
      "0.5565870910698497\n",
      "Epoch 644/1000 - 5.034062s - Loss 0.378038 - Accuracy 0.500000 - Test Loss 0.480677 - Test Accuracy 0.554819\n",
      "Epoch 645/1000 - 5.033251s - Loss 0.406079 - Accuracy 0.520833 - Test Loss 0.481035 - Test Accuracy 0.556587\n",
      "Epoch 646/1000 - 5.055113s - Loss 0.527339 - Accuracy 0.442708 - Test Loss 0.480711 - Test Accuracy 0.556145\n",
      "Epoch 647/1000 - 5.065831s - Loss 0.489143 - Accuracy 0.401042 - Test Loss 0.480108 - Test Accuracy 0.554377\n",
      "Epoch 648/1000 - 5.067404s - Loss 0.542838 - Accuracy 0.395833 - Test Loss 0.479944 - Test Accuracy 0.556145\n",
      "Epoch 649/1000 - 5.041505s - Loss 0.512529 - Accuracy 0.364583 - Test Loss 0.479246 - Test Accuracy 0.554377\n",
      "Epoch 650/1000 - 5.049235s - Loss 0.484192 - Accuracy 0.416667 - Test Loss 0.479074 - Test Accuracy 0.556145\n",
      "Epoch 651/1000 - 5.049534s - Loss 0.514806 - Accuracy 0.395833 - Test Loss 0.479649 - Test Accuracy 0.558798\n",
      "-----***-----\n",
      "0.5587975243147657\n",
      "Epoch 652/1000 - 5.077684s - Loss 0.448605 - Accuracy 0.468750 - Test Loss 0.479110 - Test Accuracy 0.560124\n",
      "-----***-----\n",
      "0.5601237842617153\n",
      "Epoch 653/1000 - 5.038787s - Loss 0.437699 - Accuracy 0.500000 - Test Loss 0.478871 - Test Accuracy 0.558798\n",
      "Epoch 654/1000 - 5.043546s - Loss 0.494526 - Accuracy 0.484375 - Test Loss 0.479182 - Test Accuracy 0.557471\n",
      "Epoch 655/1000 - 5.038184s - Loss 0.505078 - Accuracy 0.458333 - Test Loss 0.478488 - Test Accuracy 0.557029\n",
      "Epoch 656/1000 - 5.039078s - Loss 0.373937 - Accuracy 0.510417 - Test Loss 0.478427 - Test Accuracy 0.555703\n",
      "Epoch 657/1000 - 5.035303s - Loss 0.468602 - Accuracy 0.395833 - Test Loss 0.478910 - Test Accuracy 0.557471\n",
      "Epoch 658/1000 - 5.053360s - Loss 0.537374 - Accuracy 0.385417 - Test Loss 0.478098 - Test Accuracy 0.558798\n",
      "Epoch 659/1000 - 5.047349s - Loss 0.501506 - Accuracy 0.442708 - Test Loss 0.478053 - Test Accuracy 0.558355\n",
      "Epoch 660/1000 - 5.073536s - Loss 0.571392 - Accuracy 0.375000 - Test Loss 0.477765 - Test Accuracy 0.560124\n",
      "Epoch 661/1000 - 5.040047s - Loss 0.507434 - Accuracy 0.520833 - Test Loss 0.477222 - Test Accuracy 0.560124\n",
      "Epoch 662/1000 - 5.048512s - Loss 0.477286 - Accuracy 0.437500 - Test Loss 0.477304 - Test Accuracy 0.560124\n",
      "Epoch 663/1000 - 5.041047s - Loss 0.464894 - Accuracy 0.453125 - Test Loss 0.476214 - Test Accuracy 0.560124\n",
      "Epoch 664/1000 - 5.057635s - Loss 0.489191 - Accuracy 0.416667 - Test Loss 0.476125 - Test Accuracy 0.559682\n",
      "Epoch 665/1000 - 5.049032s - Loss 0.543251 - Accuracy 0.401042 - Test Loss 0.476346 - Test Accuracy 0.558798\n",
      "Epoch 666/1000 - 5.050068s - Loss 0.437854 - Accuracy 0.442708 - Test Loss 0.475499 - Test Accuracy 0.561008\n",
      "-----***-----\n",
      "0.5610079575596817\n",
      "Epoch 667/1000 - 5.033326s - Loss 0.493949 - Accuracy 0.479167 - Test Loss 0.476299 - Test Accuracy 0.560566\n",
      "Epoch 668/1000 - 5.062888s - Loss 0.465394 - Accuracy 0.416667 - Test Loss 0.475927 - Test Accuracy 0.559682\n",
      "Epoch 669/1000 - 5.031900s - Loss 0.473241 - Accuracy 0.489583 - Test Loss 0.475418 - Test Accuracy 0.560124\n",
      "Epoch 670/1000 - 5.033346s - Loss 0.465320 - Accuracy 0.416667 - Test Loss 0.474711 - Test Accuracy 0.559682\n",
      "Epoch 671/1000 - 5.037977s - Loss 0.526939 - Accuracy 0.322917 - Test Loss 0.474859 - Test Accuracy 0.557029\n",
      "Epoch 672/1000 - 5.043298s - Loss 0.402769 - Accuracy 0.447917 - Test Loss 0.473613 - Test Accuracy 0.557913\n",
      "Epoch 673/1000 - 5.030662s - Loss 0.466878 - Accuracy 0.453125 - Test Loss 0.473728 - Test Accuracy 0.557913\n",
      "Epoch 674/1000 - 5.029952s - Loss 0.452712 - Accuracy 0.427083 - Test Loss 0.473952 - Test Accuracy 0.559682\n",
      "Epoch 675/1000 - 5.033375s - Loss 0.555897 - Accuracy 0.375000 - Test Loss 0.473585 - Test Accuracy 0.559240\n",
      "Epoch 676/1000 - 5.042629s - Loss 0.459633 - Accuracy 0.432292 - Test Loss 0.473283 - Test Accuracy 0.560566\n",
      "Epoch 677/1000 - 5.041172s - Loss 0.440832 - Accuracy 0.479167 - Test Loss 0.473490 - Test Accuracy 0.557913\n",
      "Epoch 678/1000 - 5.051361s - Loss 0.492961 - Accuracy 0.463542 - Test Loss 0.472990 - Test Accuracy 0.559240\n",
      "Epoch 679/1000 - 5.038701s - Loss 0.491927 - Accuracy 0.447917 - Test Loss 0.473031 - Test Accuracy 0.559240\n",
      "Epoch 680/1000 - 5.038975s - Loss 0.500118 - Accuracy 0.427083 - Test Loss 0.472941 - Test Accuracy 0.558355\n",
      "Epoch 681/1000 - 5.032786s - Loss 0.526895 - Accuracy 0.375000 - Test Loss 0.472613 - Test Accuracy 0.559682\n",
      "Epoch 682/1000 - 5.052309s - Loss 0.506642 - Accuracy 0.411458 - Test Loss 0.473096 - Test Accuracy 0.559682\n",
      "Epoch 683/1000 - 5.036008s - Loss 0.504751 - Accuracy 0.442708 - Test Loss 0.471729 - Test Accuracy 0.559240\n",
      "Epoch 684/1000 - 5.045248s - Loss 0.468198 - Accuracy 0.427083 - Test Loss 0.472002 - Test Accuracy 0.559240\n",
      "Epoch 685/1000 - 5.029115s - Loss 0.439896 - Accuracy 0.505208 - Test Loss 0.472187 - Test Accuracy 0.559682\n",
      "Epoch 686/1000 - 5.044951s - Loss 0.492622 - Accuracy 0.421875 - Test Loss 0.470988 - Test Accuracy 0.558355\n",
      "Epoch 687/1000 - 5.027082s - Loss 0.472443 - Accuracy 0.411458 - Test Loss 0.471194 - Test Accuracy 0.560124\n",
      "Epoch 688/1000 - 5.037443s - Loss 0.464686 - Accuracy 0.442708 - Test Loss 0.471046 - Test Accuracy 0.560566\n",
      "Epoch 689/1000 - 5.030113s - Loss 0.421245 - Accuracy 0.536458 - Test Loss 0.471407 - Test Accuracy 0.561450\n",
      "-----***-----\n",
      "0.5614500442086648\n",
      "Epoch 690/1000 - 5.048941s - Loss 0.484149 - Accuracy 0.401042 - Test Loss 0.470823 - Test Accuracy 0.560124\n",
      "Epoch 691/1000 - 5.038090s - Loss 0.493840 - Accuracy 0.453125 - Test Loss 0.470748 - Test Accuracy 0.559240\n",
      "Epoch 692/1000 - 5.038877s - Loss 0.567688 - Accuracy 0.317708 - Test Loss 0.470702 - Test Accuracy 0.559682\n",
      "Epoch 693/1000 - 5.033544s - Loss 0.494292 - Accuracy 0.479167 - Test Loss 0.470884 - Test Accuracy 0.559682\n",
      "Epoch 694/1000 - 5.054455s - Loss 0.441890 - Accuracy 0.489583 - Test Loss 0.470913 - Test Accuracy 0.558355\n",
      "Epoch 695/1000 - 5.045413s - Loss 0.507040 - Accuracy 0.390625 - Test Loss 0.470961 - Test Accuracy 0.559682\n",
      "Epoch 696/1000 - 5.067370s - Loss 0.533106 - Accuracy 0.380208 - Test Loss 0.469904 - Test Accuracy 0.559682\n",
      "Epoch 697/1000 - 5.041031s - Loss 0.418136 - Accuracy 0.468750 - Test Loss 0.469184 - Test Accuracy 0.558355\n",
      "Epoch 698/1000 - 5.055110s - Loss 0.500977 - Accuracy 0.505208 - Test Loss 0.469101 - Test Accuracy 0.559682\n",
      "Epoch 699/1000 - 5.043910s - Loss 0.412088 - Accuracy 0.515625 - Test Loss 0.469212 - Test Accuracy 0.561450\n",
      "Epoch 700/1000 - 5.069277s - Loss 0.446950 - Accuracy 0.500000 - Test Loss 0.469144 - Test Accuracy 0.558798\n",
      "Epoch 701/1000 - 5.056641s - Loss 0.549755 - Accuracy 0.369792 - Test Loss 0.469054 - Test Accuracy 0.557471\n",
      "Epoch 702/1000 - 5.049366s - Loss 0.508150 - Accuracy 0.369792 - Test Loss 0.469099 - Test Accuracy 0.557913\n",
      "Epoch 703/1000 - 5.055424s - Loss 0.468768 - Accuracy 0.401042 - Test Loss 0.468485 - Test Accuracy 0.560566\n",
      "Epoch 704/1000 - 5.034888s - Loss 0.478898 - Accuracy 0.442708 - Test Loss 0.468900 - Test Accuracy 0.561008\n",
      "Epoch 705/1000 - 5.050399s - Loss 0.368652 - Accuracy 0.515625 - Test Loss 0.468593 - Test Accuracy 0.560124\n",
      "Epoch 706/1000 - 5.036885s - Loss 0.414836 - Accuracy 0.531250 - Test Loss 0.468541 - Test Accuracy 0.561892\n",
      "-----***-----\n",
      "0.5618921308576481\n",
      "Epoch 707/1000 - 5.058538s - Loss 0.524411 - Accuracy 0.463542 - Test Loss 0.468559 - Test Accuracy 0.561008\n",
      "Epoch 708/1000 - 5.041651s - Loss 0.481849 - Accuracy 0.401042 - Test Loss 0.468116 - Test Accuracy 0.561450\n",
      "Epoch 709/1000 - 5.051678s - Loss 0.419348 - Accuracy 0.531250 - Test Loss 0.467458 - Test Accuracy 0.561892\n",
      "Epoch 710/1000 - 5.039598s - Loss 0.468867 - Accuracy 0.473958 - Test Loss 0.467229 - Test Accuracy 0.561008\n",
      "Epoch 711/1000 - 5.070971s - Loss 0.479040 - Accuracy 0.406250 - Test Loss 0.466880 - Test Accuracy 0.560124\n",
      "Epoch 712/1000 - 5.034064s - Loss 0.445031 - Accuracy 0.500000 - Test Loss 0.466346 - Test Accuracy 0.561450\n",
      "Epoch 713/1000 - 5.070561s - Loss 0.470846 - Accuracy 0.473958 - Test Loss 0.467029 - Test Accuracy 0.561892\n",
      "Epoch 714/1000 - 5.036635s - Loss 0.381397 - Accuracy 0.588542 - Test Loss 0.466772 - Test Accuracy 0.561008\n",
      "Epoch 715/1000 - 5.083107s - Loss 0.447573 - Accuracy 0.473958 - Test Loss 0.465554 - Test Accuracy 0.563218\n",
      "-----***-----\n",
      "0.5632183908045977\n",
      "Epoch 716/1000 - 5.027147s - Loss 0.412740 - Accuracy 0.494792 - Test Loss 0.465056 - Test Accuracy 0.561008\n",
      "Epoch 717/1000 - 5.076687s - Loss 0.469974 - Accuracy 0.526042 - Test Loss 0.465662 - Test Accuracy 0.563660\n",
      "-----***-----\n",
      "0.5636604774535809\n",
      "Epoch 718/1000 - 5.034610s - Loss 0.464757 - Accuracy 0.505208 - Test Loss 0.465068 - Test Accuracy 0.562776\n",
      "Epoch 719/1000 - 5.052141s - Loss 0.433090 - Accuracy 0.489583 - Test Loss 0.464783 - Test Accuracy 0.561892\n",
      "Epoch 720/1000 - 5.040507s - Loss 0.455147 - Accuracy 0.500000 - Test Loss 0.465065 - Test Accuracy 0.560124\n",
      "Epoch 721/1000 - 5.049860s - Loss 0.475854 - Accuracy 0.453125 - Test Loss 0.464676 - Test Accuracy 0.561892\n",
      "Epoch 722/1000 - 5.036216s - Loss 0.448759 - Accuracy 0.458333 - Test Loss 0.464693 - Test Accuracy 0.560566\n",
      "Epoch 723/1000 - 5.055311s - Loss 0.461543 - Accuracy 0.442708 - Test Loss 0.464802 - Test Accuracy 0.561892\n",
      "Epoch 724/1000 - 5.042932s - Loss 0.500670 - Accuracy 0.385417 - Test Loss 0.464638 - Test Accuracy 0.561008\n",
      "Epoch 725/1000 - 5.052282s - Loss 0.468732 - Accuracy 0.442708 - Test Loss 0.464013 - Test Accuracy 0.560566\n",
      "Epoch 726/1000 - 5.035268s - Loss 0.455502 - Accuracy 0.473958 - Test Loss 0.463991 - Test Accuracy 0.561892\n",
      "Epoch 727/1000 - 5.065372s - Loss 0.411710 - Accuracy 0.484375 - Test Loss 0.464150 - Test Accuracy 0.561892\n",
      "Epoch 728/1000 - 5.048866s - Loss 0.493780 - Accuracy 0.447917 - Test Loss 0.464484 - Test Accuracy 0.562334\n",
      "Epoch 729/1000 - 5.057627s - Loss 0.440268 - Accuracy 0.479167 - Test Loss 0.464184 - Test Accuracy 0.561892\n",
      "Epoch 730/1000 - 5.035057s - Loss 0.402336 - Accuracy 0.510417 - Test Loss 0.463630 - Test Accuracy 0.564103\n",
      "-----***-----\n",
      "0.5641025641025641\n",
      "Epoch 731/1000 - 5.051072s - Loss 0.415687 - Accuracy 0.489583 - Test Loss 0.462786 - Test Accuracy 0.561450\n",
      "Epoch 732/1000 - 5.043135s - Loss 0.372724 - Accuracy 0.505208 - Test Loss 0.462834 - Test Accuracy 0.561450\n",
      "Epoch 733/1000 - 5.058269s - Loss 0.486924 - Accuracy 0.473958 - Test Loss 0.462331 - Test Accuracy 0.560124\n",
      "Epoch 734/1000 - 5.044215s - Loss 0.343267 - Accuracy 0.541667 - Test Loss 0.462291 - Test Accuracy 0.561892\n",
      "Epoch 735/1000 - 5.048665s - Loss 0.501560 - Accuracy 0.401042 - Test Loss 0.462896 - Test Accuracy 0.559682\n",
      "Epoch 736/1000 - 5.047487s - Loss 0.446988 - Accuracy 0.447917 - Test Loss 0.462857 - Test Accuracy 0.558798\n",
      "Epoch 737/1000 - 5.053401s - Loss 0.415101 - Accuracy 0.536458 - Test Loss 0.461977 - Test Accuracy 0.560124\n",
      "Epoch 738/1000 - 5.046057s - Loss 0.455103 - Accuracy 0.479167 - Test Loss 0.462441 - Test Accuracy 0.560124\n",
      "Epoch 739/1000 - 5.080935s - Loss 0.442496 - Accuracy 0.494792 - Test Loss 0.461922 - Test Accuracy 0.560566\n",
      "Epoch 740/1000 - 5.043977s - Loss 0.491799 - Accuracy 0.432292 - Test Loss 0.462084 - Test Accuracy 0.561008\n",
      "Epoch 741/1000 - 5.049652s - Loss 0.537966 - Accuracy 0.427083 - Test Loss 0.461956 - Test Accuracy 0.562334\n",
      "Epoch 742/1000 - 5.037881s - Loss 0.442318 - Accuracy 0.427083 - Test Loss 0.461244 - Test Accuracy 0.562334\n",
      "Epoch 743/1000 - 5.052270s - Loss 0.445388 - Accuracy 0.468750 - Test Loss 0.461336 - Test Accuracy 0.563218\n",
      "Epoch 744/1000 - 5.052402s - Loss 0.411903 - Accuracy 0.546875 - Test Loss 0.460663 - Test Accuracy 0.561892\n",
      "Epoch 745/1000 - 5.062967s - Loss 0.515908 - Accuracy 0.375000 - Test Loss 0.460823 - Test Accuracy 0.562334\n",
      "Epoch 746/1000 - 5.037108s - Loss 0.517314 - Accuracy 0.473958 - Test Loss 0.461048 - Test Accuracy 0.561450\n",
      "Epoch 747/1000 - 5.055911s - Loss 0.517457 - Accuracy 0.421875 - Test Loss 0.461676 - Test Accuracy 0.562334\n",
      "Epoch 748/1000 - 5.048518s - Loss 0.460031 - Accuracy 0.500000 - Test Loss 0.461049 - Test Accuracy 0.561450\n",
      "Epoch 749/1000 - 5.073494s - Loss 0.409144 - Accuracy 0.463542 - Test Loss 0.460343 - Test Accuracy 0.560566\n",
      "Epoch 750/1000 - 5.064746s - Loss 0.521038 - Accuracy 0.375000 - Test Loss 0.461149 - Test Accuracy 0.562776\n",
      "Epoch 751/1000 - 5.075197s - Loss 0.486190 - Accuracy 0.453125 - Test Loss 0.461062 - Test Accuracy 0.564103\n",
      "Epoch 752/1000 - 5.056118s - Loss 0.442849 - Accuracy 0.494792 - Test Loss 0.460771 - Test Accuracy 0.564545\n",
      "-----***-----\n",
      "0.5645446507515473\n",
      "Epoch 753/1000 - 5.055165s - Loss 0.471915 - Accuracy 0.505208 - Test Loss 0.459457 - Test Accuracy 0.564987\n",
      "-----***-----\n",
      "0.5649867374005305\n",
      "Epoch 754/1000 - 5.058198s - Loss 0.397100 - Accuracy 0.494792 - Test Loss 0.459807 - Test Accuracy 0.566313\n",
      "-----***-----\n",
      "0.5663129973474801\n",
      "Epoch 755/1000 - 5.052185s - Loss 0.407014 - Accuracy 0.552083 - Test Loss 0.459576 - Test Accuracy 0.564103\n",
      "Epoch 756/1000 - 5.059124s - Loss 0.418461 - Accuracy 0.505208 - Test Loss 0.459699 - Test Accuracy 0.564103\n",
      "Epoch 757/1000 - 5.081083s - Loss 0.455180 - Accuracy 0.380208 - Test Loss 0.459097 - Test Accuracy 0.566755\n",
      "-----***-----\n",
      "0.5667550839964633\n",
      "Epoch 758/1000 - 5.043354s - Loss 0.397031 - Accuracy 0.510417 - Test Loss 0.459087 - Test Accuracy 0.564987\n",
      "Epoch 759/1000 - 5.090423s - Loss 0.409584 - Accuracy 0.541667 - Test Loss 0.459744 - Test Accuracy 0.565871\n",
      "Epoch 760/1000 - 5.242501s - Loss 0.432322 - Accuracy 0.484375 - Test Loss 0.459280 - Test Accuracy 0.564987\n",
      "Epoch 761/1000 - 5.064673s - Loss 0.444223 - Accuracy 0.463542 - Test Loss 0.459064 - Test Accuracy 0.564987\n",
      "Epoch 762/1000 - 5.067811s - Loss 0.407144 - Accuracy 0.489583 - Test Loss 0.459293 - Test Accuracy 0.565871\n",
      "Epoch 763/1000 - 5.078332s - Loss 0.366736 - Accuracy 0.588542 - Test Loss 0.458797 - Test Accuracy 0.562776\n",
      "Epoch 764/1000 - 5.053980s - Loss 0.449645 - Accuracy 0.421875 - Test Loss 0.458507 - Test Accuracy 0.565429\n",
      "Epoch 765/1000 - 5.052931s - Loss 0.471146 - Accuracy 0.463542 - Test Loss 0.458376 - Test Accuracy 0.565871\n",
      "Epoch 766/1000 - 5.056731s - Loss 0.468234 - Accuracy 0.458333 - Test Loss 0.458871 - Test Accuracy 0.564103\n",
      "Epoch 767/1000 - 5.064333s - Loss 0.488216 - Accuracy 0.458333 - Test Loss 0.458955 - Test Accuracy 0.564987\n",
      "Epoch 768/1000 - 5.052398s - Loss 0.438860 - Accuracy 0.473958 - Test Loss 0.458589 - Test Accuracy 0.564103\n",
      "Epoch 769/1000 - 5.072516s - Loss 0.390982 - Accuracy 0.541667 - Test Loss 0.458191 - Test Accuracy 0.563218\n",
      "Epoch 770/1000 - 5.051715s - Loss 0.388455 - Accuracy 0.500000 - Test Loss 0.457288 - Test Accuracy 0.563660\n",
      "Epoch 771/1000 - 5.055199s - Loss 0.363396 - Accuracy 0.557292 - Test Loss 0.457758 - Test Accuracy 0.566313\n",
      "Epoch 772/1000 - 5.054281s - Loss 0.419967 - Accuracy 0.526042 - Test Loss 0.457148 - Test Accuracy 0.564103\n",
      "Epoch 773/1000 - 5.058470s - Loss 0.435899 - Accuracy 0.505208 - Test Loss 0.457160 - Test Accuracy 0.565429\n",
      "Epoch 774/1000 - 5.049895s - Loss 0.434319 - Accuracy 0.489583 - Test Loss 0.457117 - Test Accuracy 0.564103\n",
      "Epoch 775/1000 - 5.058494s - Loss 0.349442 - Accuracy 0.515625 - Test Loss 0.457734 - Test Accuracy 0.564545\n",
      "Epoch 776/1000 - 5.045789s - Loss 0.494982 - Accuracy 0.479167 - Test Loss 0.458046 - Test Accuracy 0.567197\n",
      "-----***-----\n",
      "0.5671971706454465\n",
      "Epoch 777/1000 - 5.048639s - Loss 0.479168 - Accuracy 0.427083 - Test Loss 0.457718 - Test Accuracy 0.567639\n",
      "-----***-----\n",
      "0.5676392572944297\n",
      "Epoch 778/1000 - 5.050172s - Loss 0.446576 - Accuracy 0.479167 - Test Loss 0.457341 - Test Accuracy 0.567197\n",
      "Epoch 779/1000 - 5.051529s - Loss 0.469281 - Accuracy 0.453125 - Test Loss 0.456804 - Test Accuracy 0.566313\n",
      "Epoch 780/1000 - 5.048317s - Loss 0.539905 - Accuracy 0.390625 - Test Loss 0.457327 - Test Accuracy 0.567197\n",
      "Epoch 781/1000 - 5.074519s - Loss 0.435651 - Accuracy 0.463542 - Test Loss 0.456826 - Test Accuracy 0.567639\n",
      "Epoch 782/1000 - 5.050601s - Loss 0.343259 - Accuracy 0.588542 - Test Loss 0.456521 - Test Accuracy 0.567639\n",
      "Epoch 783/1000 - 5.055830s - Loss 0.435943 - Accuracy 0.468750 - Test Loss 0.456656 - Test Accuracy 0.566755\n",
      "Epoch 784/1000 - 5.039719s - Loss 0.412930 - Accuracy 0.447917 - Test Loss 0.456755 - Test Accuracy 0.567197\n",
      "Epoch 785/1000 - 5.056441s - Loss 0.438647 - Accuracy 0.515625 - Test Loss 0.456401 - Test Accuracy 0.566755\n",
      "Epoch 786/1000 - 5.044127s - Loss 0.377949 - Accuracy 0.463542 - Test Loss 0.455978 - Test Accuracy 0.566755\n",
      "Epoch 787/1000 - 5.070482s - Loss 0.503467 - Accuracy 0.406250 - Test Loss 0.455793 - Test Accuracy 0.565871\n",
      "Epoch 788/1000 - 5.047451s - Loss 0.368040 - Accuracy 0.546875 - Test Loss 0.454904 - Test Accuracy 0.566755\n",
      "Epoch 789/1000 - 5.057874s - Loss 0.402646 - Accuracy 0.531250 - Test Loss 0.456005 - Test Accuracy 0.568966\n",
      "-----***-----\n",
      "0.5689655172413793\n",
      "Epoch 790/1000 - 5.036234s - Loss 0.499535 - Accuracy 0.468750 - Test Loss 0.455978 - Test Accuracy 0.570292\n",
      "-----***-----\n",
      "0.5702917771883289\n",
      "Epoch 791/1000 - 5.036379s - Loss 0.392360 - Accuracy 0.541667 - Test Loss 0.454962 - Test Accuracy 0.568081\n",
      "Epoch 792/1000 - 5.068815s - Loss 0.436061 - Accuracy 0.473958 - Test Loss 0.455386 - Test Accuracy 0.569408\n",
      "Epoch 793/1000 - 5.059269s - Loss 0.436881 - Accuracy 0.484375 - Test Loss 0.455088 - Test Accuracy 0.568966\n",
      "Epoch 794/1000 - 5.102611s - Loss 0.416928 - Accuracy 0.505208 - Test Loss 0.454877 - Test Accuracy 0.568523\n",
      "Epoch 795/1000 - 5.050842s - Loss 0.389974 - Accuracy 0.536458 - Test Loss 0.454414 - Test Accuracy 0.565429\n",
      "Epoch 796/1000 - 5.066705s - Loss 0.442798 - Accuracy 0.526042 - Test Loss 0.455127 - Test Accuracy 0.565429\n",
      "Epoch 797/1000 - 5.045307s - Loss 0.400799 - Accuracy 0.473958 - Test Loss 0.453979 - Test Accuracy 0.566755\n",
      "Epoch 798/1000 - 5.079886s - Loss 0.401762 - Accuracy 0.500000 - Test Loss 0.454455 - Test Accuracy 0.567639\n",
      "Epoch 799/1000 - 5.040739s - Loss 0.437274 - Accuracy 0.505208 - Test Loss 0.455019 - Test Accuracy 0.567197\n",
      "Epoch 800/1000 - 5.077644s - Loss 0.383548 - Accuracy 0.557292 - Test Loss 0.454410 - Test Accuracy 0.567197\n",
      "Epoch 801/1000 - 5.077036s - Loss 0.469272 - Accuracy 0.416667 - Test Loss 0.454159 - Test Accuracy 0.565871\n",
      "Epoch 802/1000 - 5.080091s - Loss 0.357461 - Accuracy 0.531250 - Test Loss 0.454244 - Test Accuracy 0.565871\n",
      "Epoch 803/1000 - 5.054003s - Loss 0.406677 - Accuracy 0.515625 - Test Loss 0.453805 - Test Accuracy 0.566313\n",
      "Epoch 804/1000 - 5.043128s - Loss 0.442679 - Accuracy 0.500000 - Test Loss 0.454442 - Test Accuracy 0.568081\n",
      "Epoch 805/1000 - 5.039786s - Loss 0.424374 - Accuracy 0.494792 - Test Loss 0.454300 - Test Accuracy 0.567197\n",
      "Epoch 806/1000 - 5.052944s - Loss 0.405561 - Accuracy 0.505208 - Test Loss 0.453712 - Test Accuracy 0.568081\n",
      "Epoch 807/1000 - 5.047173s - Loss 0.377314 - Accuracy 0.552083 - Test Loss 0.453026 - Test Accuracy 0.566313\n",
      "Epoch 808/1000 - 5.050199s - Loss 0.474588 - Accuracy 0.479167 - Test Loss 0.453582 - Test Accuracy 0.568966\n",
      "Epoch 809/1000 - 5.044272s - Loss 0.341503 - Accuracy 0.536458 - Test Loss 0.453420 - Test Accuracy 0.565871\n",
      "Epoch 810/1000 - 5.065201s - Loss 0.405734 - Accuracy 0.510417 - Test Loss 0.453964 - Test Accuracy 0.567197\n",
      "Epoch 811/1000 - 5.044869s - Loss 0.435925 - Accuracy 0.453125 - Test Loss 0.454139 - Test Accuracy 0.566313\n",
      "Epoch 812/1000 - 5.067200s - Loss 0.374628 - Accuracy 0.526042 - Test Loss 0.453375 - Test Accuracy 0.569408\n",
      "Epoch 813/1000 - 5.046903s - Loss 0.468911 - Accuracy 0.421875 - Test Loss 0.453272 - Test Accuracy 0.568523\n",
      "Epoch 814/1000 - 5.046345s - Loss 0.426747 - Accuracy 0.489583 - Test Loss 0.452487 - Test Accuracy 0.567639\n",
      "Epoch 815/1000 - 5.053954s - Loss 0.536511 - Accuracy 0.354167 - Test Loss 0.452970 - Test Accuracy 0.568966\n",
      "Epoch 816/1000 - 5.066263s - Loss 0.470545 - Accuracy 0.473958 - Test Loss 0.452893 - Test Accuracy 0.569408\n",
      "Epoch 817/1000 - 5.043887s - Loss 0.483684 - Accuracy 0.458333 - Test Loss 0.452488 - Test Accuracy 0.569850\n",
      "Epoch 818/1000 - 5.059558s - Loss 0.376381 - Accuracy 0.604167 - Test Loss 0.452294 - Test Accuracy 0.570292\n",
      "Epoch 819/1000 - 5.041300s - Loss 0.466561 - Accuracy 0.473958 - Test Loss 0.452861 - Test Accuracy 0.568966\n",
      "Epoch 820/1000 - 5.061594s - Loss 0.375672 - Accuracy 0.536458 - Test Loss 0.453702 - Test Accuracy 0.569408\n",
      "Epoch 821/1000 - 5.049483s - Loss 0.415920 - Accuracy 0.468750 - Test Loss 0.453089 - Test Accuracy 0.571618\n",
      "-----***-----\n",
      "0.5716180371352785\n",
      "Epoch 822/1000 - 5.074238s - Loss 0.426339 - Accuracy 0.442708 - Test Loss 0.453189 - Test Accuracy 0.568966\n",
      "Epoch 823/1000 - 5.043496s - Loss 0.437284 - Accuracy 0.473958 - Test Loss 0.452757 - Test Accuracy 0.569850\n",
      "Epoch 824/1000 - 5.049449s - Loss 0.348109 - Accuracy 0.572917 - Test Loss 0.452305 - Test Accuracy 0.569408\n",
      "Epoch 825/1000 - 5.045291s - Loss 0.406986 - Accuracy 0.494792 - Test Loss 0.451597 - Test Accuracy 0.569850\n",
      "Epoch 826/1000 - 5.050069s - Loss 0.450451 - Accuracy 0.520833 - Test Loss 0.451997 - Test Accuracy 0.570734\n",
      "Epoch 827/1000 - 5.063457s - Loss 0.409240 - Accuracy 0.500000 - Test Loss 0.451068 - Test Accuracy 0.569408\n",
      "Epoch 828/1000 - 5.094005s - Loss 0.434931 - Accuracy 0.463542 - Test Loss 0.451318 - Test Accuracy 0.568523\n",
      "Epoch 829/1000 - 5.071164s - Loss 0.358280 - Accuracy 0.593750 - Test Loss 0.451427 - Test Accuracy 0.570734\n",
      "Epoch 830/1000 - 5.082984s - Loss 0.414736 - Accuracy 0.557292 - Test Loss 0.451472 - Test Accuracy 0.570734\n",
      "Epoch 831/1000 - 5.060622s - Loss 0.514416 - Accuracy 0.416667 - Test Loss 0.451541 - Test Accuracy 0.569408\n",
      "Epoch 832/1000 - 5.064904s - Loss 0.410242 - Accuracy 0.463542 - Test Loss 0.451465 - Test Accuracy 0.567639\n",
      "Epoch 833/1000 - 5.063737s - Loss 0.408986 - Accuracy 0.562500 - Test Loss 0.451572 - Test Accuracy 0.568523\n",
      "Epoch 834/1000 - 5.072263s - Loss 0.491589 - Accuracy 0.369792 - Test Loss 0.451561 - Test Accuracy 0.568966\n",
      "Epoch 835/1000 - 5.046109s - Loss 0.456561 - Accuracy 0.468750 - Test Loss 0.451423 - Test Accuracy 0.568523\n",
      "Epoch 836/1000 - 5.063706s - Loss 0.482357 - Accuracy 0.463542 - Test Loss 0.451058 - Test Accuracy 0.568523\n",
      "Epoch 837/1000 - 5.089353s - Loss 0.495359 - Accuracy 0.500000 - Test Loss 0.450385 - Test Accuracy 0.567639\n",
      "Epoch 838/1000 - 5.086357s - Loss 0.434164 - Accuracy 0.484375 - Test Loss 0.451213 - Test Accuracy 0.571618\n",
      "Epoch 839/1000 - 5.060267s - Loss 0.377873 - Accuracy 0.541667 - Test Loss 0.449892 - Test Accuracy 0.569850\n",
      "Epoch 840/1000 - 5.079428s - Loss 0.396933 - Accuracy 0.473958 - Test Loss 0.449347 - Test Accuracy 0.569408\n",
      "Epoch 841/1000 - 5.052459s - Loss 0.433820 - Accuracy 0.531250 - Test Loss 0.449551 - Test Accuracy 0.570292\n",
      "Epoch 842/1000 - 5.086835s - Loss 0.458267 - Accuracy 0.458333 - Test Loss 0.449636 - Test Accuracy 0.568523\n",
      "Epoch 843/1000 - 5.072621s - Loss 0.324146 - Accuracy 0.614583 - Test Loss 0.449343 - Test Accuracy 0.569408\n",
      "Epoch 844/1000 - 5.063422s - Loss 0.444230 - Accuracy 0.489583 - Test Loss 0.449598 - Test Accuracy 0.569408\n",
      "Epoch 845/1000 - 5.067938s - Loss 0.445044 - Accuracy 0.473958 - Test Loss 0.449772 - Test Accuracy 0.570292\n",
      "Epoch 846/1000 - 5.091607s - Loss 0.460456 - Accuracy 0.453125 - Test Loss 0.450216 - Test Accuracy 0.571176\n",
      "Epoch 847/1000 - 5.056363s - Loss 0.464438 - Accuracy 0.442708 - Test Loss 0.449105 - Test Accuracy 0.568966\n",
      "Epoch 848/1000 - 5.060759s - Loss 0.424490 - Accuracy 0.541667 - Test Loss 0.449657 - Test Accuracy 0.569408\n",
      "Epoch 849/1000 - 5.081198s - Loss 0.386510 - Accuracy 0.583333 - Test Loss 0.449671 - Test Accuracy 0.568966\n",
      "Epoch 850/1000 - 5.065597s - Loss 0.405314 - Accuracy 0.515625 - Test Loss 0.449929 - Test Accuracy 0.567639\n",
      "Epoch 851/1000 - 5.063387s - Loss 0.384690 - Accuracy 0.500000 - Test Loss 0.449834 - Test Accuracy 0.568081\n",
      "Epoch 852/1000 - 5.090939s - Loss 0.461979 - Accuracy 0.453125 - Test Loss 0.450041 - Test Accuracy 0.569408\n",
      "Epoch 853/1000 - 5.057360s - Loss 0.437339 - Accuracy 0.484375 - Test Loss 0.450136 - Test Accuracy 0.569408\n",
      "Epoch 854/1000 - 5.090613s - Loss 0.330949 - Accuracy 0.578125 - Test Loss 0.450547 - Test Accuracy 0.567639\n",
      "Epoch 855/1000 - 5.066500s - Loss 0.374874 - Accuracy 0.526042 - Test Loss 0.450889 - Test Accuracy 0.569408\n",
      "Epoch 856/1000 - 5.098613s - Loss 0.367671 - Accuracy 0.520833 - Test Loss 0.449589 - Test Accuracy 0.569850\n",
      "Epoch 857/1000 - 5.057868s - Loss 0.415267 - Accuracy 0.468750 - Test Loss 0.449547 - Test Accuracy 0.568081\n",
      "Epoch 858/1000 - 5.074280s - Loss 0.419477 - Accuracy 0.468750 - Test Loss 0.449446 - Test Accuracy 0.568081\n",
      "Epoch 859/1000 - 5.065919s - Loss 0.412944 - Accuracy 0.500000 - Test Loss 0.449511 - Test Accuracy 0.567639\n",
      "Epoch 860/1000 - 5.063965s - Loss 0.425796 - Accuracy 0.489583 - Test Loss 0.450670 - Test Accuracy 0.566313\n",
      "Epoch 861/1000 - 5.093109s - Loss 0.475471 - Accuracy 0.447917 - Test Loss 0.449666 - Test Accuracy 0.569408\n",
      "Epoch 862/1000 - 5.071481s - Loss 0.390861 - Accuracy 0.515625 - Test Loss 0.447925 - Test Accuracy 0.568523\n",
      "Epoch 863/1000 - 5.242522s - Loss 0.434121 - Accuracy 0.531250 - Test Loss 0.449111 - Test Accuracy 0.568523\n",
      "Epoch 864/1000 - 5.056818s - Loss 0.417434 - Accuracy 0.484375 - Test Loss 0.448817 - Test Accuracy 0.568081\n",
      "Epoch 865/1000 - 5.057801s - Loss 0.448046 - Accuracy 0.494792 - Test Loss 0.449359 - Test Accuracy 0.568966\n",
      "Epoch 866/1000 - 5.061822s - Loss 0.379889 - Accuracy 0.557292 - Test Loss 0.449062 - Test Accuracy 0.569850\n",
      "Epoch 867/1000 - 5.065253s - Loss 0.396905 - Accuracy 0.458333 - Test Loss 0.449061 - Test Accuracy 0.565871\n",
      "Epoch 868/1000 - 5.054374s - Loss 0.465926 - Accuracy 0.500000 - Test Loss 0.448769 - Test Accuracy 0.568966\n",
      "Epoch 869/1000 - 5.070383s - Loss 0.386676 - Accuracy 0.557292 - Test Loss 0.448810 - Test Accuracy 0.572060\n",
      "-----***-----\n",
      "0.5720601237842617\n",
      "Epoch 870/1000 - 5.055146s - Loss 0.426114 - Accuracy 0.526042 - Test Loss 0.448239 - Test Accuracy 0.570734\n",
      "Epoch 871/1000 - 5.081243s - Loss 0.502766 - Accuracy 0.437500 - Test Loss 0.448323 - Test Accuracy 0.569408\n",
      "Epoch 872/1000 - 5.057900s - Loss 0.379884 - Accuracy 0.572917 - Test Loss 0.448055 - Test Accuracy 0.568081\n",
      "Epoch 873/1000 - 5.096679s - Loss 0.339543 - Accuracy 0.536458 - Test Loss 0.447626 - Test Accuracy 0.567639\n",
      "Epoch 874/1000 - 5.058497s - Loss 0.381022 - Accuracy 0.567708 - Test Loss 0.448112 - Test Accuracy 0.568523\n",
      "Epoch 875/1000 - 5.078785s - Loss 0.390969 - Accuracy 0.510417 - Test Loss 0.448358 - Test Accuracy 0.569408\n",
      "Epoch 876/1000 - 5.059455s - Loss 0.417886 - Accuracy 0.453125 - Test Loss 0.448454 - Test Accuracy 0.572502\n",
      "-----***-----\n",
      "0.5725022104332449\n",
      "Epoch 877/1000 - 5.062616s - Loss 0.409031 - Accuracy 0.520833 - Test Loss 0.449058 - Test Accuracy 0.569850\n",
      "Epoch 878/1000 - 5.067832s - Loss 0.409574 - Accuracy 0.531250 - Test Loss 0.448227 - Test Accuracy 0.570734\n",
      "Epoch 879/1000 - 5.062380s - Loss 0.521963 - Accuracy 0.390625 - Test Loss 0.447806 - Test Accuracy 0.568966\n",
      "Epoch 880/1000 - 5.064559s - Loss 0.362630 - Accuracy 0.510417 - Test Loss 0.447645 - Test Accuracy 0.569408\n",
      "Epoch 881/1000 - 5.062528s - Loss 0.406637 - Accuracy 0.552083 - Test Loss 0.447795 - Test Accuracy 0.567639\n",
      "Epoch 882/1000 - 5.060739s - Loss 0.425031 - Accuracy 0.557292 - Test Loss 0.447942 - Test Accuracy 0.569850\n",
      "Epoch 883/1000 - 5.083517s - Loss 0.424137 - Accuracy 0.479167 - Test Loss 0.447613 - Test Accuracy 0.570292\n",
      "Epoch 884/1000 - 5.062062s - Loss 0.392252 - Accuracy 0.531250 - Test Loss 0.447300 - Test Accuracy 0.568523\n",
      "Epoch 885/1000 - 5.091210s - Loss 0.441022 - Accuracy 0.484375 - Test Loss 0.448229 - Test Accuracy 0.570734\n",
      "Epoch 886/1000 - 5.078140s - Loss 0.392408 - Accuracy 0.541667 - Test Loss 0.447700 - Test Accuracy 0.569408\n",
      "Epoch 887/1000 - 5.070278s - Loss 0.422317 - Accuracy 0.510417 - Test Loss 0.448317 - Test Accuracy 0.569850\n",
      "Epoch 888/1000 - 5.066778s - Loss 0.383736 - Accuracy 0.557292 - Test Loss 0.447986 - Test Accuracy 0.567197\n",
      "Epoch 889/1000 - 5.073315s - Loss 0.459510 - Accuracy 0.458333 - Test Loss 0.447777 - Test Accuracy 0.568966\n",
      "Epoch 890/1000 - 5.055331s - Loss 0.441790 - Accuracy 0.468750 - Test Loss 0.447002 - Test Accuracy 0.569408\n",
      "Epoch 891/1000 - 5.085407s - Loss 0.367501 - Accuracy 0.598958 - Test Loss 0.447731 - Test Accuracy 0.568081\n",
      "Epoch 892/1000 - 5.083086s - Loss 0.350588 - Accuracy 0.572917 - Test Loss 0.447294 - Test Accuracy 0.569408\n",
      "Epoch 893/1000 - 5.067811s - Loss 0.409604 - Accuracy 0.505208 - Test Loss 0.446535 - Test Accuracy 0.569850\n",
      "Epoch 894/1000 - 5.070060s - Loss 0.450933 - Accuracy 0.510417 - Test Loss 0.447476 - Test Accuracy 0.569850\n",
      "Epoch 895/1000 - 5.049213s - Loss 0.396410 - Accuracy 0.505208 - Test Loss 0.446564 - Test Accuracy 0.569850\n",
      "Epoch 896/1000 - 5.049010s - Loss 0.391951 - Accuracy 0.479167 - Test Loss 0.446956 - Test Accuracy 0.568523\n",
      "Epoch 897/1000 - 5.077382s - Loss 0.402189 - Accuracy 0.484375 - Test Loss 0.447061 - Test Accuracy 0.568523\n",
      "Epoch 898/1000 - 5.057478s - Loss 0.406282 - Accuracy 0.526042 - Test Loss 0.447213 - Test Accuracy 0.569850\n",
      "Epoch 899/1000 - 5.078622s - Loss 0.441912 - Accuracy 0.494792 - Test Loss 0.446641 - Test Accuracy 0.568523\n",
      "Epoch 900/1000 - 5.055846s - Loss 0.383393 - Accuracy 0.520833 - Test Loss 0.446767 - Test Accuracy 0.565429\n",
      "Epoch 901/1000 - 5.103025s - Loss 0.422393 - Accuracy 0.442708 - Test Loss 0.447683 - Test Accuracy 0.566313\n",
      "Epoch 902/1000 - 5.063285s - Loss 0.425364 - Accuracy 0.520833 - Test Loss 0.446807 - Test Accuracy 0.568523\n",
      "Epoch 903/1000 - 5.070153s - Loss 0.428869 - Accuracy 0.453125 - Test Loss 0.446580 - Test Accuracy 0.568523\n",
      "Epoch 904/1000 - 5.071183s - Loss 0.413137 - Accuracy 0.489583 - Test Loss 0.446586 - Test Accuracy 0.569408\n",
      "Epoch 905/1000 - 5.072231s - Loss 0.410658 - Accuracy 0.541667 - Test Loss 0.447180 - Test Accuracy 0.572060\n",
      "Epoch 906/1000 - 5.062333s - Loss 0.429422 - Accuracy 0.520833 - Test Loss 0.447552 - Test Accuracy 0.568523\n",
      "Epoch 907/1000 - 5.062911s - Loss 0.418955 - Accuracy 0.473958 - Test Loss 0.446502 - Test Accuracy 0.568966\n",
      "Epoch 908/1000 - 5.083344s - Loss 0.459421 - Accuracy 0.505208 - Test Loss 0.445295 - Test Accuracy 0.569850\n",
      "Epoch 909/1000 - 5.066735s - Loss 0.392437 - Accuracy 0.536458 - Test Loss 0.445052 - Test Accuracy 0.572060\n",
      "Epoch 910/1000 - 5.049141s - Loss 0.423349 - Accuracy 0.567708 - Test Loss 0.445575 - Test Accuracy 0.572060\n",
      "Epoch 911/1000 - 5.081823s - Loss 0.366652 - Accuracy 0.552083 - Test Loss 0.445259 - Test Accuracy 0.571618\n",
      "Epoch 912/1000 - 5.063238s - Loss 0.371638 - Accuracy 0.494792 - Test Loss 0.445061 - Test Accuracy 0.572060\n",
      "Epoch 913/1000 - 5.116930s - Loss 0.407884 - Accuracy 0.510417 - Test Loss 0.445306 - Test Accuracy 0.570292\n",
      "Epoch 914/1000 - 5.059508s - Loss 0.472214 - Accuracy 0.468750 - Test Loss 0.445344 - Test Accuracy 0.571618\n",
      "Epoch 915/1000 - 5.074200s - Loss 0.408924 - Accuracy 0.500000 - Test Loss 0.445599 - Test Accuracy 0.571618\n",
      "Epoch 916/1000 - 5.065569s - Loss 0.449110 - Accuracy 0.500000 - Test Loss 0.444582 - Test Accuracy 0.568966\n",
      "Epoch 917/1000 - 5.074754s - Loss 0.424441 - Accuracy 0.531250 - Test Loss 0.445301 - Test Accuracy 0.572502\n",
      "Epoch 918/1000 - 5.068921s - Loss 0.380749 - Accuracy 0.583333 - Test Loss 0.445214 - Test Accuracy 0.572502\n",
      "Epoch 919/1000 - 5.061111s - Loss 0.353736 - Accuracy 0.531250 - Test Loss 0.444905 - Test Accuracy 0.570292\n",
      "Epoch 920/1000 - 5.047539s - Loss 0.425222 - Accuracy 0.494792 - Test Loss 0.445412 - Test Accuracy 0.571618\n",
      "Epoch 921/1000 - 5.062079s - Loss 0.435092 - Accuracy 0.489583 - Test Loss 0.445095 - Test Accuracy 0.569850\n",
      "Epoch 922/1000 - 5.060987s - Loss 0.405118 - Accuracy 0.520833 - Test Loss 0.445284 - Test Accuracy 0.569408\n",
      "Epoch 923/1000 - 5.082470s - Loss 0.375070 - Accuracy 0.572917 - Test Loss 0.445264 - Test Accuracy 0.568081\n",
      "Epoch 924/1000 - 5.075068s - Loss 0.370651 - Accuracy 0.531250 - Test Loss 0.444647 - Test Accuracy 0.568081\n",
      "Epoch 925/1000 - 5.070604s - Loss 0.410116 - Accuracy 0.515625 - Test Loss 0.444567 - Test Accuracy 0.567639\n",
      "Epoch 926/1000 - 5.057007s - Loss 0.401051 - Accuracy 0.567708 - Test Loss 0.445296 - Test Accuracy 0.570292\n",
      "Epoch 927/1000 - 5.052902s - Loss 0.364051 - Accuracy 0.526042 - Test Loss 0.444648 - Test Accuracy 0.567197\n",
      "Epoch 928/1000 - 5.067087s - Loss 0.421887 - Accuracy 0.505208 - Test Loss 0.445146 - Test Accuracy 0.570292\n",
      "Epoch 929/1000 - 5.058667s - Loss 0.361334 - Accuracy 0.614583 - Test Loss 0.445270 - Test Accuracy 0.569850\n",
      "Epoch 930/1000 - 5.060627s - Loss 0.395144 - Accuracy 0.510417 - Test Loss 0.445833 - Test Accuracy 0.570292\n",
      "Epoch 931/1000 - 5.089751s - Loss 0.374574 - Accuracy 0.536458 - Test Loss 0.445095 - Test Accuracy 0.571618\n",
      "Epoch 932/1000 - 5.064122s - Loss 0.336452 - Accuracy 0.546875 - Test Loss 0.445372 - Test Accuracy 0.570734\n",
      "Epoch 933/1000 - 5.085373s - Loss 0.382739 - Accuracy 0.541667 - Test Loss 0.444940 - Test Accuracy 0.570292\n",
      "Epoch 934/1000 - 5.064439s - Loss 0.392882 - Accuracy 0.531250 - Test Loss 0.444669 - Test Accuracy 0.570734\n",
      "Epoch 935/1000 - 5.085919s - Loss 0.372284 - Accuracy 0.583333 - Test Loss 0.444931 - Test Accuracy 0.570734\n",
      "Epoch 936/1000 - 5.075352s - Loss 0.431368 - Accuracy 0.489583 - Test Loss 0.444975 - Test Accuracy 0.572944\n",
      "-----***-----\n",
      "0.5729442970822282\n",
      "Epoch 937/1000 - 5.046122s - Loss 0.398428 - Accuracy 0.500000 - Test Loss 0.444735 - Test Accuracy 0.572060\n",
      "Epoch 938/1000 - 5.054411s - Loss 0.330923 - Accuracy 0.625000 - Test Loss 0.444935 - Test Accuracy 0.572060\n",
      "Epoch 939/1000 - 5.056650s - Loss 0.423869 - Accuracy 0.515625 - Test Loss 0.444874 - Test Accuracy 0.570292\n",
      "Epoch 940/1000 - 5.070028s - Loss 0.376539 - Accuracy 0.604167 - Test Loss 0.444202 - Test Accuracy 0.569850\n",
      "Epoch 941/1000 - 5.059136s - Loss 0.435788 - Accuracy 0.468750 - Test Loss 0.445123 - Test Accuracy 0.570292\n",
      "Epoch 942/1000 - 5.070392s - Loss 0.326723 - Accuracy 0.588542 - Test Loss 0.445114 - Test Accuracy 0.572060\n",
      "Epoch 943/1000 - 5.076905s - Loss 0.372146 - Accuracy 0.557292 - Test Loss 0.444974 - Test Accuracy 0.571618\n",
      "Epoch 944/1000 - 5.106997s - Loss 0.417010 - Accuracy 0.479167 - Test Loss 0.444841 - Test Accuracy 0.572060\n",
      "Epoch 945/1000 - 5.055149s - Loss 0.401458 - Accuracy 0.567708 - Test Loss 0.444914 - Test Accuracy 0.573386\n",
      "-----***-----\n",
      "0.5733863837312113\n",
      "Epoch 946/1000 - 5.072411s - Loss 0.419487 - Accuracy 0.453125 - Test Loss 0.444855 - Test Accuracy 0.572502\n",
      "Epoch 947/1000 - 5.049272s - Loss 0.348369 - Accuracy 0.588542 - Test Loss 0.445053 - Test Accuracy 0.571176\n",
      "Epoch 948/1000 - 5.088861s - Loss 0.390476 - Accuracy 0.546875 - Test Loss 0.444448 - Test Accuracy 0.574271\n",
      "-----***-----\n",
      "0.5742705570291777\n",
      "Epoch 949/1000 - 5.062225s - Loss 0.447740 - Accuracy 0.479167 - Test Loss 0.444285 - Test Accuracy 0.571618\n",
      "Epoch 950/1000 - 5.058873s - Loss 0.392368 - Accuracy 0.583333 - Test Loss 0.444712 - Test Accuracy 0.573386\n",
      "Epoch 951/1000 - 5.066419s - Loss 0.406347 - Accuracy 0.536458 - Test Loss 0.444337 - Test Accuracy 0.573828\n",
      "Epoch 952/1000 - 5.081821s - Loss 0.342061 - Accuracy 0.609375 - Test Loss 0.444166 - Test Accuracy 0.571176\n",
      "Epoch 953/1000 - 5.055874s - Loss 0.404838 - Accuracy 0.484375 - Test Loss 0.443924 - Test Accuracy 0.571176\n",
      "Epoch 954/1000 - 5.069403s - Loss 0.410271 - Accuracy 0.520833 - Test Loss 0.443592 - Test Accuracy 0.572944\n",
      "Epoch 955/1000 - 5.072434s - Loss 0.425796 - Accuracy 0.515625 - Test Loss 0.443691 - Test Accuracy 0.573386\n",
      "Epoch 956/1000 - 5.112941s - Loss 0.441430 - Accuracy 0.515625 - Test Loss 0.443569 - Test Accuracy 0.572060\n",
      "Epoch 957/1000 - 5.067114s - Loss 0.393556 - Accuracy 0.526042 - Test Loss 0.444215 - Test Accuracy 0.571176\n",
      "Epoch 958/1000 - 5.079362s - Loss 0.452613 - Accuracy 0.500000 - Test Loss 0.443875 - Test Accuracy 0.572060\n",
      "Epoch 959/1000 - 5.054615s - Loss 0.419769 - Accuracy 0.557292 - Test Loss 0.443990 - Test Accuracy 0.570292\n",
      "Epoch 960/1000 - 5.080745s - Loss 0.462125 - Accuracy 0.427083 - Test Loss 0.444019 - Test Accuracy 0.568966\n",
      "Epoch 961/1000 - 5.053903s - Loss 0.417140 - Accuracy 0.489583 - Test Loss 0.443481 - Test Accuracy 0.571618\n",
      "Epoch 962/1000 - 5.054101s - Loss 0.457274 - Accuracy 0.421875 - Test Loss 0.443139 - Test Accuracy 0.572060\n",
      "Epoch 963/1000 - 5.055571s - Loss 0.415061 - Accuracy 0.500000 - Test Loss 0.442785 - Test Accuracy 0.570734\n",
      "Epoch 964/1000 - 5.076332s - Loss 0.404787 - Accuracy 0.494792 - Test Loss 0.442274 - Test Accuracy 0.571618\n",
      "Epoch 965/1000 - 5.055022s - Loss 0.369937 - Accuracy 0.515625 - Test Loss 0.442209 - Test Accuracy 0.571618\n",
      "Epoch 966/1000 - 5.081341s - Loss 0.369997 - Accuracy 0.546875 - Test Loss 0.443148 - Test Accuracy 0.572502\n",
      "Epoch 967/1000 - 5.066289s - Loss 0.385990 - Accuracy 0.541667 - Test Loss 0.443630 - Test Accuracy 0.571176\n",
      "Epoch 968/1000 - 5.094827s - Loss 0.359057 - Accuracy 0.552083 - Test Loss 0.442494 - Test Accuracy 0.573828\n",
      "Epoch 969/1000 - 5.056666s - Loss 0.377793 - Accuracy 0.546875 - Test Loss 0.443081 - Test Accuracy 0.573828\n",
      "Epoch 970/1000 - 5.080550s - Loss 0.360548 - Accuracy 0.593750 - Test Loss 0.442385 - Test Accuracy 0.572060\n",
      "Epoch 971/1000 - 5.064929s - Loss 0.425735 - Accuracy 0.505208 - Test Loss 0.442815 - Test Accuracy 0.571176\n",
      "Epoch 972/1000 - 5.066953s - Loss 0.397450 - Accuracy 0.531250 - Test Loss 0.441840 - Test Accuracy 0.569850\n",
      "Epoch 973/1000 - 5.073034s - Loss 0.398039 - Accuracy 0.500000 - Test Loss 0.442816 - Test Accuracy 0.571618\n",
      "Epoch 974/1000 - 5.060601s - Loss 0.415688 - Accuracy 0.500000 - Test Loss 0.443254 - Test Accuracy 0.572944\n",
      "Epoch 975/1000 - 5.050740s - Loss 0.380110 - Accuracy 0.520833 - Test Loss 0.442943 - Test Accuracy 0.573828\n",
      "Epoch 976/1000 - 5.060673s - Loss 0.359538 - Accuracy 0.572917 - Test Loss 0.442975 - Test Accuracy 0.572502\n",
      "Epoch 977/1000 - 5.055363s - Loss 0.383906 - Accuracy 0.520833 - Test Loss 0.442571 - Test Accuracy 0.572060\n",
      "Epoch 978/1000 - 5.082443s - Loss 0.424497 - Accuracy 0.489583 - Test Loss 0.442739 - Test Accuracy 0.575597\n",
      "-----***-----\n",
      "0.5755968169761273\n",
      "Epoch 979/1000 - 5.069085s - Loss 0.369712 - Accuracy 0.593750 - Test Loss 0.442937 - Test Accuracy 0.574713\n",
      "Epoch 980/1000 - 5.074751s - Loss 0.390239 - Accuracy 0.526042 - Test Loss 0.443079 - Test Accuracy 0.574713\n",
      "Epoch 981/1000 - 5.054111s - Loss 0.395335 - Accuracy 0.541667 - Test Loss 0.443168 - Test Accuracy 0.572944\n",
      "Epoch 982/1000 - 5.054644s - Loss 0.369008 - Accuracy 0.531250 - Test Loss 0.443288 - Test Accuracy 0.572502\n",
      "Epoch 983/1000 - 5.058581s - Loss 0.437602 - Accuracy 0.484375 - Test Loss 0.443398 - Test Accuracy 0.572502\n",
      "Epoch 984/1000 - 5.079476s - Loss 0.365257 - Accuracy 0.567708 - Test Loss 0.442504 - Test Accuracy 0.572944\n",
      "Epoch 985/1000 - 5.082168s - Loss 0.443946 - Accuracy 0.468750 - Test Loss 0.441427 - Test Accuracy 0.571618\n",
      "Epoch 986/1000 - 5.080576s - Loss 0.374132 - Accuracy 0.562500 - Test Loss 0.442519 - Test Accuracy 0.572060\n",
      "Epoch 987/1000 - 5.054720s - Loss 0.366298 - Accuracy 0.526042 - Test Loss 0.442663 - Test Accuracy 0.572502\n",
      "Epoch 988/1000 - 5.073285s - Loss 0.349914 - Accuracy 0.546875 - Test Loss 0.442842 - Test Accuracy 0.572502\n",
      "Epoch 989/1000 - 5.051634s - Loss 0.400150 - Accuracy 0.557292 - Test Loss 0.441989 - Test Accuracy 0.572502\n",
      "Epoch 990/1000 - 5.070432s - Loss 0.392787 - Accuracy 0.526042 - Test Loss 0.442390 - Test Accuracy 0.572944\n",
      "Epoch 991/1000 - 5.065606s - Loss 0.351761 - Accuracy 0.567708 - Test Loss 0.441727 - Test Accuracy 0.572944\n",
      "Epoch 992/1000 - 5.060757s - Loss 0.453935 - Accuracy 0.500000 - Test Loss 0.443058 - Test Accuracy 0.574713\n",
      "Epoch 993/1000 - 5.060337s - Loss 0.390783 - Accuracy 0.567708 - Test Loss 0.442333 - Test Accuracy 0.572060\n",
      "Epoch 994/1000 - 5.058788s - Loss 0.388779 - Accuracy 0.604167 - Test Loss 0.442240 - Test Accuracy 0.575155\n",
      "Epoch 995/1000 - 5.046431s - Loss 0.369457 - Accuracy 0.619792 - Test Loss 0.442153 - Test Accuracy 0.572944\n",
      "Epoch 996/1000 - 5.081637s - Loss 0.363725 - Accuracy 0.552083 - Test Loss 0.442087 - Test Accuracy 0.573828\n",
      "Epoch 997/1000 - 5.056737s - Loss 0.368306 - Accuracy 0.567708 - Test Loss 0.442490 - Test Accuracy 0.572944\n",
      "Epoch 998/1000 - 5.071223s - Loss 0.391773 - Accuracy 0.526042 - Test Loss 0.440930 - Test Accuracy 0.572944\n",
      "Epoch 999/1000 - 5.061665s - Loss 0.317217 - Accuracy 0.609375 - Test Loss 0.441291 - Test Accuracy 0.572944\n",
      "repeat_0 [0.5755968169761273]\n",
      "{'repeat_0': {'0': {'precision': 0.2, 'recall': 0.0784313725490196, 'f1-score': 0.11267605633802816, 'support': 102}, '1': {'precision': 0.38271604938271603, 'recall': 0.23308270676691728, 'f1-score': 0.2897196261682243, 'support': 133}, '2': {'precision': 0.2222222222222222, 'recall': 0.10344827586206896, 'f1-score': 0.1411764705882353, 'support': 116}, '3': {'precision': 0.1875, 'recall': 0.1276595744680851, 'f1-score': 0.1518987341772152, 'support': 94}, '4': {'precision': 0.26666666666666666, 'recall': 0.11214953271028037, 'f1-score': 0.15789473684210525, 'support': 107}, '5': {'precision': 0.15384615384615385, 'recall': 0.05454545454545454, 'f1-score': 0.08053691275167785, 'support': 110}, '6': {'precision': 0.15, 'recall': 0.06060606060606061, 'f1-score': 0.08633093525179855, 'support': 99}, '7': {'precision': 0.2753623188405797, 'recall': 0.17272727272727273, 'f1-score': 0.2122905027932961, 'support': 110}, '8': {'precision': 0.25, 'recall': 0.14414414414414414, 'f1-score': 0.18285714285714286, 'support': 111}, 'micro avg': {'precision': 0.24596774193548387, 'recall': 0.12423625254582485, 'f1-score': 0.16508795669824086, 'support': 982}, 'macro avg': {'precision': 0.2320348234398154, 'recall': 0.12075493270881149, 'f1-score': 0.15726456864085817, 'support': 982}, 'weighted avg': {'precision': 0.23732207502500305, 'recall': 0.12423625254582485, 'f1-score': 0.16153796092349237, 'support': 982}, 'samples avg': {'precision': 0.043803418803418794, 'recall': 0.053934571175950484, 'f1-score': 0.04696433834364869, 'support': 982}}}\n",
      "{'repeat_0': {'0': {'precision': 0.2, 'recall': 0.0784313725490196, 'f1-score': 0.11267605633802816, 'support': 102}, '1': {'precision': 0.38271604938271603, 'recall': 0.23308270676691728, 'f1-score': 0.2897196261682243, 'support': 133}, '2': {'precision': 0.2222222222222222, 'recall': 0.10344827586206896, 'f1-score': 0.1411764705882353, 'support': 116}, '3': {'precision': 0.1875, 'recall': 0.1276595744680851, 'f1-score': 0.1518987341772152, 'support': 94}, '4': {'precision': 0.26666666666666666, 'recall': 0.11214953271028037, 'f1-score': 0.15789473684210525, 'support': 107}, '5': {'precision': 0.15384615384615385, 'recall': 0.05454545454545454, 'f1-score': 0.08053691275167785, 'support': 110}, '6': {'precision': 0.15, 'recall': 0.06060606060606061, 'f1-score': 0.08633093525179855, 'support': 99}, '7': {'precision': 0.2753623188405797, 'recall': 0.17272727272727273, 'f1-score': 0.2122905027932961, 'support': 110}, '8': {'precision': 0.25, 'recall': 0.14414414414414414, 'f1-score': 0.18285714285714286, 'support': 111}, 'micro avg': {'precision': 0.24596774193548387, 'recall': 0.12423625254582485, 'f1-score': 0.16508795669824086, 'support': 982}, 'macro avg': {'precision': 0.2320348234398154, 'recall': 0.12075493270881149, 'f1-score': 0.15726456864085817, 'support': 982}, 'weighted avg': {'precision': 0.23732207502500305, 'recall': 0.12423625254582485, 'f1-score': 0.16153796092349237, 'support': 982}, 'samples avg': {'precision': 0.043803418803418794, 'recall': 0.053934571175950484, 'f1-score': 0.04696433834364869, 'support': 982}}, 'accuracy': {'avg': 0.5755968169761273, 'std': 0.0}, 'time_train': {'avg': 5059.009657382965, 'std': 0.0}, 'time_test': {'avg': 0.4766092300415039, 'std': 0.0}, 'model': 'THAT', 'task': 'activity', 'data': {'num_users': ['0', '1', '2', '3', '4', '5'], 'wifi_band': ['2.4'], 'environment': ['classroom'], 'length': 3000}, 'nn': {'lr': 1e-06, 'epoch': 1000, 'batch_size': 64, 'threshold': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import torch\n",
    "gc.collect()           \n",
    "torch.cuda.empty_cache()  \n",
    "torch.cuda.ipc_collect()  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "[file]          run.py\n",
    "[description]   run WiFi-based models and optionally save a multiclass confusion matrix\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# from preset import preset, name_run\n",
    "# from load_data import load_data_x, load_data_y, encode_data_y\n",
    "# from lstm import run_lstm, LSTMM\n",
    "# from bilstm import run_bilstm, BiLSTMM\n",
    "# from that import run_that, THAT\n",
    "# from resnet import run_resnet, ResNet18Model\n",
    "# from strf import run_strf  # if you have the ST-RF implementation\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--model\",   default=preset[\"model\"],  type=str)\n",
    "    parser.add_argument(\"--task\",    default=preset[\"task\"],   type=str)\n",
    "    parser.add_argument(\"--repeat\",  default=preset[\"repeat\"], type=int)\n",
    "    parser.add_argument(\"--save_cm\", action=\"store_true\",\n",
    "                        help=\"Save a multiclass confusion matrix of the best model to PDF\")\n",
    "    args, _ = parser.parse_known_args()\n",
    "    return args\n",
    "\n",
    "def save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes):\n",
    "    \"\"\"\n",
    "    Given a model that outputs one-hot logits for a multiclass task,\n",
    "    convert to predicted classes via argmax, then plot and save a\n",
    "    num_classes × num_classes confusion matrix to pdf_path.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in data_loader:\n",
    "            xb = xb.to(device)\n",
    "            logits = model(xb)\n",
    "            # predicted class is index of max logit\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            trues = torch.argmax(yb, dim=1).cpu().numpy()\n",
    "            y_pred.extend(preds.tolist())\n",
    "            y_true.extend(trues.tolist())\n",
    "\n",
    "    labels = list(range(num_classes))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    disp.plot(ax=ax, xticks_rotation=\"vertical\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    with PdfPages(pdf_path) as pdf:\n",
    "        pdf.savefig(fig)\n",
    "    plt.close(fig)\n",
    "\n",
    "def run():\n",
    "    args       = parse_args()\n",
    "    var_model  = args.model\n",
    "    var_task   = args.task\n",
    "    var_repeat = args.repeat\n",
    "\n",
    "    # --- Load and encode the data ---\n",
    "    data_pd_y = load_data_y(\n",
    "        preset[\"path\"][\"data_y\"],\n",
    "        var_environment=preset[\"data\"][\"environment\"],\n",
    "        var_wifi_band=preset[\"data\"][\"wifi_band\"],\n",
    "        var_num_users=preset[\"data\"][\"num_users\"]\n",
    "    )\n",
    "    labels = data_pd_y[\"label\"].tolist()\n",
    "    data_x = load_data_x(preset[\"path\"][\"data_x\"], labels)\n",
    "    data_y = encode_data_y(data_pd_y, var_task)\n",
    "\n",
    "    train_x, test_x, train_y, test_y = train_test_split(\n",
    "        data_x, data_y, test_size=0.2, shuffle=True, random_state=39\n",
    "    )\n",
    "\n",
    "    # --- Select which model runner to use ---\n",
    "    if var_model == \"ST-RF\":\n",
    "        from strf import run_strf\n",
    "        run_model = run_strf\n",
    "    elif var_model == \"LSTM\":\n",
    "        run_model = run_lstm\n",
    "    elif var_model == \"bi-LSTM\":\n",
    "        run_model = run_bilstm\n",
    "    elif var_model == \"THAT\":\n",
    "        run_model = run_that\n",
    "    elif var_model == \"ResNet18\":\n",
    "        run_model = run_resnet\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {var_model}\")\n",
    "\n",
    "    # --- Train and evaluate ---\n",
    "    print(f\"Running model: {var_model}\")\n",
    "    result = run_model(train_x, train_y, test_x, test_y, var_repeat)\n",
    "    result[\"model\"] = var_model\n",
    "    result[\"task\"]  = var_task\n",
    "    result[\"data\"]  = preset[\"data\"]\n",
    "    result[\"nn\"]    = preset[\"nn\"]\n",
    "    print(result)\n",
    "\n",
    "    # --- Save results to JSON ---\n",
    "    # with open(preset[\"path\"][\"save\"], \"w\") as f:\n",
    "    #     json.dump(result, f, indent=4)\n",
    "\n",
    "    # # --- Optionally save a multiclass confusion matrix ---\n",
    "    # # if args.save_cm:\n",
    "    # if Confusion_matrix == 1:\n",
    "    #     # 1) completely release GPU memory used for training\n",
    "    #     del run_model                      # if 'model' from training is still in scope\n",
    "    #     torch.cuda.empty_cache()\n",
    "    #     torch.cuda.ipc_collect()\n",
    "    \n",
    "    #     # 2) reshape input only if the network is sequence‑based\n",
    "    #     if var_model in (\"LSTM\", \"bi-LSTM\", \"THAT\"):\n",
    "    #         test_x_cm = test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n",
    "    #     else:                           # ResNet18, ST‑RF\n",
    "    #         test_x_cm = test_x\n",
    "    \n",
    "    #     # 3) build the *same* architecture on CPU and load its weights\n",
    "    #     device_cm = torch.device(\"cpu\")\n",
    "    #     if var_model == \"LSTM\":\n",
    "    #         model_cm = LSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "    #     elif var_model == \"bi-LSTM\":\n",
    "    #         model_cm = BiLSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "    #     elif var_model == \"THAT\":\n",
    "    #         model_cm = THAT(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "    #     elif var_model == \"ResNet18\":\n",
    "    #         model_cm = ResNet18Model(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n",
    "    #     else:\n",
    "    #         raise ValueError(f\"Confusion matrix not supported for {var_model}\")\n",
    "    \n",
    "    #     # best_path = f\"/kaggle/working/{name_run}_best_model.pt\"\n",
    "    #     # model_cm.load_state_dict(torch.load(best_path, map_location=device_cm))\n",
    "    #     # model_cm.eval()\n",
    "    \n",
    "    #     # 4) DataLoader on CPU with a safe batch size\n",
    "    #     test_ds = TensorDataset(torch.from_numpy(test_x_cm).float(),\n",
    "    #                             torch.from_numpy(test_y).float())\n",
    "    #     test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "    \n",
    "    #     # 5) save the confusion matrix PDF\n",
    "    #     num_classes = test_y.shape[1]\n",
    "    #     pdf_name = f\"{name_run}_confusion_matrix.pdf\"\n",
    "    #     save_multiclass_confusion_matrix(model_cm,test_loader,device_cm,pdf_name,num_classes)\n",
    "    #     print(f\"✅ Saved confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"start\")\n",
    "    run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bf6ad",
   "metadata": {
    "papermill": {
     "duration": 0.04621,
     "end_time": "2025-12-28T18:53:43.612500",
     "exception": false,
     "start_time": "2025-12-28T18:53:43.566290",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "Cell 12: Few-shot Learning\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c465464f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:53:43.705358Z",
     "iopub.status.busy": "2025-12-28T18:53:43.705048Z",
     "iopub.status.idle": "2025-12-28T18:53:43.710991Z",
     "shell.execute_reply": "2025-12-28T18:53:43.710284Z"
    },
    "papermill": {
     "duration": 0.053645,
     "end_time": "2025-12-28T18:53:43.712064",
     "exception": false,
     "start_time": "2025-12-28T18:53:43.658419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gc\n",
    "# import torch\n",
    "# import shutil\n",
    "# import json\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# gc.collect()           \n",
    "# torch.cuda.empty_cache()  \n",
    "# torch.cuda.ipc_collect()\n",
    "\n",
    "# # ---------- helper: save multiclass confusion matrix ------------------\n",
    "# def save_multiclass_confusion_matrix(model, data_loader, pdf_path, num_classes):\n",
    "#     \"\"\"\n",
    "#     Forward‑pass on CPU, collect predictions, and write an N×N confusion matrix\n",
    "#     to a single‑page PDF (pdf_path).\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     y_true, y_pred = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in data_loader:\n",
    "#             logits = model(xb.cpu())                       # ensure CPU\n",
    "#             preds  = torch.argmax(logits, dim=1).numpy()\n",
    "#             trues  = torch.argmax(yb, dim=1).numpy()\n",
    "#             y_pred.extend(preds.tolist())\n",
    "#             y_true.extend(trues.tolist())\n",
    "\n",
    "#     labels = list(range(num_classes))\n",
    "#     cm  = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "#     disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "#     fig, ax = plt.subplots(figsize=(8, 8))\n",
    "#     disp.plot(ax=ax, xticks_rotation=\"vertical\")\n",
    "#     ax.set_title(\"Few‑shot Confusion Matrix\")\n",
    "#     with PdfPages(pdf_path) as pdf:\n",
    "#         pdf.savefig(fig)\n",
    "#     plt.close(fig)\n",
    "\n",
    "# # -------------------- pick run_* function ------------------------------\n",
    "# if preset[\"model\"] == \"ST-RF\":\n",
    "#     run_model = run_strf\n",
    "# elif preset[\"model\"] == \"LSTM\":\n",
    "#     run_model = run_lstm\n",
    "# elif preset[\"model\"] == \"bi-LSTM\":\n",
    "#     run_model = run_bilstm\n",
    "# elif preset[\"model\"] == \"THAT\":\n",
    "#     run_model = run_that\n",
    "# elif preset[\"model\"] == \"ResNet18\":\n",
    "#     run_model = run_resnet\n",
    "# else:\n",
    "#     raise ValueError(f\"No few‑shot implementation for {preset['model']}.\")\n",
    "\n",
    "# # ------------------------ load / split data ----------------------------\n",
    "# data_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n",
    "#                         var_environment=[dest_env],\n",
    "#                         var_wifi_band=preset[\"data\"][\"wifi_band\"],\n",
    "#                         var_num_users=preset[\"data\"][\"num_users\"])\n",
    "\n",
    "# labels_list = data_pd_y[\"label\"].tolist()\n",
    "# data_x = load_data_x(preset[\"path\"][\"data_x\"], labels_list)\n",
    "# data_y = encode_data_y(data_pd_y, preset[\"task\"])\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(\n",
    "#     data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n",
    "\n",
    "# # Few-shot sample size\n",
    "# train_x = train_x[:few_shot_num_samples]\n",
    "# train_y = train_y[:few_shot_num_samples]\n",
    "\n",
    "# # ----------------------- few‑shot training -----------------------------\n",
    "# original_epochs = preset[\"nn\"][\"epoch\"]\n",
    "# preset[\"nn\"][\"epoch\"] = few_shot_epochs\n",
    "\n",
    "# # Load the best model weights\n",
    "# best_model_path = f\"{name_run}_best_model.pt\"\n",
    "\n",
    "# # Initialize the model \n",
    "# if preset[\"model\"] == \"LSTM\":\n",
    "#     model = LSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "#     # print('train_y_[0].shape:', train_y[0].shape)\n",
    "#     # print('train_x_[0].shape:', train_x[0].reshape(train_x[0].shape[0], -1).shape)\n",
    "# elif preset[\"model\"] == \"bi-LSTM\":\n",
    "#     model = BiLSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "# elif preset[\"model\"] == \"THAT\":\n",
    "#     model = THAT(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "# elif preset[\"model\"] == \"ResNet18\":\n",
    "#     model = ResNet18Model(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n",
    "# else:\n",
    "#     raise ValueError(f\"Model {preset['model']} not supported!\")\n",
    "\n",
    "# # Load the weights into the model\n",
    "# model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n",
    "# model = model.to('cuda')\n",
    "\n",
    "# # Fine-tune the model on few-shot data (note: `run_model` should now return only the result)\n",
    "# result = run_model(train_x, train_y, test_x, test_y, var_repeat=1, init_model=model)\n",
    "# print(result)\n",
    "\n",
    "# # --------------------- save few‑shot checkpoints -----------------------\n",
    "# # After fine-tuning, save the model\n",
    "# torch.save(model.state_dict(), f\"{name_run}_fewshot_final_model.pt\")\n",
    "# torch.save(model.state_dict(), f\"{name_run}_fewshot_best_model.pt\")\n",
    "\n",
    "# # ------------------- confusion matrix on CPU ---------------------------\n",
    "# if Confusion_matrix == 1 and preset[\"model\"] != \"ST-RF\":\n",
    "\n",
    "#     # reshape for sequence models\n",
    "#     test_x_rs = (test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n",
    "#                  if preset[\"model\"] in (\"LSTM\", \"bi-LSTM\", \"THAT\") else test_x)\n",
    "\n",
    "#     # instantiate identical architecture on CPU\n",
    "#     if preset[\"model\"] == \"LSTM\":\n",
    "#         model_cpu = LSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "#     elif preset[\"model\"] == \"bi-LSTM\":\n",
    "#         model_cpu = BiLSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "#     elif preset[\"model\"] == \"THAT\":\n",
    "#         model_cpu = THAT(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "#     else:  # ResNet18\n",
    "#         model_cpu = ResNet18Model(test_x_rs[0].shape, test_y[0].shape).cpu()\n",
    "\n",
    "#     # load weights\n",
    "#     model_cpu.load_state_dict(torch.load(f\"{name_run}_fewshot_best_model.pt\", map_location=\"cpu\"))\n",
    "\n",
    "#     # CPU DataLoader with a safe batch size\n",
    "#     test_ds = TensorDataset(torch.from_numpy(test_x_rs).float(),\n",
    "#                             torch.from_numpy(test_y).float())\n",
    "#     test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n",
    "\n",
    "#     pdf_name = f\"{name_run}_fewshot_confusion_matrix.pdf\"\n",
    "#     num_classes = test_y.shape[1]\n",
    "#     save_multiclass_confusion_matrix(model_cpu, test_loader, pdf_name, num_classes)\n",
    "#     print(f\"✅ Saved few‑shot confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\n",
    "\n",
    "# # ----------------------- restore & persist -----------------------------\n",
    "# preset[\"nn\"][\"epoch\"] = original_epochs\n",
    "\n",
    "# # Save the final result to JSON\n",
    "# with open(\"result_fewshot.json\", \"w\") as f:\n",
    "#     json.dump(result, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "593ea035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T18:53:43.805453Z",
     "iopub.status.busy": "2025-12-28T18:53:43.805151Z",
     "iopub.status.idle": "2025-12-28T18:53:43.815085Z",
     "shell.execute_reply": "2025-12-28T18:53:43.814379Z"
    },
    "papermill": {
     "duration": 0.058426,
     "end_time": "2025-12-28T18:53:43.816289",
     "exception": false,
     "start_time": "2025-12-28T18:53:43.757863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import argparse\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import scipy.io as scio\n",
    "# import time\n",
    "# import torch\n",
    "# import gc\n",
    "# from numpy.linalg import svd\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "# from copy import deepcopy\n",
    "# import json\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# import torch._dynamo\n",
    "# from matplotlib.backends.backend_pdf import PdfPages\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # --- تنظیمات سیستمی ---\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# # --------------------------\n",
    "# # 1. تنظیمات (Configuration)\n",
    "# # --------------------------\n",
    "# preset = {\n",
    "#     \"model\": \"THAT\",          \n",
    "#     \"task\": \"activity\",       \n",
    "#     \"repeat\": 1,\n",
    "#     \"path\": {\n",
    "#         \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   \n",
    "#         \"data_y\": \"/kaggle/input/wimans/annotation.csv\", \n",
    "#     },\n",
    "#     \"data\": {\n",
    "#         \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  \n",
    "#         \"wifi_band\": [\"2.4\"],                         \n",
    "#         \"environment\": [\"classroom\"],                 \n",
    "#         \"length\": 3000,\n",
    "        \n",
    "#         # 1.0 = 100% data (Full run) | 0.1 = 10% data (Quick test)\n",
    "#         \"subset_ratio\": 0.5,  \n",
    "#     },\n",
    "#     \"nn\": {\n",
    "#         \"lr\": 1e-3,           \n",
    "#         \"epoch\": 80,          \n",
    "#         \"batch_size\": 32,    \n",
    "#         \"threshold\": 0.5,\n",
    "#         \"patience\": 5,        \n",
    "#         \"factor\": 0.5,        \n",
    "#         \"min_lr\": 1e-6        \n",
    "#     },\n",
    "#     \"encoding\": {\n",
    "#         \"activity\": {\n",
    "#             \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#             \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "#             \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "#             \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "#             \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "#             \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "#             \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "#             \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "#             \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "#             \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "#         },\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # --------------------------\n",
    "# # 2. توابع RPCA و لود دیتا\n",
    "# # --------------------------\n",
    "# def soft_threshold(x, epsilon):\n",
    "#     return np.maximum(np.abs(x) - epsilon, 0) * np.sign(x)\n",
    "\n",
    "# def robust_pca(M, max_iter=10, tol=1e-4):\n",
    "#     n1, n2 = M.shape\n",
    "#     lambda_param = 1 / np.sqrt(max(n1, n2))\n",
    "#     Y = M / np.maximum(np.linalg.norm(M, 2), np.linalg.norm(M, np.inf) / lambda_param)\n",
    "#     L = np.zeros_like(M)\n",
    "#     S = np.zeros_like(M)\n",
    "#     mu = 1.25 / np.linalg.norm(M, 2)\n",
    "#     rho = 1.5\n",
    "#     for i in range(max_iter):\n",
    "#         temp_L = M - S + (1/mu) * Y\n",
    "#         U, Sigma, Vt = svd(temp_L, full_matrices=False)\n",
    "#         Sigma_thresh = soft_threshold(Sigma, 1/mu)\n",
    "#         L_new = np.dot(U * Sigma_thresh, Vt)\n",
    "#         temp_S = M - L_new + (1/mu) * Y\n",
    "#         S_new = soft_threshold(temp_S, lambda_param/mu)\n",
    "#         error = np.linalg.norm(M - L_new - S_new, 'fro') / np.linalg.norm(M, 'fro')\n",
    "#         L = L_new; S = S_new\n",
    "#         if error < tol: break\n",
    "#         Y = Y + mu * (M - L - S)\n",
    "#         mu = min(mu * rho, 1e7)\n",
    "#     return L, S\n",
    "\n",
    "# def load_data_y(var_path_data_y, var_environment=None, var_wifi_band=None, var_num_users=None):\n",
    "#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n",
    "#     if var_environment is not None: data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "#     if var_wifi_band is not None: data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "#     if var_num_users is not None: data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "#     return data_pd_y\n",
    "\n",
    "# def load_data_x(var_path_data_x, var_label_list, use_rpca=True):\n",
    "#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "#     data_x = []\n",
    "#     mode_str = \"WITH RPCA\" if use_rpca else \"RAW DATA (No RPCA)\"\n",
    "#     print(f\"Loading {len(var_path_list)} samples - Mode: {mode_str}...\")\n",
    "#     for i, var_path in enumerate(var_path_list):\n",
    "#         if i % 100 == 0 and i > 0: print(f\"Processing {i}/{len(var_path_list)}...\")\n",
    "#         data_csi = np.load(var_path) \n",
    "#         data_csi_2d = data_csi.reshape(data_csi.shape[0], -1)\n",
    "#         target_len = preset[\"data\"][\"length\"]\n",
    "#         current_len = data_csi_2d.shape[0]\n",
    "#         var_pad_length = target_len - current_len\n",
    "#         if var_pad_length > 0: data_csi_pad = np.pad(data_csi_2d, ((0, var_pad_length), (0, 0)), mode='constant')\n",
    "#         else: data_csi_pad = data_csi_2d[:target_len, :]\n",
    "#         if use_rpca:\n",
    "#             L, S = robust_pca(data_csi_pad)\n",
    "#             final_sample = np.concatenate([L, S], axis=1) \n",
    "#         else:\n",
    "#             final_sample = data_csi_pad\n",
    "#         data_x.append(final_sample)\n",
    "#     data_x = np.array(data_x)\n",
    "#     return data_x\n",
    "\n",
    "# def encode_data_y(data_pd_y, var_task):\n",
    "#     if var_task == \"activity\": return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "#     return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "\n",
    "# def encode_activity(data_pd_y, var_encoding):\n",
    "#     cols = [f\"user_{i}_activity\" for i in range(1, 7)]\n",
    "#     data = data_pd_y[cols].to_numpy(copy=True).astype(str)\n",
    "#     return np.array([[var_encoding[y] for y in sample] for sample in data])\n",
    "\n",
    "# # --------------------------\n",
    "# # 3. مدل THAT\n",
    "# # --------------------------\n",
    "# class Gaussian_Position(torch.nn.Module):\n",
    "#     def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n",
    "#         super(Gaussian_Position, self).__init__()\n",
    "#         self.var_embedding = torch.nn.Parameter(torch.zeros([var_num_gaussian, var_dim_feature]), requires_grad=True)\n",
    "#         torch.nn.init.xavier_uniform_(self.var_embedding)\n",
    "#         self.var_position = torch.nn.Parameter(torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian), requires_grad=False)\n",
    "#         self.var_mu = torch.nn.Parameter(torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0), requires_grad=True)\n",
    "#         self.var_sigma = torch.nn.Parameter(torch.tensor([50.0] * var_num_gaussian).unsqueeze(0), requires_grad=True)\n",
    "#     def forward(self, var_input):\n",
    "#         var_pdf = - (self.var_position - self.var_mu)**2 / (2 * self.var_sigma**2) - torch.log(self.var_sigma)\n",
    "#         var_pdf = torch.softmax(var_pdf, dim=-1)\n",
    "#         return var_input + torch.matmul(var_pdf, self.var_embedding).unsqueeze(0)\n",
    "\n",
    "# class Encoder(torch.nn.Module):\n",
    "#     def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n",
    "#         super(Encoder, self).__init__()\n",
    "#         self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n",
    "#         self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n",
    "#         self.layer_dropout_0 = torch.nn.Dropout(0.1)\n",
    "#         self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n",
    "#         self.layer_cnn = torch.nn.ModuleList([torch.nn.Sequential(torch.nn.Conv1d(var_dim_feature, var_dim_feature, s, padding=\"same\"), torch.nn.BatchNorm1d(var_dim_feature), torch.nn.Dropout(0.1), torch.nn.LeakyReLU()) for s in var_size_cnn])\n",
    "#         self.layer_dropout_1 = torch.nn.Dropout(0.1)\n",
    "#     def forward(self, var_input):\n",
    "#         var_t = self.layer_norm_0(var_input)\n",
    "#         var_t, _ = self.layer_attention(var_t, var_t, var_t)\n",
    "#         var_t = self.layer_dropout_0(var_t) + var_input\n",
    "#         var_s = self.layer_norm_1(var_t).permute(0, 2, 1)\n",
    "#         var_c = torch.stack([l(var_s) for l in self.layer_cnn], dim=0)\n",
    "#         var_s = self.layer_dropout_1((torch.sum(var_c, dim=0) / len(self.layer_cnn)).permute(0, 2, 1))\n",
    "#         return var_s + var_t\n",
    "\n",
    "# class THAT(torch.nn.Module):\n",
    "#     def __init__(self, var_x_shape, var_y_shape):\n",
    "#         super(THAT, self).__init__()\n",
    "#         var_dim_feature, var_dim_time = var_x_shape[-1], var_x_shape[-2]\n",
    "#         var_dim_output = var_y_shape[-1]\n",
    "#         self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "#         self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n",
    "#         self.layer_left_encoder = torch.nn.ModuleList([Encoder(var_dim_feature, 10, [1, 3, 5]) for _ in range(4)])\n",
    "#         self.layer_left_norm = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n",
    "#         self.layer_left_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_feature, 128, k) for k in [8, 16]])\n",
    "#         self.layer_left_dropout = torch.nn.Dropout(0.5)\n",
    "#         var_dim_right = var_dim_time // 20\n",
    "#         self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n",
    "#         self.layer_right_encoder = torch.nn.ModuleList([Encoder(var_dim_right, 10, [1, 2, 3])])\n",
    "#         self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n",
    "#         self.layer_right_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_right, 16, k) for k in [2, 4]])\n",
    "#         self.layer_right_dropout = torch.nn.Dropout(0.5)\n",
    "#         self.layer_leakyrelu = torch.nn.LeakyReLU()\n",
    "#         self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n",
    "#     def forward(self, var_input):\n",
    "#         v_l = self.layer_left_gaussian(self.layer_left_pooling(var_input.permute(0, 2, 1)).permute(0, 2, 1))\n",
    "#         for l in self.layer_left_encoder: v_l = l(v_l)\n",
    "#         v_l = self.layer_left_norm(v_l).permute(0, 2, 1)\n",
    "#         v_l = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_l)), dim=-1) for cnn in self.layer_left_cnn], dim=-1)\n",
    "#         v_l = self.layer_left_dropout(v_l)\n",
    "#         v_r = self.layer_right_pooling(var_input.permute(0, 2, 1))\n",
    "#         for l in self.layer_right_encoder: v_r = l(v_r)\n",
    "#         v_r = self.layer_right_norm(v_r).permute(0, 2, 1)\n",
    "#         v_r = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_r)), dim=-1) for cnn in self.layer_right_cnn], dim=-1)\n",
    "#         v_r = self.layer_right_dropout(v_r)\n",
    "#         return self.layer_output(torch.cat([v_l, v_r], dim=-1))\n",
    "\n",
    "# # --------------------------\n",
    "# # 4. Training Loop\n",
    "# # --------------------------\n",
    "# def train(model, optimizer, loss_fn, train_loader, test_loader, threshold, epochs, device, model_path):\n",
    "#     best_acc = -1.0\n",
    "#     best_w = deepcopy(model.state_dict())\n",
    "    \n",
    "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "#         optimizer, mode='max', factor=preset[\"nn\"][\"factor\"], patience=preset[\"nn\"][\"patience\"],\n",
    "#         min_lr=preset[\"nn\"][\"min_lr\"], verbose=True\n",
    "#     )\n",
    "    \n",
    "#     for epoch in range(epochs):\n",
    "#         t0 = time.time()\n",
    "#         model.train()\n",
    "        \n",
    "#         # --- [MODIFIED] Using requested variable names ---\n",
    "#         for data_batch_x, data_batch_y in train_loader:\n",
    "#             data_batch_x = data_batch_x.to(device)\n",
    "#             data_batch_y = data_batch_y.to(device)\n",
    "            \n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#             predict_train_y = model(data_batch_x)\n",
    "            \n",
    "#             # --- [REQUESTED LINE] ---\n",
    "#             loss_value = loss_fn(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n",
    "            \n",
    "#             loss_value.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             tx, ty = next(iter(test_loader))\n",
    "#             tx, ty = tx.to(device), ty.to(device)\n",
    "#             pred_t = model(tx)\n",
    "            \n",
    "#             p_cls = (torch.sigmoid(pred_t) > threshold).float().cpu().numpy()\n",
    "#             t_cls = ty.cpu().numpy()\n",
    "#             acc = accuracy_score(t_cls.reshape(-1, t_cls.shape[-1]), p_cls.reshape(-1, t_cls.shape[-1]))\n",
    "            \n",
    "#         scheduler.step(acc)\n",
    "#         current_lr = optimizer.param_groups[0]['lr']\n",
    "#         print(f\"Ep {epoch+1}/{epochs} | LR: {current_lr:.6f} | L_tr: {loss_value.item():.4f} | Acc: {acc:.4f}\")\n",
    "        \n",
    "#         if acc > best_acc:\n",
    "#             best_acc = acc\n",
    "#             best_w = deepcopy(model.state_dict())\n",
    "            \n",
    "#     torch.save(best_w, model_path)\n",
    "#     return best_w\n",
    "\n",
    "# def save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes, title_text):\n",
    "#     model.eval()\n",
    "#     y_true, y_pred = [], []\n",
    "#     with torch.no_grad():\n",
    "#         for xb, yb in data_loader:\n",
    "#             xb = xb.to(device)\n",
    "#             logits = model(xb) \n",
    "#             logits = logits.reshape(-1, num_classes) \n",
    "#             yb = yb.reshape(-1, num_classes)        \n",
    "#             y_pred.extend(torch.argmax(logits, dim=1).cpu().numpy().tolist())\n",
    "#             y_true.extend(torch.argmax(yb, dim=1).cpu().numpy().tolist())\n",
    "    \n",
    "#     labels = list(range(num_classes))\n",
    "#     cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "#     disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n",
    "#     fig, ax = plt.subplots(figsize=(12, 12))\n",
    "#     disp.plot(ax=ax, xticks_rotation=\"vertical\", cmap='Blues')\n",
    "#     ax.set_title(title_text)\n",
    "#     with PdfPages(pdf_path) as pdf: pdf.savefig(fig)\n",
    "#     plt.close(fig)\n",
    "\n",
    "# # --------------------------\n",
    "# # 5. اجرا\n",
    "# # --------------------------\n",
    "# def run_experiment(scenario_name, use_rpca):\n",
    "#     print(f\"\\n################################################\")\n",
    "#     print(f\"STARTING SCENARIO: {scenario_name}\")\n",
    "#     print(f\"################################################\")\n",
    "    \n",
    "#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#     current_run_name = f\"{preset['model']}_{preset['task']}_{scenario_name}\"\n",
    "#     model_save_path = f\"{current_run_name}_best_model.pt\"\n",
    "#     json_save_path = f\"result_{current_run_name}.json\"\n",
    "#     pdf_save_path = f\"Confusion_{current_run_name}.pdf\"\n",
    "    \n",
    "#     # 1. Load Labels\n",
    "#     data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], preset[\"data\"][\"environment\"], preset[\"data\"][\"wifi_band\"], preset[\"data\"][\"num_users\"])\n",
    "    \n",
    "#     # Apply Subset Ratio\n",
    "#     subset_ratio = preset[\"data\"][\"subset_ratio\"]\n",
    "#     if subset_ratio < 1.0:\n",
    "#         data_pd_y = data_pd_y.sample(frac=subset_ratio, random_state=42).reset_index(drop=True)\n",
    "#         print(f\"*** DEBUG MODE: Using {subset_ratio*100}% of data ({len(data_pd_y)} samples) ***\")\n",
    "    \n",
    "#     # 2. Load X\n",
    "#     data_x = load_data_x(preset[\"path\"][\"data_x\"], data_pd_y[\"label\"].tolist(), use_rpca=use_rpca)\n",
    "#     data_y = encode_data_y(data_pd_y, preset[\"task\"])\n",
    "    \n",
    "#     # 3. Split\n",
    "#     train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n",
    "#     train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "#     test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "#     train_loader = DataLoader(train_ds, batch_size=preset[\"nn\"][\"batch_size\"], shuffle=True)\n",
    "#     test_loader = DataLoader(test_ds, batch_size=len(test_ds), shuffle=False)\n",
    "    \n",
    "#     result = {\"accuracy\": []}\n",
    "    \n",
    "#     for r in range(preset[\"repeat\"]):\n",
    "#         print(f\"--- Repeat {r+1}/{preset['repeat']} ---\")\n",
    "#         torch.random.manual_seed(r + 39)\n",
    "        \n",
    "#         model = THAT(train_x[0].shape, train_y[0].reshape(-1).shape).to(device)\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=preset[\"nn\"][\"lr\"])\n",
    "#         loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "#         best_w = train(model, optimizer, loss_fn, train_loader, test_loader, \n",
    "#                        preset[\"nn\"][\"threshold\"], preset[\"nn\"][\"epoch\"], device, model_save_path)\n",
    "        \n",
    "#         model.load_state_dict(best_w)\n",
    "#         with torch.no_grad():\n",
    "#             preds = model(torch.from_numpy(test_x).to(device))\n",
    "#             preds_reshaped = (torch.sigmoid(preds) > preset[\"nn\"][\"threshold\"]).float().cpu().numpy().reshape(-1, 9)\n",
    "#             targets_reshaped = test_y.reshape(-1, 9)\n",
    "#             acc = accuracy_score(targets_reshaped, preds_reshaped)\n",
    "#             result[\"accuracy\"].append(acc)\n",
    "            \n",
    "#     print(f\"Final Accuracy ({scenario_name}): {np.mean(result['accuracy']):.4f}\")\n",
    "#     with open(json_save_path, \"w\") as f: json.dump(result, f, indent=4)\n",
    "    \n",
    "#     print(\"Generating Confusion Matrix...\")\n",
    "#     model_cm = THAT(test_x[0].shape, test_y[0].reshape(-1).shape).to(\"cpu\")\n",
    "#     model_cm.load_state_dict(torch.load(model_save_path, map_location=\"cpu\"))\n",
    "#     cm_loader = DataLoader(TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y)), batch_size=32)\n",
    "#     num_classes = test_y.shape[2] \n",
    "#     title = f\"Confusion Matrix: {scenario_name} (Acc: {np.mean(result['accuracy']):.2f} - {subset_ratio*100}% Data)\"\n",
    "#     save_multiclass_confusion_matrix(model_cm, cm_loader, \"cpu\", pdf_save_path, num_classes, title)\n",
    "    \n",
    "#     del model, model_cm, train_x, test_x, data_x\n",
    "#     gc.collect()\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print(f\"Done with {scenario_name}.\\n\")\n",
    "\n",
    "# def run():\n",
    "#     scenarios = [\n",
    "#         (\"RPCA\", True),\n",
    "#         (\"RAW\", False)\n",
    "#     ]\n",
    "#     for name, rpca_flag in scenarios:\n",
    "#         run_experiment(name, rpca_flag)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27f97d",
   "metadata": {
    "papermill": {
     "duration": 0.045364,
     "end_time": "2025-12-28T18:53:43.908268",
     "exception": false,
     "start_time": "2025-12-28T18:53:43.862904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4451316,
     "sourceId": 7638081,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7503373,
     "sourceId": 11934698,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7340.824691,
   "end_time": "2025-12-28T18:53:46.558058",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-28T16:51:25.733367",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
