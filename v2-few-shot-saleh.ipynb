{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7638081,"sourceType":"datasetVersion","datasetId":4451316},{"sourceId":11934698,"sourceType":"datasetVersion","datasetId":7503373}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\nCell 1: Library Imports\n---\n---","metadata":{}},{"cell_type":"code","source":"# Cell 1: Library Imports\nimport os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport scipy.io as scio\nimport time\nimport torch\ntorch.cuda.empty_cache()\nimport torch._dynamo\nfrom torch.utils.data import TensorDataset, DataLoader\n# from ptflops import get_model_complexity_info\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom copy import deepcopy\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:29:23.296045Z","iopub.execute_input":"2025-12-13T06:29:23.296628Z","iopub.status.idle":"2025-12-13T06:29:30.819032Z","shell.execute_reply.started":"2025-12-13T06:29:23.296601Z","shell.execute_reply":"2025-12-13T06:29:30.818296Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"---\nCell 2: preset.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          preset.py\n[description]   default settings of WiFi-based models\n\"\"\"\nminidata_set = 1\npreset = {\n    # define model\n    \"model\": \"THAT\",  # \"ST-RF\", \"MLP\", \"LSTM\", \"CNN-1D\", \"CNN-2D\", \"CLSTM\", \"ABLSTM\", \"THAT\", \"bi-LSTM\", \"ResNet18\"\n    # define task\n    \"task\": \"activity\",  # \"identity\", \"activity\", \"location\", \"count\"\n    # number of repeated experiments\n    \"repeat\": 1,\n    # path of data\n    \"path\": {\n        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   # directory of CSI amplitude files \n        \"data_y\": \"/kaggle/input/wimans/annotation.csv\", # path of annotation file\n        \"save\": \"result_lstm_epoch=80_batchsize=32_envs=empty_room_wifiband=2.4.json\"               # path to save results\n    },\n    # data selection for experiments\n    \"data\": {\n        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  # select number(s) of users\n        \"wifi_band\": [\"2.4\"],                         # select WiFi band(s)\n        \"environment\": [\"classroom\"],                 # select environment(s) [\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\n        \"length\": 3000,                               # default length of CSI\n    },\n    # hyperparameters of models\n    \"nn\": {\n        \"lr\": 1e-3,           # learning rate\n        \"epoch\": 100,         # number of epochs\n        \"batch_size\": 64,    # batch size\n        \"threshold\": 0.5,     # threshold to binarize sigmoid outputs\n    },\n    # encoding of activities and locations\n    \"encoding\": {\n        \"activity\": {  # encoding of different activities\n            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n        },\n        \"location\": {  # encoding of different locations\n            \"nan\":  [0, 0, 0, 0, 0],\n            \"a\":    [1, 0, 0, 0, 0],\n            \"b\":    [0, 1, 0, 0, 0],\n            \"c\":    [0, 0, 1, 0, 0],\n            \"d\":    [0, 0, 0, 1, 0],\n            \"e\":    [0, 0, 0, 0, 1],\n        },\n    },\n}\n\n\n# Few-shot parameters (manually set)\ndest_env = \"empty_room\"       # Destination environment[\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\nfew_shot_epochs = 100         # Number of epochs for few-shot training\nfew_shot_num_samples = 5     # Number of samples to use from the destination test data\n\nConfusion_matrix = 1\n\nname_run = \"few={},{},{},m={},t={},epoch={},batch={},environment={}\".format(dest_env, few_shot_epochs, few_shot_num_samples, preset[\"model\"], preset[\"task\"], preset[\"nn\"][\"epoch\"], preset[\"nn\"][\"batch_size\"], preset[\"data\"][\"environment\"])\nprint(name_run)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:29:30.820196Z","iopub.execute_input":"2025-12-13T06:29:30.820599Z","iopub.status.idle":"2025-12-13T06:29:30.829529Z","shell.execute_reply.started":"2025-12-13T06:29:30.820578Z","shell.execute_reply":"2025-12-13T06:29:30.828863Z"}},"outputs":[{"name":"stdout","text":"few=empty_room,100,5,m=THAT,t=activity,epoch=20,batch=64,environment=['classroom']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"---\nCell 3: load_data.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          load_data.py\n[description]   load annotation file and CSI amplitude, and encode labels\n\"\"\"\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n# Note: All necessary libraries (os, numpy, pandas, etc.) are imported in Cell 1.\n# from preset import preset   --> preset is already defined in Cell 2.\n\ndef load_data_y(var_path_data_y,\n                var_environment=None, \n                var_wifi_band=None, \n                var_num_users=None):\n    \"\"\"\n    Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n    \"\"\"\n    data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n    if var_environment is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n    if var_wifi_band is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n    if var_num_users is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n    return data_pd_y\n\ndef load_data_x(var_path_data_x, var_label_list):\n    \"\"\"\n    Load CSI amplitude (*.npy) files based on a label list.\n    \"\"\"\n    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n    data_x = []\n    for var_path in var_path_list:\n        data_csi = np.load(var_path)\n        var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n        data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n        data_x.append(data_csi_pad)\n    data_x = np.array(data_x)\n    return data_x\n\ndef encode_data_y(data_pd_y, var_task):\n    \"\"\"\n    Encode labels according to specific task.\n    \"\"\"\n    if var_task == \"identity\":\n        data_y = encode_identity(data_pd_y)\n    elif var_task == \"activity\":\n        data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    elif var_task == \"location\":\n        data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n    elif var_task == \"count\":\n        data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n    return data_y\n\ndef encode_identity(data_pd_y):\n    \"\"\"\n    Onehot encoding for identity labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_identity_y[data_identity_y != \"nan\"] = 1\n    data_identity_y[data_identity_y == \"nan\"] = 0\n    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n    return data_identity_onehot_y\n\n\n\ndef encode_activity(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for activity labels.\n    \"\"\"\n    data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n                                    \"user_3_activity\", \"user_4_activity\", \n                                    \"user_5_activity\", \"user_6_activity\"]]\n    data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n    data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n    return data_activity_onehot_y\n\ndef encode_location(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for location labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n    return data_location_onehot_y\n\n# Test functions (optional)\ndef test_load_data_y():\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"classroom\"]).describe())\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"]).describe())\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=[\"1\", \"2\", \"3\"]).describe())\n\ndef test_load_data_x():\n    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=None)\n    var_label_list = data_pd_y[\"label\"].to_list()\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n    print(data_x.shape)\n\ndef test_encode_identity():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_identity_onehot_y = encode_identity(data_pd_y)\n    print(data_identity_onehot_y.shape)\n    print(data_identity_onehot_y[2000])\n\ndef test_encode_activity():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    print(data_activity_onehot_y.shape)\n    print(data_activity_onehot_y[1560])\n\ndef test_encode_location():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n    print(data_location_onehot_y.shape)\n    print(data_location_onehot_y[1560])\n\ndef encode_count(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for identity labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_identity_y[data_identity_y != \"nan\"] = 1\n    data_identity_y[data_identity_y == \"nan\"] = 0\n    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n    print(\"data_identity_onehot_y\",data_identity_onehot_y.shape)\n    count_data = np.sum(data_identity_onehot_y, axis=1)\n    print(\"count_data\",count_data.shape)\n    count_data = count_data.reshape(-1, 1)  # shape = (11286, 1)\n    encoder = OneHotEncoder(sparse=False)  \n    count_data_onehot = encoder.fit_transform(count_data)\n    print(count_data_onehot.shape)  \n    count_data_onehot = count_data_onehot.astype(\"int8\")\n\n    return count_data_onehot\n\n\ndef test_encode_count():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_count_onehot_y = encode_count(data_pd_y)\n    print(data_count_onehot_y.shape)\n    print(data_count_onehot_y[20])\n\n# if __name__ == \"__main__\":\n#     test_encode_count()\n#     test_load_data_y()\n#     test_load_data_x()\n#     test_encode_identity()\n#     test_encode_activity()\n#     test_encode_location()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:29:30.830396Z","iopub.execute_input":"2025-12-13T06:29:30.830679Z","iopub.status.idle":"2025-12-13T06:29:30.854096Z","shell.execute_reply.started":"2025-12-13T06:29:30.830650Z","shell.execute_reply":"2025-12-13T06:29:30.853351Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"---\nCell 4: preprocess.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          preprocess.py\n[description]   preprocess WiFi CSI data\n\"\"\"\n\n# All necessary libraries are already imported in Cell 1.\n\ndef mat_to_amp(data_mat):\n    \"\"\"\n    Calculate amplitude of raw WiFi CSI data.\n    \"\"\"\n    var_length = data_mat[\"trace\"].shape[0]\n    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n    data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n    return data_csi_amp\n\ndef extract_csi_amp(var_dir_mat, var_dir_amp):\n    \"\"\"\n    Read raw WiFi CSI (*.mat) files, calculate CSI amplitude, and save as (*.npy).\n    \"\"\"\n    var_path_mat = os.listdir(var_dir_mat)\n    for var_c, var_path in enumerate(var_path_mat):\n        data_mat = scio.loadmat(os.path.join(var_dir_mat, var_path))\n        data_csi_amp = mat_to_amp(data_mat)\n        # print(var_c, data_csi_amp.shape)\n        var_path_save = os.path.join(var_dir_amp, var_path.replace(\".mat\", \".npy\"))\n        with open(var_path_save, \"wb\") as var_file:\n            np.save(var_file, data_csi_amp)\n\n\n\n# # تنظیمات low-rank (بدون تغییر ورودی mat_to_amp)\n# LOW_RANK_ENERGY = 0.95   # مثلاً 95% انرژی\n# LOW_RANK_RANK = None     # اگر عدد بذاری (مثلاً 5)، به جای ENERGY از rank ثابت استفاده میشه\n\n# def _low_rank_approx(X, rank=None, energy=0.95):\n#     X = np.asarray(X)\n\n#     was_1d = (X.ndim == 1)\n#     if was_1d:\n#         X = X[:, None]\n\n#     U, S, Vt = np.linalg.svd(X, full_matrices=False)\n\n#     if rank is None:\n#         s2 = S**2\n#         cum = np.cumsum(s2) / (np.sum(s2) + 1e-12)\n#         rank = int(np.searchsorted(cum, energy) + 1)\n\n#     rank = max(1, min(rank, S.shape[0]))\n#     X_lr = (U[:, :rank] * S[:rank]) @ Vt[:rank, :]\n\n#     if was_1d:\n#         X_lr = X_lr[:, 0]\n\n#     return X_lr.astype(np.float32)\n\n# def mat_to_amp(data_mat):\n#     \"\"\"\n#     Calculate amplitude of raw WiFi CSI data, then return its low-rank approximation.\n#     (ورودی تابع تغییر نکرده)\n#     \"\"\"\n#     var_length = data_mat[\"trace\"].shape[0]\n#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n\n#     # خروجی low-rank با همان ابعاد\n#     data_csi_amp_lr = _low_rank_approx(\n#         data_csi_amp,\n#         rank=LOW_RANK_RANK,\n#         energy=LOW_RANK_ENERGY\n#     )\n#     return data_csi_amp_lr\n\n\n\n# # تنظیمات sparsity (بدون تغییر ورودی mat_to_amp)\n# SPARSE_KEEP_RATIO = 0.10   # مثلا فقط 10% بزرگترین مقادیر نگه داشته بشن\n# SPARSE_MIN_ABS = None      # اگر عدد بذاری (مثلا 0.5)، به جای keep_ratio آستانه ثابت میشه\n\n# def _to_sparse(X, keep_ratio=0.10, min_abs=None):\n#     \"\"\"\n#     Convert X to a sparse representation by keeping only large-magnitude entries.\n#     Returns:\n#       - scipy.sparse.csr_matrix if SciPy is available\n#       - otherwise returns a dense array with many zeros (still \"sparse\" in content)\n#     \"\"\"\n#     X = np.asarray(X)\n#     flat = X.ravel()\n#     absflat = np.abs(flat)\n\n#     if flat.size == 0:\n#         return X.astype(np.float32)\n\n#     # انتخاب آستانه\n#     if min_abs is not None:\n#         thr = float(min_abs)\n#         mask = absflat >= thr\n#     else:\n#         k = int(np.ceil(keep_ratio * flat.size))\n#         k = max(1, min(k, flat.size))\n#         if k == flat.size:\n#             mask = np.ones_like(absflat, dtype=bool)\n#         else:\n#             thr = np.partition(absflat, -k)[-k]  # kth largest magnitude\n#             mask = absflat >= thr\n\n#     idx = np.nonzero(mask)[0]\n#     data = flat[idx].astype(np.float32)\n\n#     # اگر SciPy هست: sparse واقعی بساز\n#     try:\n#         # معمولاً تو Cell1 یا از قبل import شده؛ اگر هم نشده باشه اینجا تلاش می‌کنه.\n#         import scipy.sparse as sp\n\n#         if X.ndim == 1:\n#             rows = idx\n#             cols = np.zeros_like(rows)\n#             shape = (X.shape[0], 1)\n#         else:\n#             rows, cols = np.unravel_index(idx, X.shape)\n#             shape = X.shape\n\n#         return sp.coo_matrix((data, (rows, cols)), shape=shape).tocsr()\n\n#     except Exception:\n#         # fallback: آرایه‌ی dense با صفرهای زیاد\n#         out = np.zeros_like(flat, dtype=np.float32)\n#         out[idx] = data\n#         return out.reshape(X.shape)\n\ndef mat_to_amp(data_mat):\n    \"\"\"\n    Calculate amplitude of raw WiFi CSI data, then return its sparse version.\n    (ورودی تابع تغییر نکرده)\n    \"\"\"\n    var_length = data_mat[\"trace\"].shape[0]\n    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n    data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n\n    # خروجی sparse (CSR اگر SciPy باشد)\n    return _to_sparse(data_csi_amp, keep_ratio=SPARSE_KEEP_RATIO, min_abs=SPARSE_MIN_ABS)\n\n\n\n\n\n\ndef parse_args():\n    \"\"\"\n    Parse arguments from input.\n    \"\"\"\n    var_args = argparse.ArgumentParser()\n    var_args.add_argument(\"--dir_mat\", default=\"/kaggle/input/wimans/wifi_csi/mat\", type=str)\n    var_args.add_argument(\"--dir_amp\", default=\"/kaggle/input/wimans/wifi_csi/amp\", type=str)\n    return var_args.parse_args()\n\n# if __name__ == \"__main__\":\n#     var_args = parse_args()\n#     extract_csi_amp(var_dir_mat=var_args.dir_mat, var_dir_amp=var_args.dir_amp)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:36:27.241852Z","iopub.execute_input":"2025-12-13T06:36:27.242601Z","iopub.status.idle":"2025-12-13T06:36:27.253955Z","shell.execute_reply.started":"2025-12-13T06:36:27.242574Z","shell.execute_reply":"2025-12-13T06:36:27.253261Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"---\nCell 5: that.py (WiFi-based Model THAT)\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          that.py\n[description]   implement and evaluate WiFi-based model THAT\n                https://github.com/windofshadow/THAT\n\"\"\"\n\n# All necessary libraries are imported in Cell 1.\n# from train import train   --> Defined in Cell 6.\n# from preset import preset --> Defined in Cell 2.\n\nclass Gaussian_Position(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n        super(Gaussian_Position, self).__init__()\n        var_embedding = torch.zeros([var_num_gaussian, var_dim_feature], dtype=torch.float)\n        self.var_embedding = torch.nn.Parameter(var_embedding, requires_grad=True)\n        torch.nn.init.xavier_uniform_(self.var_embedding)\n        var_position = torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian)\n        self.var_position = torch.nn.Parameter(var_position, requires_grad=False)\n        var_mu = torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0)\n        self.var_mu = torch.nn.Parameter(var_mu, requires_grad=True)\n        var_sigma = torch.tensor([50.0] * var_num_gaussian).unsqueeze(0)\n        self.var_sigma = torch.nn.Parameter(var_sigma, requires_grad=True)\n\n    def calculate_pdf(self, var_position, var_mu, var_sigma):\n        var_pdf = var_position - var_mu\n        var_pdf = - var_pdf * var_pdf\n        var_pdf = var_pdf / var_sigma / var_sigma / 2\n        var_pdf = var_pdf - torch.log(var_sigma)\n        return var_pdf\n\n    def forward(self, var_input):\n        var_pdf = self.calculate_pdf(self.var_position, self.var_mu, self.var_sigma)\n        var_pdf = torch.softmax(var_pdf, dim=-1)\n        var_position_encoding = torch.matmul(var_pdf, self.var_embedding)\n        var_output = var_input + var_position_encoding.unsqueeze(0)\n        return var_output\n\nclass Encoder(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n        super(Encoder, self).__init__()\n        self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n        self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n        self.layer_dropout_0 = torch.nn.Dropout(0.1)\n        self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n        layer_cnn = []\n        for var_size in var_size_cnn:\n            layer = torch.nn.Sequential(\n                torch.nn.Conv1d(var_dim_feature, var_dim_feature, var_size, padding=\"same\"),\n                torch.nn.BatchNorm1d(var_dim_feature),\n                torch.nn.Dropout(0.1),\n                torch.nn.LeakyReLU()\n            )\n            layer_cnn.append(layer)\n        self.layer_cnn = torch.nn.ModuleList(layer_cnn)\n        self.layer_dropout_1 = torch.nn.Dropout(0.1)\n\n    def forward(self, var_input):\n        var_t = var_input\n        var_t = self.layer_norm_0(var_t)\n        var_t, _ = self.layer_attention(var_t, var_t, var_t)\n        var_t = self.layer_dropout_0(var_t)\n        var_t = var_t + var_input\n        var_s = self.layer_norm_1(var_t)\n        var_s = torch.permute(var_s, (0, 2, 1))\n        var_c = torch.stack([layer(var_s) for layer in self.layer_cnn], dim=0)\n        var_s = torch.sum(var_c, dim=0) / len(self.layer_cnn)\n        var_s = self.layer_dropout_1(var_s)\n        var_s = torch.permute(var_s, (0, 2, 1))\n        var_output = var_s + var_t\n        return var_output\n\nclass THAT(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(THAT, self).__init__()\n        var_dim_feature = var_x_shape[-1]\n        var_dim_time = var_x_shape[-2]\n        var_dim_output = var_y_shape[-1]\n        # Left branch\n        self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n        var_num_left = 4\n        var_dim_left = var_dim_feature\n        self.layer_left_encoder = torch.nn.ModuleList([\n            Encoder(var_dim_feature=var_dim_left, var_num_head=10, var_size_cnn=[1, 3, 5])\n            for _ in range(var_num_left)\n        ])\n        self.layer_left_norm = torch.nn.LayerNorm(var_dim_left, eps=1e-6)\n        self.layer_left_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=8)\n        self.layer_left_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=16)\n        self.layer_left_dropout = torch.nn.Dropout(0.5)\n        # Right branch\n        self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        var_num_right = 1\n        var_dim_right = var_dim_time // 20\n        self.layer_right_encoder = torch.nn.ModuleList([\n            Encoder(var_dim_feature=var_dim_right, var_num_head=10, var_size_cnn=[1, 2, 3])\n            for _ in range(var_num_right)\n        ])\n        self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n        self.layer_right_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=2)\n        self.layer_right_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=4)\n        self.layer_right_dropout = torch.nn.Dropout(0.5)\n        self.layer_leakyrelu = torch.nn.LeakyReLU()\n        self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n\n    def forward(self, var_input):\n        var_t = var_input  # shape: (batch_size, time_steps, features)\n        # Left branch\n        var_left = torch.permute(var_t, (0, 2, 1))\n        var_left = self.layer_left_pooling(var_left)\n        var_left = torch.permute(var_left, (0, 2, 1))\n        var_left = self.layer_left_gaussian(var_left)\n        for layer in self.layer_left_encoder:\n            var_left = layer(var_left)\n        var_left = self.layer_left_norm(var_left)\n        var_left = torch.permute(var_left, (0, 2, 1))\n        var_left_0 = self.layer_leakyrelu(self.layer_left_cnn_0(var_left))\n        var_left_1 = self.layer_leakyrelu(self.layer_left_cnn_1(var_left))\n        var_left_0 = torch.sum(var_left_0, dim=-1)\n        var_left_1 = torch.sum(var_left_1, dim=-1)\n        var_left = torch.concat([var_left_0, var_left_1], dim=-1)\n        var_left = self.layer_left_dropout(var_left)\n        # Right branch\n        var_right = torch.permute(var_t, (0, 2, 1))\n        var_right = self.layer_right_pooling(var_right)\n        for layer in self.layer_right_encoder:\n            var_right = layer(var_right)\n        var_right = self.layer_right_norm(var_right)\n        var_right = torch.permute(var_right, (0, 2, 1))\n        var_right_0 = self.layer_leakyrelu(self.layer_right_cnn_0(var_right))\n        var_right_1 = self.layer_leakyrelu(self.layer_right_cnn_1(var_right))\n        var_right_0 = torch.sum(var_right_0, dim=-1)\n        var_right_1 = torch.sum(var_right_1, dim=-1)\n        var_right = torch.concat([var_right_0, var_right_1], dim=-1)\n        var_right = self.layer_right_dropout(var_right)\n        # Concatenate branches\n        var_t = torch.concat([var_left, var_right], dim=-1)\n        var_output = self.layer_output(var_t)\n        return var_output\n\ndef run_that(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n    \"\"\"\n    Run WiFi-based model THAT.\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    data_train_x = data_train_x.reshape(data_train_x.shape[0], data_train_x.shape[1], -1)\n    data_test_x = data_test_x.reshape(data_test_x.shape[0], data_test_x.shape[1], -1)\n    var_x_shape, var_y_shape = data_train_x[0].shape, data_train_y[0].reshape(-1).shape\n    data_train_set = TensorDataset(torch.from_numpy(data_train_x), torch.from_numpy(data_train_y))\n    data_test_set = TensorDataset(torch.from_numpy(data_test_x), torch.from_numpy(data_test_y))\n    \n    result = {}\n    result_accuracy = []\n    result_time_train = []\n    result_time_test = []\n    \n    # var_macs, var_params = get_model_complexity_info(THAT(var_x_shape, var_y_shape), var_x_shape, as_strings=False)\n    # print(\"Parameters:\", var_params, \"- FLOPs:\", var_macs * 2)\n    \n    for var_r in range(var_repeat):\n        print(\"Repeat\", var_r)\n        torch.random.manual_seed(var_r + 39)\n        if init_model is not None:\n            model_that = init_model\n            lr2 = preset[\"nn\"][\"lr\"] /10\n        else:\n            model_that = THAT(var_x_shape, var_y_shape).to(device)\n            lr2 = preset[\"nn\"][\"lr\"]\n\n        optimizer = torch.optim.Adam(model_that.parameters(), lr=lr2, weight_decay=0)\n        loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4] * var_y_shape[-1]).to(device))\n        var_time_0 = time.time()\n        \n        # Train\n        var_best_weight = train(model=model_that, optimizer=optimizer, loss=loss, \n                                  data_train_set=data_train_set, data_test_set=data_test_set,\n                                  var_threshold=preset[\"nn\"][\"threshold\"],\n                                  var_batch_size=preset[\"nn\"][\"batch_size\"],\n                                  var_epochs=preset[\"nn\"][\"epoch\"],\n                                  device=device)\n        var_time_1 = time.time()\n        \n        # Test\n        model_that.load_state_dict(var_best_weight)\n        with torch.no_grad():\n            predict_test_y = model_that(torch.from_numpy(data_test_x).to(device))\n        predict_test_y = (torch.sigmoid(predict_test_y) > preset[\"nn\"][\"threshold\"]).float()\n        predict_test_y = predict_test_y.detach().cpu().numpy()\n        var_time_2 = time.time()\n        \n        # Evaluate\n        data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n        predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n        result_acc = accuracy_score(data_test_y_c.astype(int), predict_test_y_c.astype(int))\n        result_dict = classification_report(data_test_y_c, predict_test_y_c, digits=6, zero_division=0, output_dict=True)\n        result[\"repeat_\" + str(var_r)] = result_dict\n        result_accuracy.append(result_acc)\n        result_time_train.append(var_time_1 - var_time_0)\n        result_time_test.append(var_time_2 - var_time_1)\n        print(\"repeat_\" + str(var_r), result_accuracy)\n        print(result)\n    \n    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n    # result[\"complexity\"] = {\"parameter\": var_params, \"flops\": var_macs * 2}\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:36:30.330942Z","iopub.execute_input":"2025-12-13T06:36:30.331675Z","iopub.status.idle":"2025-12-13T06:36:30.357429Z","shell.execute_reply.started":"2025-12-13T06:36:30.331649Z","shell.execute_reply":"2025-12-13T06:36:30.356568Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell7: for RESNET18 Model\n---\n---","metadata":{}},{"cell_type":"code","source":"# import os\n# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# import torch._dynamo\n# torch._dynamo.config.suppress_errors = True\n# import time\n# import torch\n# torch.cuda.empty_cache()\n# import numpy as np\n# from torch.utils.data import TensorDataset, DataLoader\n# from sklearn.metrics import accuracy_score, classification_report\n# import torchvision.models as models\n# from copy import deepcopy\n\n# torch.set_float32_matmul_precision(\"high\")\n# torch._dynamo.config.cache_size_limit = 65536\n\n# # فرض می‌کنیم preset قبلاً تعریف شده باشه\n# # preset = { \"nn\": {\"lr\": 1e-3, \"epoch\": 10, \"batch_size\": 4, \"threshold\": 0.5}, ... }\n\n# class ResNet18Model(torch.nn.Module):\n#     def __init__(self, var_x_shape, var_y_shape):\n#         super(ResNet18Model, self).__init__()\n#         model_resnet = models.resnet18(weights=None)\n#         model_resnet.conv1 = torch.nn.Conv2d(1, 64, 7, 3, 2, bias=False)\n#         in_features_fc = model_resnet.fc.in_features  # معمولاً 512\n#         out_features_fc = var_y_shape[-1]\n#         model_resnet.fc = torch.nn.Linear(in_features_fc, out_features_fc)\n#         self.resnet = model_resnet\n\n#     def forward(self, var_input):\n#         var_input = var_input.reshape(var_input.size(0), 1, 3000, 270)\n#         return self.resnet(var_input)\n\n# def run_resnet(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     var_x_shape = data_train_x[0].shape\n#     var_y_shape = data_train_y[0].reshape(-1).shape\n\n#     # تغییر شکل داده‌ها روی CPU\n#     data_train_x = data_train_x.reshape(data_train_x.shape[0], 1, data_train_x.shape[1],\n#                                         data_train_x.shape[2]*data_train_x.shape[3]*data_train_x.shape[4])\n#     data_test_x  = data_test_x.reshape(data_test_x.shape[0], 1, data_test_x.shape[1],\n#                                        data_test_x.shape[2]*data_test_x.shape[3]*data_test_x.shape[4])\n    \n#     # دیتاست‌ها روی CPU\n#     data_train_set = TensorDataset(torch.from_numpy(data_train_x).float(),\n#                                    torch.from_numpy(data_train_y).float())\n#     data_test_set  = TensorDataset(torch.from_numpy(data_test_x).float(),\n#                                    torch.from_numpy(data_test_y).float())\n    \n#     result = {}\n#     result_accuracy = []\n#     result_time_train = []\n#     result_time_test = []\n    \n#     for var_r in range(var_repeat):\n#         print(\"Repeat\", var_r)\n#         torch.random.manual_seed(var_r + 39)\n        \n#         # ساخت مدل و انتقال به GPU\n#         if init_model is not None:\n#             model_resnet = init_model\n#             lr2 = preset[\"nn\"][\"lr\"] /10\n            \n#         else:\n#             model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n#             lr2 = preset[\"nn\"][\"lr\"]\n\n#         optimizer = torch.optim.Adam(model_resnet.parameters(), lr=lr2, weight_decay=0)\n#         loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6] * var_y_shape[-1]).to(device))\n        \n#         # تابع آموزش داخلی؛ دیتا روی CPU باقی می‌مونه و فقط هنگام محاسبه batch به GPU میره\n#         def train_inner():\n#             train_loader = DataLoader(data_train_set, preset[\"nn\"][\"batch_size\"], shuffle=True, pin_memory=False)\n#             test_loader = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n#             best_accuracy = 0\n#             best_weight = None\n            \n#             for epoch in range(preset[\"nn\"][\"epoch\"]):\n#                 t0 = time.time()\n#                 model_resnet.train()\n#                 # متغیرهای مربوط به آخرین batch آموزش\n#                 last_train_loss = None\n#                 last_train_acc = None\n#                 for batch in train_loader:\n#                     batch_x, batch_y = batch\n#                     batch_x = batch_x.to(device)\n#                     batch_y = batch_y.to(device)\n#                     outputs = model_resnet(batch_x)\n#                     loss_val = loss_func(outputs, batch_y.reshape(batch_y.shape[0], -1).float())\n#                     optimizer.zero_grad()\n#                     loss_val.backward()\n#                     optimizer.step()\n#                     last_train_loss = loss_val.item()\n#                     # محاسبه دقت آخرین batch آموزش\n#                     train_preds = (torch.sigmoid(outputs) > preset[\"nn\"][\"threshold\"]).float()\n#                     last_train_acc = accuracy_score(batch_y.reshape(batch_y.shape[0], -1).detach().cpu().numpy().astype(int),\n#                                                     train_preds.detach().cpu().numpy().astype(int))\n                \n#                 # ارزیابی روی دیتاست تست به صورت batch به batch\n#                 model_resnet.eval()\n#                 all_preds = []\n#                 all_labels = []\n#                 test_loss_val = None\n#                 with torch.no_grad():\n#                     for t_batch in test_loader:\n#                         t_x, t_y = t_batch\n#                         t_x = t_x.to(device)\n#                         outputs_test = model_resnet(t_x)\n#                         outputs_test = (torch.sigmoid(outputs_test) > preset[\"nn\"][\"threshold\"]).float()\n#                         all_preds.append(outputs_test.detach().cpu().numpy())\n#                         all_labels.append(t_y.cpu().numpy())  # اینجا تغییر دادیم\n#                 preds_cat = np.vstack(all_preds)\n#                 labels_cat = np.vstack(all_labels)\n#                 print(\"preds_cat\",preds_cat.shape)\n#                 # تبدیل به شکل (n, 6, 5)\n                \n#                 # preds_cat = preds_cat.reshape(-1, 6, 5)\n#                 # labels_cat = labels_cat.reshape(-1, 6, 5)\n\n#                 preds_cat = preds_cat.reshape(-1, 6)\n#                 labels_cat = labels_cat.reshape(-1, 6)\n                \n#                 # برای محاسبه دقت، مسطح می‌کنیم\n#                 test_acc = accuracy_score(labels_cat.reshape(labels_cat.shape[0], -1).astype(int),\n#                                           preds_cat.reshape(preds_cat.shape[0], -1).astype(int))\n#                 epoch_time = time.time() - t0\n#                 print(f\"Epoch {epoch}/{preset['nn']['epoch']} - \"\n#                       f\"Train Loss: {(last_train_loss if last_train_loss is not None else 0.0):.6f}, \"\n#                       f\"Train Acc: {(last_train_acc if last_train_acc is not None else 0.0):.6f}, \"\n#                       f\"Test Loss: {(test_loss_val if test_loss_val is not None else 0.0):.6f}, \"\n#                       f\"Test Acc: {(test_acc if test_acc is not None else 0.0):.6f} - \"\n#                       f\"Time: {epoch_time:.4f}s\")\n\n#                 if test_acc > best_accuracy:\n#                     best_accuracy = test_acc\n#                     print('-----***-----')\n#                     print(best_accuracy)\n#                     best_weight = deepcopy(model_resnet.state_dict())\n#             return best_weight\n        \n#         t0_run = time.time()\n#         best_weight = train_inner()\n#         t1_run = time.time()\n        \n#         torch.save(model_resnet.state_dict(), f\"{name_run}_model_final.pt\")\n#         model_resnet.load_state_dict(best_weight)\n#         torch.save(model_resnet.state_dict(), f\"{name_run}_best_model.pt\")\n\n#         # bad age niaz bod load koni\n#         # model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n#         # model_resnet.load_state_dict(torch.load(\"resnet_model_repeat0.pt\"))\n#         # model_resnet.eval()\n\n        \n#         # ارزیابی نهایی مدل روی دیتاست تست (استفاده از batchهای کوچک)\n#         model_resnet.eval()\n#         all_preds = []\n#         test_loader_final = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n#         with torch.no_grad():\n#             for batch in test_loader_final:\n#                 batch_x, _ = batch\n#                 batch_x = batch_x.to(device)\n#                 all_preds.append(model_resnet(batch_x))\n#         preds_all = torch.cat(all_preds, dim=0)\n#         preds_final = (torch.sigmoid(preds_all) > preset[\"nn\"][\"threshold\"]).float().detach().cpu().numpy()\n#         t2_run = time.time()\n        \n#         data_test_y_np = data_test_y.reshape(-1, data_test_y.shape[-1])\n#         preds_final = preds_final.reshape(-1, data_test_y.shape[-1])\n#         acc_final = accuracy_score(data_test_y_np.astype(int), preds_final.astype(int))\n#         result[f\"repeat_{var_r}\"] = {\"accuracy\": acc_final}\n#         result_accuracy.append(acc_final)\n#         result_time_train.append(t1_run - t0_run)\n#         result_time_test.append(t2_run - t1_run)\n#         print(\"Repeat\", var_r, \"Final Test Accuracy:\", acc_final)\n    \n#     result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n#     result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n#     result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n#     return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:36:34.721659Z","iopub.execute_input":"2025-12-13T06:36:34.722156Z","iopub.status.idle":"2025-12-13T06:36:34.729263Z","shell.execute_reply.started":"2025-12-13T06:36:34.722122Z","shell.execute_reply":"2025-12-13T06:36:34.728500Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"---\nCell 9: train.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          train.py\n[description]   function to train WiFi-based models\n\"\"\"\n\n# All necessary libraries are imported in Cell 1.\n\ntorch.set_float32_matmul_precision(\"high\")\ntorch._dynamo.config.cache_size_limit = 65536\n\ndef train(model, optimizer, loss, data_train_set, data_test_set, var_threshold, var_batch_size, var_epochs, device):\n    \"\"\"\n    Generic training function for WiFi-based models.\n    \"\"\"\n    # دیتا رو روی CPU نگه می‌داریم (pin_memory=False)\n    data_train_loader = DataLoader(data_train_set, var_batch_size, shuffle=True, pin_memory=False)\n    data_test_loader = DataLoader(data_test_set, batch_size=len(data_test_set), shuffle=False, pin_memory=False)\n    \n    var_best_accuracy = -1.0\n    var_best_weight   = deepcopy(model.state_dict())\n    \n    \n    for var_epoch in range(var_epochs):\n        var_time_e0 = time.time()\n        model.train()\n        for data_batch in data_train_loader:\n            data_batch_x, data_batch_y = data_batch\n            # انتقال موقتی داده به GPU فقط برای forward pass\n            data_batch_x = data_batch_x.to(device)\n            data_batch_y = data_batch_y.to(device)\n            predict_train_y = model(data_batch_x)\n            var_loss_train = loss(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n            optimizer.zero_grad()\n            var_loss_train.backward()\n            optimizer.step()\n        \n        # محاسبه دقت روی آخرین batch و انتقال نتایج به CPU\n        predict_train_y = (torch.sigmoid(predict_train_y) > var_threshold).float()\n        data_batch_y = data_batch_y.detach().cpu().numpy()\n        predict_train_y = predict_train_y.detach().cpu().numpy()\n        \n        predict_train_y = predict_train_y.reshape(-1, data_batch_y.shape[-1])\n        data_batch_y = data_batch_y.reshape(-1, data_batch_y.shape[-1])\n        var_accuracy_train = accuracy_score(data_batch_y.astype(int), predict_train_y.astype(int))\n        \n        model.eval()\n        with torch.no_grad():\n            data_test_x, data_test_y = next(iter(data_test_loader))\n            # انتقال موقتی دیتا تست به GPU برای محاسبات\n            data_test_x = data_test_x.to(device)\n            data_test_y = data_test_y.to(device)\n            \n            predict_test_y = model(data_test_x)\n            var_loss_test = loss(predict_test_y, data_test_y.reshape(data_test_y.shape[0], -1).float())\n            \n            predict_test_y = (torch.sigmoid(predict_test_y) > var_threshold).float()\n            \n            # انتقال نتایج به CPU برای ارزیابی\n            data_test_y = data_test_y.detach().cpu().numpy()\n            predict_test_y = predict_test_y.detach().cpu().numpy()\n            \n            predict_test_y = predict_test_y.reshape(-1, data_test_y.shape[-1])\n            data_test_y = data_test_y.reshape(-1, data_test_y.shape[-1])\n            var_accuracy_test = accuracy_score(data_test_y.astype(int), predict_test_y.astype(int))\n        \n        print(f\"Epoch {var_epoch}/{var_epochs}\",\n              \"- %.6fs\"%(time.time() - var_time_e0),\n              \"- Loss %.6f\"%var_loss_train.cpu(),\n              \"- Accuracy %.6f\"%var_accuracy_train,\n              \"- Test Loss %.6f\"%var_loss_test.cpu(),\n              \"- Test Accuracy %.6f\"%var_accuracy_test)\n            \n        if var_accuracy_test > var_best_accuracy:\n            var_best_accuracy = var_accuracy_test\n            print('-----***-----')\n            print(var_best_accuracy)\n            var_best_weight = deepcopy(model.state_dict())\n\n    torch.save(model.state_dict(), f\"{name_run}_model_final.pt\")\n    torch.save(var_best_weight, f\"{name_run}_best_model.pt\")\n\n    \n    return var_best_weight\n\n\n\n# === importsِ لازم را یک‌بار بالای فایل اضافه کن ===\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport matplotlib.pyplot as plt\n\n# ---------- تابع کمکی ----------\ndef save_confusion_matrix(model, data_loader, threshold, device, pdf_path):\n    \"\"\"\n    Runs the model on `data_loader`, builds a confusion matrix and writes it to `pdf_path`.\n    \"\"\"\n    model.eval()\n    y_true, y_pred = [], []\n\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n\n            preds = (torch.sigmoid(logits) > threshold).float().cpu().numpy().ravel()\n            yb    = yb.cpu().numpy().ravel()\n\n            y_true.extend(yb)\n            y_pred.extend(preds)\n\n    cm  = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots()\n    ConfusionMatrixDisplay(cm).plot(ax=ax)\n    ax.set_title(\"Confusion Matrix – Test\")\n\n    with PdfPages(pdf_path) as pdf:\n        pdf.savefig(fig)\n    plt.close(fig)\n# ---------------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:36:36.825853Z","iopub.execute_input":"2025-12-13T06:36:36.826348Z","iopub.status.idle":"2025-12-13T06:36:36.839760Z","shell.execute_reply.started":"2025-12-13T06:36:36.826323Z","shell.execute_reply":"2025-12-13T06:36:36.839184Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"---\nCell 11: run.py\n---\n---","metadata":{}},{"cell_type":"code","source":"import gc\nimport torch\ngc.collect()           \ntorch.cuda.empty_cache()  \ntorch.cuda.ipc_collect()  \n\n\n\n\n\"\"\"\n[file]          run.py\n[description]   run WiFi-based models and optionally save a multiclass confusion matrix\n\"\"\"\n\nimport argparse\nimport json\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib.backends.backend_pdf import PdfPages\n\n# from preset import preset, name_run\n# from load_data import load_data_x, load_data_y, encode_data_y\n# from lstm import run_lstm, LSTMM\n# from bilstm import run_bilstm, BiLSTMM\n# from that import run_that, THAT\n# from resnet import run_resnet, ResNet18Model\n# from strf import run_strf  # if you have the ST-RF implementation\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\",   default=preset[\"model\"],  type=str)\n    parser.add_argument(\"--task\",    default=preset[\"task\"],   type=str)\n    parser.add_argument(\"--repeat\",  default=preset[\"repeat\"], type=int)\n    parser.add_argument(\"--save_cm\", action=\"store_true\",\n                        help=\"Save a multiclass confusion matrix of the best model to PDF\")\n    args, _ = parser.parse_known_args()\n    return args\n\ndef save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes):\n    \"\"\"\n    Given a model that outputs one-hot logits for a multiclass task,\n    convert to predicted classes via argmax, then plot and save a\n    num_classes × num_classes confusion matrix to pdf_path.\n    \"\"\"\n    model.eval()\n    y_true = []\n    y_pred = []\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n            # predicted class is index of max logit\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            trues = torch.argmax(yb, dim=1).cpu().numpy()\n            y_pred.extend(preds.tolist())\n            y_true.extend(trues.tolist())\n\n    labels = list(range(num_classes))\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    disp.plot(ax=ax, xticks_rotation=\"vertical\")\n    ax.set_title(\"Confusion Matrix\")\n    with PdfPages(pdf_path) as pdf:\n        pdf.savefig(fig)\n    plt.close(fig)\n\ndef run():\n    args       = parse_args()\n    var_model  = args.model\n    var_task   = args.task\n    var_repeat = args.repeat\n\n    # --- Load and encode the data ---\n    data_pd_y = load_data_y(\n        preset[\"path\"][\"data_y\"],\n        var_environment=preset[\"data\"][\"environment\"],\n        var_wifi_band=preset[\"data\"][\"wifi_band\"],\n        var_num_users=preset[\"data\"][\"num_users\"]\n    )\n    labels = data_pd_y[\"label\"].tolist()\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], labels)\n    data_y = encode_data_y(data_pd_y, var_task)\n\n    train_x, test_x, train_y, test_y = train_test_split(\n        data_x, data_y, test_size=0.2, shuffle=True, random_state=39\n    )\n\n    # --- Select which model runner to use ---\n    if var_model == \"ST-RF\":\n        from strf import run_strf\n        run_model = run_strf\n    elif var_model == \"LSTM\":\n        run_model = run_lstm\n    elif var_model == \"bi-LSTM\":\n        run_model = run_bilstm\n    elif var_model == \"THAT\":\n        run_model = run_that\n    elif var_model == \"ResNet18\":\n        run_model = run_resnet\n    else:\n        raise ValueError(f\"Unknown model: {var_model}\")\n\n    # --- Train and evaluate ---\n    print(f\"Running model: {var_model}\")\n    result = run_model(train_x, train_y, test_x, test_y, var_repeat)\n    result[\"model\"] = var_model\n    result[\"task\"]  = var_task\n    result[\"data\"]  = preset[\"data\"]\n    result[\"nn\"]    = preset[\"nn\"]\n    print(result)\n\n    # --- Save results to JSON ---\n    with open(preset[\"path\"][\"save\"], \"w\") as f:\n        json.dump(result, f, indent=4)\n\n    # --- Optionally save a multiclass confusion matrix ---\n    # if args.save_cm:\n    if Confusion_matrix == 1:\n        # 1) completely release GPU memory used for training\n        del run_model                      # if 'model' from training is still in scope\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n    \n        # 2) reshape input only if the network is sequence‑based\n        if var_model in (\"LSTM\", \"bi-LSTM\", \"THAT\"):\n            test_x_cm = test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n        else:                           # ResNet18, ST‑RF\n            test_x_cm = test_x\n    \n        # 3) build the *same* architecture on CPU and load its weights\n        device_cm = torch.device(\"cpu\")\n        if var_model == \"LSTM\":\n            model_cm = LSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"bi-LSTM\":\n            model_cm = BiLSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"THAT\":\n            model_cm = THAT(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"ResNet18\":\n            model_cm = ResNet18Model(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        else:\n            raise ValueError(f\"Confusion matrix not supported for {var_model}\")\n    \n        best_path = f\"/kaggle/working/{name_run}_best_model.pt\"\n        model_cm.load_state_dict(torch.load(best_path, map_location=device_cm))\n        model_cm.eval()\n    \n        # 4) DataLoader on CPU with a safe batch size\n        test_ds = TensorDataset(torch.from_numpy(test_x_cm).float(),\n                                torch.from_numpy(test_y).float())\n        test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n    \n        # 5) save the confusion matrix PDF\n        num_classes = test_y.shape[1]\n        pdf_name = f\"{name_run}_confusion_matrix.pdf\"\n        save_multiclass_confusion_matrix(model_cm,test_loader,device_cm,pdf_name,num_classes)\n        print(f\"✅ Saved confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\nif __name__ == \"__main__\":\n    print(\"start\")\n    run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T06:36:40.064121Z","iopub.execute_input":"2025-12-13T06:36:40.064919Z","iopub.status.idle":"2025-12-13T06:38:50.448739Z","shell.execute_reply.started":"2025-12-13T06:36:40.064893Z","shell.execute_reply":"2025-12-13T06:38:50.447729Z"}},"outputs":[{"name":"stdout","text":"start\nRunning model: THAT\nRepeat 0\nEpoch 0/20 - 5.293747s - Loss 2.380586 - Accuracy 0.098958 - Test Loss 1.243687 - Test Accuracy 0.319187\n-----***-----\n0.3191865605658709\nEpoch 1/20 - 5.013028s - Loss 0.894588 - Accuracy 0.276042 - Test Loss 0.685200 - Test Accuracy 0.556145\n-----***-----\n0.5561450044208665\nEpoch 2/20 - 5.036592s - Loss 0.824894 - Accuracy 0.307292 - Test Loss 0.580449 - Test Accuracy 0.552608\nEpoch 3/20 - 5.027923s - Loss 0.633289 - Accuracy 0.312500 - Test Loss 0.556710 - Test Accuracy 0.522546\nEpoch 4/20 - 5.033720s - Loss 0.641981 - Accuracy 0.427083 - Test Loss 0.510532 - Test Accuracy 0.545093\nEpoch 5/20 - 5.067954s - Loss 0.607188 - Accuracy 0.390625 - Test Loss 0.527796 - Test Accuracy 0.537135\nEpoch 6/20 - 5.037771s - Loss 0.559231 - Accuracy 0.385417 - Test Loss 0.518239 - Test Accuracy 0.557029\n-----***-----\n0.5570291777188329\nEpoch 7/20 - 5.033230s - Loss 0.575307 - Accuracy 0.453125 - Test Loss 0.493905 - Test Accuracy 0.551724\nEpoch 8/20 - 5.033489s - Loss 0.653466 - Accuracy 0.333333 - Test Loss 0.505148 - Test Accuracy 0.556587\nEpoch 9/20 - 5.023539s - Loss 0.493944 - Accuracy 0.484375 - Test Loss 0.496142 - Test Accuracy 0.557913\n-----***-----\n0.5579133510167993\nEpoch 10/20 - 5.048801s - Loss 0.506001 - Accuracy 0.432292 - Test Loss 0.478560 - Test Accuracy 0.535809\nEpoch 11/20 - 5.020465s - Loss 0.470922 - Accuracy 0.505208 - Test Loss 0.480413 - Test Accuracy 0.559240\n-----***-----\n0.5592396109637489\nEpoch 12/20 - 5.029832s - Loss 0.533815 - Accuracy 0.338542 - Test Loss 0.492580 - Test Accuracy 0.521220\nEpoch 13/20 - 5.018238s - Loss 0.434517 - Accuracy 0.453125 - Test Loss 0.469672 - Test Accuracy 0.566313\n-----***-----\n0.5663129973474801\nEpoch 14/20 - 5.042158s - Loss 0.483545 - Accuracy 0.427083 - Test Loss 0.450059 - Test Accuracy 0.553935\nEpoch 15/20 - 5.028714s - Loss 0.485318 - Accuracy 0.442708 - Test Loss 0.449503 - Test Accuracy 0.558355\nEpoch 16/20 - 5.030634s - Loss 0.474748 - Accuracy 0.484375 - Test Loss 0.470892 - Test Accuracy 0.524757\nEpoch 17/20 - 5.027572s - Loss 0.499905 - Accuracy 0.354167 - Test Loss 0.445895 - Test Accuracy 0.568966\n-----***-----\n0.5689655172413793\nEpoch 18/20 - 5.057295s - Loss 0.473265 - Accuracy 0.401042 - Test Loss 0.448399 - Test Accuracy 0.535809\nEpoch 19/20 - 5.043442s - Loss 0.341957 - Accuracy 0.572917 - Test Loss 0.460834 - Test Accuracy 0.540230\nrepeat_0 [0.5689655172413793]\n{'repeat_0': {'0': {'precision': 0.12727272727272726, 'recall': 0.06862745098039216, 'f1-score': 0.08917197452229299, 'support': 102}, '1': {'precision': 0.40540540540540543, 'recall': 0.22556390977443608, 'f1-score': 0.2898550724637681, 'support': 133}, '2': {'precision': 0.2236842105263158, 'recall': 0.14655172413793102, 'f1-score': 0.17708333333333331, 'support': 116}, '3': {'precision': 0.1111111111111111, 'recall': 0.05319148936170213, 'f1-score': 0.07194244604316548, 'support': 94}, '4': {'precision': 0.25, 'recall': 0.08411214953271028, 'f1-score': 0.12587412587412586, 'support': 107}, '5': {'precision': 0.30952380952380953, 'recall': 0.11818181818181818, 'f1-score': 0.17105263157894737, 'support': 110}, '6': {'precision': 0.1896551724137931, 'recall': 0.1111111111111111, 'f1-score': 0.14012738853503184, 'support': 99}, '7': {'precision': 0.24107142857142858, 'recall': 0.24545454545454545, 'f1-score': 0.24324324324324326, 'support': 110}, '8': {'precision': 0.33766233766233766, 'recall': 0.23423423423423423, 'f1-score': 0.2765957446808511, 'support': 111}, 'micro avg': {'precision': 0.25217391304347825, 'recall': 0.14765784114052954, 'f1-score': 0.18625561978163135, 'support': 982}, 'macro avg': {'precision': 0.24393180027632536, 'recall': 0.14300315919654227, 'f1-score': 0.1761051066971955, 'support': 982}, 'weighted avg': {'precision': 0.25138941721608493, 'recall': 0.14765784114052954, 'f1-score': 0.18183944954907774, 'support': 982}, 'samples avg': {'precision': 0.04779693486590038, 'recall': 0.0641025641025641, 'f1-score': 0.052770409666961386, 'support': 982}}}\n{'repeat_0': {'0': {'precision': 0.12727272727272726, 'recall': 0.06862745098039216, 'f1-score': 0.08917197452229299, 'support': 102}, '1': {'precision': 0.40540540540540543, 'recall': 0.22556390977443608, 'f1-score': 0.2898550724637681, 'support': 133}, '2': {'precision': 0.2236842105263158, 'recall': 0.14655172413793102, 'f1-score': 0.17708333333333331, 'support': 116}, '3': {'precision': 0.1111111111111111, 'recall': 0.05319148936170213, 'f1-score': 0.07194244604316548, 'support': 94}, '4': {'precision': 0.25, 'recall': 0.08411214953271028, 'f1-score': 0.12587412587412586, 'support': 107}, '5': {'precision': 0.30952380952380953, 'recall': 0.11818181818181818, 'f1-score': 0.17105263157894737, 'support': 110}, '6': {'precision': 0.1896551724137931, 'recall': 0.1111111111111111, 'f1-score': 0.14012738853503184, 'support': 99}, '7': {'precision': 0.24107142857142858, 'recall': 0.24545454545454545, 'f1-score': 0.24324324324324326, 'support': 110}, '8': {'precision': 0.33766233766233766, 'recall': 0.23423423423423423, 'f1-score': 0.2765957446808511, 'support': 111}, 'micro avg': {'precision': 0.25217391304347825, 'recall': 0.14765784114052954, 'f1-score': 0.18625561978163135, 'support': 982}, 'macro avg': {'precision': 0.24393180027632536, 'recall': 0.14300315919654227, 'f1-score': 0.1761051066971955, 'support': 982}, 'weighted avg': {'precision': 0.25138941721608493, 'recall': 0.14765784114052954, 'f1-score': 0.18183944954907774, 'support': 982}, 'samples avg': {'precision': 0.04779693486590038, 'recall': 0.0641025641025641, 'f1-score': 0.052770409666961386, 'support': 982}}, 'accuracy': {'avg': 0.5689655172413793, 'std': 0.0}, 'time_train': {'avg': 101.13538670539856, 'std': 0.0}, 'time_test': {'avg': 0.4834890365600586, 'std': 0.0}, 'model': 'THAT', 'task': 'activity', 'data': {'num_users': ['0', '1', '2', '3', '4', '5'], 'wifi_band': ['2.4'], 'environment': ['classroom'], 'length': 3000}, 'nn': {'lr': 0.001, 'epoch': 20, 'batch_size': 64, 'threshold': 0.5}}\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/3169739687.py:148: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model_cm.load_state_dict(torch.load(best_path, map_location=device_cm))\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3169739687.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_33/3169739687.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mbest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"/kaggle/working/{name_run}_best_model.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mmodel_cm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_cm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mmodel_cm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for THAT:\n\tsize mismatch for layer_output.weight: copying a param with shape torch.Size([54, 288]) from checkpoint, the shape in current model is torch.Size([9, 288]).\n\tsize mismatch for layer_output.bias: copying a param with shape torch.Size([54]) from checkpoint, the shape in current model is torch.Size([9])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for THAT:\n\tsize mismatch for layer_output.weight: copying a param with shape torch.Size([54, 288]) from checkpoint, the shape in current model is torch.Size([9, 288]).\n\tsize mismatch for layer_output.bias: copying a param with shape torch.Size([54]) from checkpoint, the shape in current model is torch.Size([9]).","output_type":"error"}],"execution_count":18},{"cell_type":"markdown","source":"---\nCell 12: Few-shot Learning\n---\n---","metadata":{}},{"cell_type":"code","source":"# import gc\n# import torch\n# import shutil\n# import json\n# from sklearn.model_selection import train_test_split\n# from torch.utils.data import DataLoader, TensorDataset\n# import matplotlib.pyplot as plt\n# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n# from matplotlib.backends.backend_pdf import PdfPages\n\n# gc.collect()           \n# torch.cuda.empty_cache()  \n# torch.cuda.ipc_collect()\n\n# # ---------- helper: save multiclass confusion matrix ------------------\n# def save_multiclass_confusion_matrix(model, data_loader, pdf_path, num_classes):\n#     \"\"\"\n#     Forward‑pass on CPU, collect predictions, and write an N×N confusion matrix\n#     to a single‑page PDF (pdf_path).\n#     \"\"\"\n#     model.eval()\n#     y_true, y_pred = [], []\n#     with torch.no_grad():\n#         for xb, yb in data_loader:\n#             logits = model(xb.cpu())                       # ensure CPU\n#             preds  = torch.argmax(logits, dim=1).numpy()\n#             trues  = torch.argmax(yb, dim=1).numpy()\n#             y_pred.extend(preds.tolist())\n#             y_true.extend(trues.tolist())\n\n#     labels = list(range(num_classes))\n#     cm  = confusion_matrix(y_true, y_pred, labels=labels)\n#     disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n#     fig, ax = plt.subplots(figsize=(8, 8))\n#     disp.plot(ax=ax, xticks_rotation=\"vertical\")\n#     ax.set_title(\"Few‑shot Confusion Matrix\")\n#     with PdfPages(pdf_path) as pdf:\n#         pdf.savefig(fig)\n#     plt.close(fig)\n\n# # -------------------- pick run_* function ------------------------------\n# if preset[\"model\"] == \"ST-RF\":\n#     run_model = run_strf\n# elif preset[\"model\"] == \"LSTM\":\n#     run_model = run_lstm\n# elif preset[\"model\"] == \"bi-LSTM\":\n#     run_model = run_bilstm\n# elif preset[\"model\"] == \"THAT\":\n#     run_model = run_that\n# elif preset[\"model\"] == \"ResNet18\":\n#     run_model = run_resnet\n# else:\n#     raise ValueError(f\"No few‑shot implementation for {preset['model']}.\")\n\n# # ------------------------ load / split data ----------------------------\n# data_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n#                         var_environment=[dest_env],\n#                         var_wifi_band=preset[\"data\"][\"wifi_band\"],\n#                         var_num_users=preset[\"data\"][\"num_users\"])\n\n# labels_list = data_pd_y[\"label\"].tolist()\n# data_x = load_data_x(preset[\"path\"][\"data_x\"], labels_list)\n# data_y = encode_data_y(data_pd_y, preset[\"task\"])\n\n# train_x, test_x, train_y, test_y = train_test_split(\n#     data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n\n# # Few-shot sample size\n# train_x = train_x[:few_shot_num_samples]\n# train_y = train_y[:few_shot_num_samples]\n\n# # ----------------------- few‑shot training -----------------------------\n# original_epochs = preset[\"nn\"][\"epoch\"]\n# preset[\"nn\"][\"epoch\"] = few_shot_epochs\n\n# # Load the best model weights\n# best_model_path = f\"{name_run}_best_model.pt\"\n\n# # Initialize the model \n# if preset[\"model\"] == \"LSTM\":\n#     model = LSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n#     # print('train_y_[0].shape:', train_y[0].shape)\n#     # print('train_x_[0].shape:', train_x[0].reshape(train_x[0].shape[0], -1).shape)\n# elif preset[\"model\"] == \"bi-LSTM\":\n#     model = BiLSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n# elif preset[\"model\"] == \"THAT\":\n#     model = THAT(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n# elif preset[\"model\"] == \"ResNet18\":\n#     model = ResNet18Model(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n# else:\n#     raise ValueError(f\"Model {preset['model']} not supported!\")\n\n# # Load the weights into the model\n# model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n# model = model.to('cuda')\n\n# # Fine-tune the model on few-shot data (note: `run_model` should now return only the result)\n# result = run_model(train_x, train_y, test_x, test_y, var_repeat=1, init_model=model)\n# print(result)\n\n# # --------------------- save few‑shot checkpoints -----------------------\n# # After fine-tuning, save the model\n# torch.save(model.state_dict(), f\"{name_run}_fewshot_final_model.pt\")\n# torch.save(model.state_dict(), f\"{name_run}_fewshot_best_model.pt\")\n\n# # ------------------- confusion matrix on CPU ---------------------------\n# if Confusion_matrix == 1 and preset[\"model\"] != \"ST-RF\":\n\n#     # reshape for sequence models\n#     test_x_rs = (test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n#                  if preset[\"model\"] in (\"LSTM\", \"bi-LSTM\", \"THAT\") else test_x)\n\n#     # instantiate identical architecture on CPU\n#     if preset[\"model\"] == \"LSTM\":\n#         model_cpu = LSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n#     elif preset[\"model\"] == \"bi-LSTM\":\n#         model_cpu = BiLSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n#     elif preset[\"model\"] == \"THAT\":\n#         model_cpu = THAT(test_x_rs[0].shape, test_y[0].shape).cpu()\n#     else:  # ResNet18\n#         model_cpu = ResNet18Model(test_x_rs[0].shape, test_y[0].shape).cpu()\n\n#     # load weights\n#     model_cpu.load_state_dict(torch.load(f\"{name_run}_fewshot_best_model.pt\", map_location=\"cpu\"))\n\n#     # CPU DataLoader with a safe batch size\n#     test_ds = TensorDataset(torch.from_numpy(test_x_rs).float(),\n#                             torch.from_numpy(test_y).float())\n#     test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n\n#     pdf_name = f\"{name_run}_fewshot_confusion_matrix.pdf\"\n#     num_classes = test_y.shape[1]\n#     save_multiclass_confusion_matrix(model_cpu, test_loader, pdf_name, num_classes)\n#     print(f\"✅ Saved few‑shot confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\n\n# # ----------------------- restore & persist -----------------------------\n# preset[\"nn\"][\"epoch\"] = original_epochs\n\n# # Save the final result to JSON\n# with open(\"result_fewshot.json\", \"w\") as f:\n#     json.dump(result, f, indent=4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport scipy.io as scio\nimport time\nimport torch\nimport gc\nfrom numpy.linalg import svd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nfrom copy import deepcopy\nimport json\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch._dynamo\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport matplotlib.pyplot as plt\n\n# --- تنظیمات سیستمی ---\ntorch.cuda.empty_cache()\ntorch.set_float32_matmul_precision(\"high\")\n\n# --------------------------\n# 1. تنظیمات (Configuration)\n# --------------------------\npreset = {\n    \"model\": \"THAT\",          \n    \"task\": \"activity\",       \n    \"repeat\": 1,\n    \"path\": {\n        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   \n        \"data_y\": \"/kaggle/input/wimans/annotation.csv\", \n    },\n    \"data\": {\n        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  \n        \"wifi_band\": [\"2.4\"],                         \n        \"environment\": [\"classroom\"],                 \n        \"length\": 3000,\n        \n        # 1.0 = 100% data (Full run) | 0.1 = 10% data (Quick test)\n        \"subset_ratio\": 0.5,  \n    },\n    \"nn\": {\n        \"lr\": 1e-3,           \n        \"epoch\": 80,          \n        \"batch_size\": 32,    \n        \"threshold\": 0.5,\n        \"patience\": 5,        \n        \"factor\": 0.5,        \n        \"min_lr\": 1e-6        \n    },\n    \"encoding\": {\n        \"activity\": {\n            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n        },\n    },\n}\n\n# --------------------------\n# 2. توابع RPCA و لود دیتا\n# --------------------------\ndef soft_threshold(x, epsilon):\n    return np.maximum(np.abs(x) - epsilon, 0) * np.sign(x)\n\ndef robust_pca(M, max_iter=10, tol=1e-4):\n    n1, n2 = M.shape\n    lambda_param = 1 / np.sqrt(max(n1, n2))\n    Y = M / np.maximum(np.linalg.norm(M, 2), np.linalg.norm(M, np.inf) / lambda_param)\n    L = np.zeros_like(M)\n    S = np.zeros_like(M)\n    mu = 1.25 / np.linalg.norm(M, 2)\n    rho = 1.5\n    for i in range(max_iter):\n        temp_L = M - S + (1/mu) * Y\n        U, Sigma, Vt = svd(temp_L, full_matrices=False)\n        Sigma_thresh = soft_threshold(Sigma, 1/mu)\n        L_new = np.dot(U * Sigma_thresh, Vt)\n        temp_S = M - L_new + (1/mu) * Y\n        S_new = soft_threshold(temp_S, lambda_param/mu)\n        error = np.linalg.norm(M - L_new - S_new, 'fro') / np.linalg.norm(M, 'fro')\n        L = L_new; S = S_new\n        if error < tol: break\n        Y = Y + mu * (M - L - S)\n        mu = min(mu * rho, 1e7)\n    return L, S\n\ndef load_data_y(var_path_data_y, var_environment=None, var_wifi_band=None, var_num_users=None):\n    data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n    if var_environment is not None: data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n    if var_wifi_band is not None: data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n    if var_num_users is not None: data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n    return data_pd_y\n\ndef load_data_x(var_path_data_x, var_label_list, use_rpca=True):\n    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n    data_x = []\n    mode_str = \"WITH RPCA\" if use_rpca else \"RAW DATA (No RPCA)\"\n    print(f\"Loading {len(var_path_list)} samples - Mode: {mode_str}...\")\n    for i, var_path in enumerate(var_path_list):\n        if i % 100 == 0 and i > 0: print(f\"Processing {i}/{len(var_path_list)}...\")\n        data_csi = np.load(var_path) \n        data_csi_2d = data_csi.reshape(data_csi.shape[0], -1)\n        target_len = preset[\"data\"][\"length\"]\n        current_len = data_csi_2d.shape[0]\n        var_pad_length = target_len - current_len\n        if var_pad_length > 0: data_csi_pad = np.pad(data_csi_2d, ((0, var_pad_length), (0, 0)), mode='constant')\n        else: data_csi_pad = data_csi_2d[:target_len, :]\n        if use_rpca:\n            L, S = robust_pca(data_csi_pad)\n            final_sample = np.concatenate([L, S], axis=1) \n        else:\n            final_sample = data_csi_pad\n        data_x.append(final_sample)\n    data_x = np.array(data_x)\n    return data_x\n\ndef encode_data_y(data_pd_y, var_task):\n    if var_task == \"activity\": return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n\ndef encode_activity(data_pd_y, var_encoding):\n    cols = [f\"user_{i}_activity\" for i in range(1, 7)]\n    data = data_pd_y[cols].to_numpy(copy=True).astype(str)\n    return np.array([[var_encoding[y] for y in sample] for sample in data])\n\n# --------------------------\n# 3. مدل THAT\n# --------------------------\nclass Gaussian_Position(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n        super(Gaussian_Position, self).__init__()\n        self.var_embedding = torch.nn.Parameter(torch.zeros([var_num_gaussian, var_dim_feature]), requires_grad=True)\n        torch.nn.init.xavier_uniform_(self.var_embedding)\n        self.var_position = torch.nn.Parameter(torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian), requires_grad=False)\n        self.var_mu = torch.nn.Parameter(torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0), requires_grad=True)\n        self.var_sigma = torch.nn.Parameter(torch.tensor([50.0] * var_num_gaussian).unsqueeze(0), requires_grad=True)\n    def forward(self, var_input):\n        var_pdf = - (self.var_position - self.var_mu)**2 / (2 * self.var_sigma**2) - torch.log(self.var_sigma)\n        var_pdf = torch.softmax(var_pdf, dim=-1)\n        return var_input + torch.matmul(var_pdf, self.var_embedding).unsqueeze(0)\n\nclass Encoder(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n        super(Encoder, self).__init__()\n        self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n        self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n        self.layer_dropout_0 = torch.nn.Dropout(0.1)\n        self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n        self.layer_cnn = torch.nn.ModuleList([torch.nn.Sequential(torch.nn.Conv1d(var_dim_feature, var_dim_feature, s, padding=\"same\"), torch.nn.BatchNorm1d(var_dim_feature), torch.nn.Dropout(0.1), torch.nn.LeakyReLU()) for s in var_size_cnn])\n        self.layer_dropout_1 = torch.nn.Dropout(0.1)\n    def forward(self, var_input):\n        var_t = self.layer_norm_0(var_input)\n        var_t, _ = self.layer_attention(var_t, var_t, var_t)\n        var_t = self.layer_dropout_0(var_t) + var_input\n        var_s = self.layer_norm_1(var_t).permute(0, 2, 1)\n        var_c = torch.stack([l(var_s) for l in self.layer_cnn], dim=0)\n        var_s = self.layer_dropout_1((torch.sum(var_c, dim=0) / len(self.layer_cnn)).permute(0, 2, 1))\n        return var_s + var_t\n\nclass THAT(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(THAT, self).__init__()\n        var_dim_feature, var_dim_time = var_x_shape[-1], var_x_shape[-2]\n        var_dim_output = var_y_shape[-1]\n        self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n        self.layer_left_encoder = torch.nn.ModuleList([Encoder(var_dim_feature, 10, [1, 3, 5]) for _ in range(4)])\n        self.layer_left_norm = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n        self.layer_left_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_feature, 128, k) for k in [8, 16]])\n        self.layer_left_dropout = torch.nn.Dropout(0.5)\n        var_dim_right = var_dim_time // 20\n        self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        self.layer_right_encoder = torch.nn.ModuleList([Encoder(var_dim_right, 10, [1, 2, 3])])\n        self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n        self.layer_right_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_right, 16, k) for k in [2, 4]])\n        self.layer_right_dropout = torch.nn.Dropout(0.5)\n        self.layer_leakyrelu = torch.nn.LeakyReLU()\n        self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n    def forward(self, var_input):\n        v_l = self.layer_left_gaussian(self.layer_left_pooling(var_input.permute(0, 2, 1)).permute(0, 2, 1))\n        for l in self.layer_left_encoder: v_l = l(v_l)\n        v_l = self.layer_left_norm(v_l).permute(0, 2, 1)\n        v_l = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_l)), dim=-1) for cnn in self.layer_left_cnn], dim=-1)\n        v_l = self.layer_left_dropout(v_l)\n        v_r = self.layer_right_pooling(var_input.permute(0, 2, 1))\n        for l in self.layer_right_encoder: v_r = l(v_r)\n        v_r = self.layer_right_norm(v_r).permute(0, 2, 1)\n        v_r = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_r)), dim=-1) for cnn in self.layer_right_cnn], dim=-1)\n        v_r = self.layer_right_dropout(v_r)\n        return self.layer_output(torch.cat([v_l, v_r], dim=-1))\n\n# --------------------------\n# 4. Training Loop\n# --------------------------\ndef train(model, optimizer, loss_fn, train_loader, test_loader, threshold, epochs, device, model_path):\n    best_acc = -1.0\n    best_w = deepcopy(model.state_dict())\n    \n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=preset[\"nn\"][\"factor\"], patience=preset[\"nn\"][\"patience\"],\n        min_lr=preset[\"nn\"][\"min_lr\"], verbose=True\n    )\n    \n    for epoch in range(epochs):\n        t0 = time.time()\n        model.train()\n        \n        # --- [MODIFIED] Using requested variable names ---\n        for data_batch_x, data_batch_y in train_loader:\n            data_batch_x = data_batch_x.to(device)\n            data_batch_y = data_batch_y.to(device)\n            \n            optimizer.zero_grad()\n            \n            predict_train_y = model(data_batch_x)\n            \n            # --- [REQUESTED LINE] ---\n            loss_value = loss_fn(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n            \n            loss_value.backward()\n            optimizer.step()\n            \n        model.eval()\n        with torch.no_grad():\n            tx, ty = next(iter(test_loader))\n            tx, ty = tx.to(device), ty.to(device)\n            pred_t = model(tx)\n            \n            p_cls = (torch.sigmoid(pred_t) > threshold).float().cpu().numpy()\n            t_cls = ty.cpu().numpy()\n            acc = accuracy_score(t_cls.reshape(-1, t_cls.shape[-1]), p_cls.reshape(-1, t_cls.shape[-1]))\n            \n        scheduler.step(acc)\n        current_lr = optimizer.param_groups[0]['lr']\n        print(f\"Ep {epoch+1}/{epochs} | LR: {current_lr:.6f} | L_tr: {loss_value.item():.4f} | Acc: {acc:.4f}\")\n        \n        if acc > best_acc:\n            best_acc = acc\n            best_w = deepcopy(model.state_dict())\n            \n    torch.save(best_w, model_path)\n    return best_w\n\ndef save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes, title_text):\n    model.eval()\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb) \n            logits = logits.reshape(-1, num_classes) \n            yb = yb.reshape(-1, num_classes)        \n            y_pred.extend(torch.argmax(logits, dim=1).cpu().numpy().tolist())\n            y_true.extend(torch.argmax(yb, dim=1).cpu().numpy().tolist())\n    \n    labels = list(range(num_classes))\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n    fig, ax = plt.subplots(figsize=(12, 12))\n    disp.plot(ax=ax, xticks_rotation=\"vertical\", cmap='Blues')\n    ax.set_title(title_text)\n    with PdfPages(pdf_path) as pdf: pdf.savefig(fig)\n    plt.close(fig)\n\n# --------------------------\n# 5. اجرا\n# --------------------------\ndef run_experiment(scenario_name, use_rpca):\n    print(f\"\\n################################################\")\n    print(f\"STARTING SCENARIO: {scenario_name}\")\n    print(f\"################################################\")\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    current_run_name = f\"{preset['model']}_{preset['task']}_{scenario_name}\"\n    model_save_path = f\"{current_run_name}_best_model.pt\"\n    json_save_path = f\"result_{current_run_name}.json\"\n    pdf_save_path = f\"Confusion_{current_run_name}.pdf\"\n    \n    # 1. Load Labels\n    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], preset[\"data\"][\"environment\"], preset[\"data\"][\"wifi_band\"], preset[\"data\"][\"num_users\"])\n    \n    # Apply Subset Ratio\n    subset_ratio = preset[\"data\"][\"subset_ratio\"]\n    if subset_ratio < 1.0:\n        data_pd_y = data_pd_y.sample(frac=subset_ratio, random_state=42).reset_index(drop=True)\n        print(f\"*** DEBUG MODE: Using {subset_ratio*100}% of data ({len(data_pd_y)} samples) ***\")\n    \n    # 2. Load X\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], data_pd_y[\"label\"].tolist(), use_rpca=use_rpca)\n    data_y = encode_data_y(data_pd_y, preset[\"task\"])\n    \n    # 3. Split\n    train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n    train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n    test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n    train_loader = DataLoader(train_ds, batch_size=preset[\"nn\"][\"batch_size\"], shuffle=True)\n    test_loader = DataLoader(test_ds, batch_size=len(test_ds), shuffle=False)\n    \n    result = {\"accuracy\": []}\n    \n    for r in range(preset[\"repeat\"]):\n        print(f\"--- Repeat {r+1}/{preset['repeat']} ---\")\n        torch.random.manual_seed(r + 39)\n        \n        model = THAT(train_x[0].shape, train_y[0].reshape(-1).shape).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=preset[\"nn\"][\"lr\"])\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        \n        best_w = train(model, optimizer, loss_fn, train_loader, test_loader, \n                       preset[\"nn\"][\"threshold\"], preset[\"nn\"][\"epoch\"], device, model_save_path)\n        \n        model.load_state_dict(best_w)\n        with torch.no_grad():\n            preds = model(torch.from_numpy(test_x).to(device))\n            preds_reshaped = (torch.sigmoid(preds) > preset[\"nn\"][\"threshold\"]).float().cpu().numpy().reshape(-1, 9)\n            targets_reshaped = test_y.reshape(-1, 9)\n            acc = accuracy_score(targets_reshaped, preds_reshaped)\n            result[\"accuracy\"].append(acc)\n            \n    print(f\"Final Accuracy ({scenario_name}): {np.mean(result['accuracy']):.4f}\")\n    with open(json_save_path, \"w\") as f: json.dump(result, f, indent=4)\n    \n    print(\"Generating Confusion Matrix...\")\n    model_cm = THAT(test_x[0].shape, test_y[0].reshape(-1).shape).to(\"cpu\")\n    model_cm.load_state_dict(torch.load(model_save_path, map_location=\"cpu\"))\n    cm_loader = DataLoader(TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y)), batch_size=32)\n    num_classes = test_y.shape[2] \n    title = f\"Confusion Matrix: {scenario_name} (Acc: {np.mean(result['accuracy']):.2f} - {subset_ratio*100}% Data)\"\n    save_multiclass_confusion_matrix(model_cm, cm_loader, \"cpu\", pdf_save_path, num_classes, title)\n    \n    del model, model_cm, train_x, test_x, data_x\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(f\"Done with {scenario_name}.\\n\")\n\ndef run():\n    scenarios = [\n        (\"RPCA\", True),\n        (\"RAW\", False)\n    ]\n    for name, rpca_flag in scenarios:\n        run_experiment(name, rpca_flag)\n\nif __name__ == \"__main__\":\n    run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:48:21.536089Z","iopub.execute_input":"2025-11-24T13:48:21.536388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}