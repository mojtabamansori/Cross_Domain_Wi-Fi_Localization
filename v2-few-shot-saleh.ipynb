{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7638081,"sourceType":"datasetVersion","datasetId":4451316},{"sourceId":11934698,"sourceType":"datasetVersion","datasetId":7503373}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\nCell 1: Library Imports\n---\n---","metadata":{}},{"cell_type":"code","source":"# Cell 1: Library Imports\nimport os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport scipy.io as scio\nimport time\nimport torch\ntorch.cuda.empty_cache()\nimport torch._dynamo\nfrom torch.utils.data import TensorDataset, DataLoader\n# from ptflops import get_model_complexity_info\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom copy import deepcopy\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:09:44.930111Z","iopub.execute_input":"2025-12-13T16:09:44.930407Z","iopub.status.idle":"2025-12-13T16:09:52.912866Z","shell.execute_reply.started":"2025-12-13T16:09:44.930378Z","shell.execute_reply":"2025-12-13T16:09:52.912298Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"---\nCell 2: preset.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          preset.py\n[description]   default settings of WiFi-based models\n\"\"\"\nminidata_set = 1\npreset = {\n    # define model\n    \"model\": \"THAT\",  # \"ST-RF\", \"MLP\", \"LSTM\", \"CNN-1D\", \"CNN-2D\", \"CLSTM\", \"ABLSTM\", \"THAT\", \"bi-LSTM\", \"ResNet18\"\n    # define task\n    \"task\": \"activity\",  # \"identity\", \"activity\", \"location\", \"count\"\n    # number of repeated experiments\n    \"repeat\": 1,\n    # path of data\n    \"path\": {\n        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   # directory of CSI amplitude files \n        \"data_y\": \"/kaggle/input/wimans/annotation.csv\", # path of annotation file\n        \"save\": \"result_lstm_epoch=80_batchsize=32_envs=empty_room_wifiband=2.4.json\"               # path to save results\n    },\n    # data selection for experiments\n    \"data\": {\n        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  # select number(s) of users\n        \"wifi_band\": [\"2.4\"],                         # select WiFi band(s)\n        \"environment\": [\"classroom\"],                 # select environment(s) [\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\n        \"length\": 3000,                               # default length of CSI\n    },\n    # hyperparameters of models\n    \"nn\": {\n        \"lr\": 1e-3,           # learning rate\n        \"epoch\": 10,         # number of epochs\n        \"batch_size\": 64,    # batch size\n        \"threshold\": 0.5,     # threshold to binarize sigmoid outputs\n    },\n    # encoding of activities and locations\n    \"encoding\": {\n        \"activity\": {  # encoding of different activities\n            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n        },\n        \"location\": {  # encoding of different locations\n            \"nan\":  [0, 0, 0, 0, 0],\n            \"a\":    [1, 0, 0, 0, 0],\n            \"b\":    [0, 1, 0, 0, 0],\n            \"c\":    [0, 0, 1, 0, 0],\n            \"d\":    [0, 0, 0, 1, 0],\n            \"e\":    [0, 0, 0, 0, 1],\n        },\n    },\n}\n\n\n# Few-shot parameters (manually set)\ndest_env = \"empty_room\"       # Destination environment[\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\nfew_shot_epochs = 100         # Number of epochs for few-shot training\nfew_shot_num_samples = 5     # Number of samples to use from the destination test data\n\nConfusion_matrix = 1\n\nname_run = \"few={},{},{},m={},t={},epoch={},batch={},environment={}\".format(dest_env, few_shot_epochs, few_shot_num_samples, preset[\"model\"], preset[\"task\"], preset[\"nn\"][\"epoch\"], preset[\"nn\"][\"batch_size\"], preset[\"data\"][\"environment\"])\nprint(name_run)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:09:52.914353Z","iopub.execute_input":"2025-12-13T16:09:52.914646Z","iopub.status.idle":"2025-12-13T16:09:52.924771Z","shell.execute_reply.started":"2025-12-13T16:09:52.914630Z","shell.execute_reply":"2025-12-13T16:09:52.924072Z"}},"outputs":[{"name":"stdout","text":"few=empty_room,100,5,m=THAT,t=activity,epoch=100,batch=64,environment=['classroom']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"---\nCell 3: load_data.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          load_data.py\n[description]   load annotation file and CSI amplitude, and encode labels\n\"\"\"\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n# Note: All necessary libraries (os, numpy, pandas, etc.) are imported in Cell 1.\n# from preset import preset   --> preset is already defined in Cell 2.\n\n# =========================================================\n# ğŸ”§ NEW: Choose CSI representation mode here (ONLY EDIT THIS)\n# ---------------------------------------------------------\n# \"raw\"     : use original CSI amplitude as-is\n# \"lowrank\" : use low-rank approximation (SVD)\n# \"sparse\"  : keep only large-magnitude entries (dense array with many zeros)\nCSI_INPUT_MODE = \"raw\"     # <-- set to: \"raw\" / \"lowrank\" / \"sparse\"\n\n# Low-rank settings\nLOW_RANK_ENERGY = 0.95     # keep enough singular values to preserve this energy\nLOW_RANK_RANK   = None     # if set to an int (e.g., 10), it overrides ENERGY\n\n# Sparse settings\nSPARSE_KEEP_RATIO = 0.10   # keep top 10% magnitudes (globally per sample)\nSPARSE_MIN_ABS    = None   # if set (e.g., 0.5), keeps |x|>=threshold instead of keep_ratio\n# =========================================================\n\n\ndef _low_rank_approx_keep_shape(X, rank=None, energy=0.95):\n    \"\"\"\n    Low-rank approximation using SVD while preserving the original shape.\n    Works for 1D/2D/ND by flattening all non-time dims into features.\n    Assumes first axis is time.\n    \"\"\"\n    X = np.asarray(X, dtype=np.float32)\n\n    if X.ndim == 1:\n        M = X[:, None]  # (T,1)\n        U, S, Vt = np.linalg.svd(M, full_matrices=False)\n        if rank is None:\n            s2 = S**2\n            cum = np.cumsum(s2) / (np.sum(s2) + 1e-12)\n            rank = int(np.searchsorted(cum, energy) + 1)\n        rank = max(1, min(rank, S.shape[0]))\n        M_lr = (U[:, :rank] * S[:rank]) @ Vt[:rank, :]\n        return M_lr[:, 0].astype(np.float32)\n\n    # ND: reshape to (T, F)\n    T = X.shape[0]\n    F = int(np.prod(X.shape[1:]))\n    M = X.reshape(T, F)\n\n    U, S, Vt = np.linalg.svd(M, full_matrices=False)\n\n    if rank is None:\n        s2 = S**2\n        cum = np.cumsum(s2) / (np.sum(s2) + 1e-12)\n        rank = int(np.searchsorted(cum, energy) + 1)\n\n    rank = max(1, min(rank, S.shape[0]))\n    M_lr = (U[:, :rank] * S[:rank]) @ Vt[:rank, :]\n\n    return M_lr.reshape(X.shape).astype(np.float32)\n\n\ndef _to_sparse_dense_keep_shape(X, keep_ratio=0.10, min_abs=None):\n    \"\"\"\n    Makes X sparse-in-content (many zeros) but keeps it as a dense numpy array\n    so the rest of the pipeline (np.save/np.load/pad/model) doesn't change.\n    Keeps the same shape.\n    \"\"\"\n    X = np.asarray(X, dtype=np.float32)\n    flat = X.ravel()\n    if flat.size == 0:\n        return X.astype(np.float32)\n\n    absflat = np.abs(flat)\n\n    if min_abs is not None:\n        thr = float(min_abs)\n        mask = absflat >= thr\n    else:\n        k = int(np.ceil(keep_ratio * flat.size))\n        k = max(1, min(k, flat.size))\n        if k == flat.size:\n            mask = np.ones_like(absflat, dtype=bool)\n        else:\n            thr = np.partition(absflat, -k)[-k]\n            mask = absflat >= thr\n\n    out = np.zeros_like(flat, dtype=np.float32)\n    out[mask] = flat[mask]\n    return out.reshape(X.shape).astype(np.float32)\n\n\ndef _apply_csi_mode(data_csi):\n    \"\"\"\n    Apply selected CSI_INPUT_MODE to a single sample array.\n    \"\"\"\n    if CSI_INPUT_MODE == \"raw\":\n        return data_csi.astype(np.float32, copy=False)\n\n    elif CSI_INPUT_MODE == \"lowrank\":\n        return _low_rank_approx_keep_shape(\n            data_csi,\n            rank=LOW_RANK_RANK,\n            energy=LOW_RANK_ENERGY\n        )\n\n    elif CSI_INPUT_MODE == \"sparse\":\n        return _to_sparse_dense_keep_shape(\n            data_csi,\n            keep_ratio=SPARSE_KEEP_RATIO,\n            min_abs=SPARSE_MIN_ABS\n        )\n\n    else:\n        raise ValueError(f\"Unknown CSI_INPUT_MODE: {CSI_INPUT_MODE}. Use 'raw', 'lowrank', or 'sparse'.\")\n\n\ndef load_data_y(var_path_data_y,\n                var_environment=None, \n                var_wifi_band=None, \n                var_num_users=None):\n    \"\"\"\n    Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n    \"\"\"\n    data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n    if var_environment is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n    if var_wifi_band is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n    if var_num_users is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n    return data_pd_y\n\n\ndef load_data_x(var_path_data_x, var_label_list):\n    \"\"\"\n    Load CSI amplitude (*.npy) files based on a label list.\n    \"\"\"\n    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n    data_x = []\n    for var_path in var_path_list:\n        data_csi = np.load(var_path)\n\n        # âœ… NEW: convert input CSI according to selected mode (raw/lowrank/sparse)\n        data_csi = _apply_csi_mode(data_csi)\n\n        var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n        data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n        data_x.append(data_csi_pad)\n    data_x = np.array(data_x)\n    return data_x\n\n\ndef encode_data_y(data_pd_y, var_task):\n    \"\"\"\n    Encode labels according to specific task.\n    \"\"\"\n    if var_task == \"identity\":\n        data_y = encode_identity(data_pd_y)\n    elif var_task == \"activity\":\n        data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    elif var_task == \"location\":\n        data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n    elif var_task == \"count\":\n        data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n    return data_y\n\n\ndef encode_identity(data_pd_y):\n    \"\"\"\n    Onehot encoding for identity labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_identity_y[data_identity_y != \"nan\"] = 1\n    data_identity_y[data_identity_y == \"nan\"] = 0\n    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n    return data_identity_onehot_y\n\n\ndef encode_activity(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for activity labels.\n    \"\"\"\n    data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n                                    \"user_3_activity\", \"user_4_activity\", \n                                    \"user_5_activity\", \"user_6_activity\"]]\n    data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n    data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n    return data_activity_onehot_y\n\n\ndef encode_location(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for location labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n    return data_location_onehot_y\n\n\ndef encode_count(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for identity labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_identity_y[data_identity_y != \"nan\"] = 1\n    data_identity_y[data_identity_y == \"nan\"] = 0\n    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n    print(\"data_identity_onehot_y\",data_identity_onehot_y.shape)\n    count_data = np.sum(data_identity_onehot_y, axis=1)\n    print(\"count_data\",count_data.shape)\n    count_data = count_data.reshape(-1, 1)  # shape = (11286, 1)\n    encoder = OneHotEncoder(sparse=False)  \n    count_data_onehot = encoder.fit_transform(count_data)\n    print(count_data_onehot.shape)  \n    count_data_onehot = count_data_onehot.astype(\"int8\")\n\n    return count_data_onehot\n\n\n# Test functions (optional)\ndef test_load_data_y():\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"classroom\"]).describe())\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"]).describe())\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=[\"1\", \"2\", \"3\"]).describe())\n\ndef test_load_data_x():\n    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=None)\n    var_label_list = data_pd_y[\"label\"].to_list()\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n    print(data_x.shape)\n\ndef test_encode_identity():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_identity_onehot_y = encode_identity(data_pd_y)\n    print(data_identity_onehot_y.shape)\n    print(data_identity_onehot_y[2000])\n\ndef test_encode_activity():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    print(data_activity_onehot_y.shape)\n    print(data_activity_onehot_y[1560])\n\ndef test_encode_location():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n    print(data_location_onehot_y.shape)\n    print(data_location_onehot_y[1560])\n\ndef test_encode_count():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_count_onehot_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n    print(data_count_onehot_y.shape)\n    print(data_count_onehot_y[20])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \"\"\"\n# [file]          load_data.py\n# [description]   load annotation file and CSI amplitude, and encode labels\n# \"\"\"\n# from sklearn.preprocessing import OneHotEncoder\n# import numpy as np\n\n# # Note: All necessary libraries (os, numpy, pandas, etc.) are imported in Cell 1.\n# # from preset import preset   --> preset is already defined in Cell 2.\n\n# def load_data_y(var_path_data_y,\n#                 var_environment=None, \n#                 var_wifi_band=None, \n#                 var_num_users=None):\n#     \"\"\"\n#     Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n#     \"\"\"\n#     data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n#     if var_environment is not None:\n#         data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n#     if var_wifi_band is not None:\n#         data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n#     if var_num_users is not None:\n#         data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n#     return data_pd_y\n\n# def load_data_x(var_path_data_x, var_label_list):\n#     \"\"\"\n#     Load CSI amplitude (*.npy) files based on a label list.\n#     \"\"\"\n#     var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n#     data_x = []\n#     for var_path in var_path_list:\n#         data_csi = np.load(var_path)\n#         var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n#         data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n#         data_x.append(data_csi_pad)\n#     data_x = np.array(data_x)\n#     return data_x\n\n# def encode_data_y(data_pd_y, var_task):\n#     \"\"\"\n#     Encode labels according to specific task.\n#     \"\"\"\n#     if var_task == \"identity\":\n#         data_y = encode_identity(data_pd_y)\n#     elif var_task == \"activity\":\n#         data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n#     elif var_task == \"location\":\n#         data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n#     elif var_task == \"count\":\n#         data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n#     return data_y\n\n# def encode_identity(data_pd_y):\n#     \"\"\"\n#     Onehot encoding for identity labels.\n#     \"\"\"\n#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n#                                     \"user_3_location\", \"user_4_location\", \n#                                     \"user_5_location\", \"user_6_location\"]]\n#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n#     data_identity_y[data_identity_y != \"nan\"] = 1\n#     data_identity_y[data_identity_y == \"nan\"] = 0\n#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n#     return data_identity_onehot_y\n\n\n\n# def encode_activity(data_pd_y, var_encoding):\n#     \"\"\"\n#     Onehot encoding for activity labels.\n#     \"\"\"\n#     data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n#                                     \"user_3_activity\", \"user_4_activity\", \n#                                     \"user_5_activity\", \"user_6_activity\"]]\n#     data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n#     data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n#     return data_activity_onehot_y\n\n# def encode_location(data_pd_y, var_encoding):\n#     \"\"\"\n#     Onehot encoding for location labels.\n#     \"\"\"\n#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n#                                     \"user_3_location\", \"user_4_location\", \n#                                     \"user_5_location\", \"user_6_location\"]]\n#     data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n#     data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n#     return data_location_onehot_y\n\n# # Test functions (optional)\n# def test_load_data_y():\n#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"classroom\"]).describe())\n#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"]).describe())\n#     print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=[\"1\", \"2\", \"3\"]).describe())\n\n# def test_load_data_x():\n#     data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=None)\n#     var_label_list = data_pd_y[\"label\"].to_list()\n#     data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n#     print(data_x.shape)\n\n# def test_encode_identity():\n#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n#     data_identity_onehot_y = encode_identity(data_pd_y)\n#     print(data_identity_onehot_y.shape)\n#     print(data_identity_onehot_y[2000])\n\n# def test_encode_activity():\n#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n#     data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n#     print(data_activity_onehot_y.shape)\n#     print(data_activity_onehot_y[1560])\n\n# def test_encode_location():\n#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n#     data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n#     print(data_location_onehot_y.shape)\n#     print(data_location_onehot_y[1560])\n\n# def encode_count(data_pd_y, var_encoding):\n#     \"\"\"\n#     Onehot encoding for identity labels.\n#     \"\"\"\n#     data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n#                                     \"user_3_location\", \"user_4_location\", \n#                                     \"user_5_location\", \"user_6_location\"]]\n#     data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n#     data_identity_y[data_identity_y != \"nan\"] = 1\n#     data_identity_y[data_identity_y == \"nan\"] = 0\n#     data_identity_onehot_y = data_identity_y.astype(\"int8\")\n#     print(\"data_identity_onehot_y\",data_identity_onehot_y.shape)\n#     count_data = np.sum(data_identity_onehot_y, axis=1)\n#     print(\"count_data\",count_data.shape)\n#     count_data = count_data.reshape(-1, 1)  # shape = (11286, 1)\n#     encoder = OneHotEncoder(sparse=False)  \n#     count_data_onehot = encoder.fit_transform(count_data)\n#     print(count_data_onehot.shape)  \n#     count_data_onehot = count_data_onehot.astype(\"int8\")\n\n#     return count_data_onehot\n\n\n# def test_encode_count():\n#     data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n#     data_count_onehot_y = encode_count(data_pd_y)\n#     print(data_count_onehot_y.shape)\n#     print(data_count_onehot_y[20])\n\n# # if __name__ == \"__main__\":\n# #     test_encode_count()\n# #     test_load_data_y()\n# #     test_load_data_x()\n# #     test_encode_identity()\n# #     test_encode_activity()\n# #     test_encode_location()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:09:52.925598Z","iopub.execute_input":"2025-12-13T16:09:52.925831Z","iopub.status.idle":"2025-12-13T16:09:52.964915Z","shell.execute_reply.started":"2025-12-13T16:09:52.925815Z","shell.execute_reply":"2025-12-13T16:09:52.964114Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"---\nCell 4: preprocess.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          preprocess.py\n[description]   preprocess WiFi CSI data\n\"\"\"\n\n# All necessary libraries are already imported in Cell 1.\n\n# def mat_to_amp(data_mat):\n#     \"\"\"\n#     Calculate amplitude of raw WiFi CSI data.\n#     \"\"\"\n#     var_length = data_mat[\"trace\"].shape[0]\n#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n#     return data_csi_amp\n\ndef extract_csi_amp(var_dir_mat, var_dir_amp):\n    \"\"\"\n    Read raw WiFi CSI (*.mat) files, calculate CSI amplitude, and save as (*.npy).\n    \"\"\"\n    var_path_mat = os.listdir(var_dir_mat)\n    for var_c, var_path in enumerate(var_path_mat):\n        data_mat = scio.loadmat(os.path.join(var_dir_mat, var_path))\n        data_csi_amp = mat_to_amp(data_mat)\n        # print(var_c, data_csi_amp.shape)\n        var_path_save = os.path.join(var_dir_amp, var_path.replace(\".mat\", \".npy\"))\n        with open(var_path_save, \"wb\") as var_file:\n            np.save(var_file, data_csi_amp)\n\n\n\n# # ØªÙ†Ø¸ÛŒÙ…Ø§Øª low-rank (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ mat_to_amp)\n# LOW_RANK_ENERGY = 0.95   # Ù…Ø«Ù„Ø§Ù‹ 95% Ø§Ù†Ø±Ú˜ÛŒ\n# LOW_RANK_RANK = None     # Ø§Ú¯Ø± Ø¹Ø¯Ø¯ Ø¨Ø°Ø§Ø±ÛŒ (Ù…Ø«Ù„Ø§Ù‹ 5)ØŒ Ø¨Ù‡ Ø¬Ø§ÛŒ ENERGY Ø§Ø² rank Ø«Ø§Ø¨Øª Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒØ´Ù‡\n\n# def _low_rank_approx(X, rank=None, energy=0.95):\n#     X = np.asarray(X)\n\n#     was_1d = (X.ndim == 1)\n#     if was_1d:\n#         X = X[:, None]\n\n#     U, S, Vt = np.linalg.svd(X, full_matrices=False)\n\n#     if rank is None:\n#         s2 = S**2\n#         cum = np.cumsum(s2) / (np.sum(s2) + 1e-12)\n#         rank = int(np.searchsorted(cum, energy) + 1)\n\n#     rank = max(1, min(rank, S.shape[0]))\n#     X_lr = (U[:, :rank] * S[:rank]) @ Vt[:rank, :]\n\n#     if was_1d:\n#         X_lr = X_lr[:, 0]\n\n#     return X_lr.astype(np.float32)\n\n# def mat_to_amp(data_mat):\n#     \"\"\"\n#     Calculate amplitude of raw WiFi CSI data, then return its low-rank approximation.\n#     (ÙˆØ±ÙˆØ¯ÛŒ ØªØ§Ø¨Ø¹ ØªØºÛŒÛŒØ± Ù†Ú©Ø±Ø¯Ù‡)\n#     \"\"\"\n#     var_length = data_mat[\"trace\"].shape[0]\n#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n\n#     # Ø®Ø±ÙˆØ¬ÛŒ low-rank Ø¨Ø§ Ù‡Ù…Ø§Ù† Ø§Ø¨Ø¹Ø§Ø¯\n#     data_csi_amp_lr = _low_rank_approx(\n#         data_csi_amp,\n#         rank=LOW_RANK_RANK,\n#         energy=LOW_RANK_ENERGY\n#     )\n#     return data_csi_amp_lr\n\n\n\n# # ØªÙ†Ø¸ÛŒÙ…Ø§Øª sparsity (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ mat_to_amp)\n# SPARSE_KEEP_RATIO = 0.10   # Ù…Ø«Ù„Ø§ ÙÙ‚Ø· 10% Ø¨Ø²Ø±Ú¯ØªØ±ÛŒÙ† Ù…Ù‚Ø§Ø¯ÛŒØ± Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø´Ù†\n# SPARSE_MIN_ABS = None      # Ø§Ú¯Ø± Ø¹Ø¯Ø¯ Ø¨Ø°Ø§Ø±ÛŒ (Ù…Ø«Ù„Ø§ 0.5)ØŒ Ø¨Ù‡ Ø¬Ø§ÛŒ keep_ratio Ø¢Ø³ØªØ§Ù†Ù‡ Ø«Ø§Ø¨Øª Ù…ÛŒØ´Ù‡\n\n# def _to_sparse(X, keep_ratio=0.10, min_abs=None):\n#     \"\"\"\n#     Convert X to a sparse representation by keeping only large-magnitude entries.\n#     Returns:\n#       - scipy.sparse.csr_matrix if SciPy is available\n#       - otherwise returns a dense array with many zeros (still \"sparse\" in content)\n#     \"\"\"\n#     X = np.asarray(X)\n#     flat = X.ravel()\n#     absflat = np.abs(flat)\n\n#     if flat.size == 0:\n#         return X.astype(np.float32)\n\n#     # Ø§Ù†ØªØ®Ø§Ø¨ Ø¢Ø³ØªØ§Ù†Ù‡\n#     if min_abs is not None:\n#         thr = float(min_abs)\n#         mask = absflat >= thr\n#     else:\n#         k = int(np.ceil(keep_ratio * flat.size))\n#         k = max(1, min(k, flat.size))\n#         if k == flat.size:\n#             mask = np.ones_like(absflat, dtype=bool)\n#         else:\n#             thr = np.partition(absflat, -k)[-k]  # kth largest magnitude\n#             mask = absflat >= thr\n\n#     idx = np.nonzero(mask)[0]\n#     data = flat[idx].astype(np.float32)\n\n#     # Ø§Ú¯Ø± SciPy Ù‡Ø³Øª: sparse ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø³Ø§Ø²\n#     try:\n#         # Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ ØªÙˆ Cell1 ÛŒØ§ Ø§Ø² Ù‚Ø¨Ù„ import Ø´Ø¯Ù‡Ø› Ø§Ú¯Ø± Ù‡Ù… Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù‡ Ø§ÛŒÙ†Ø¬Ø§ ØªÙ„Ø§Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ù‡.\n#         import scipy.sparse as sp\n\n#         if X.ndim == 1:\n#             rows = idx\n#             cols = np.zeros_like(rows)\n#             shape = (X.shape[0], 1)\n#         else:\n#             rows, cols = np.unravel_index(idx, X.shape)\n#             shape = X.shape\n\n#         return sp.coo_matrix((data, (rows, cols)), shape=shape).tocsr()\n\n#     except Exception:\n#         # fallback: Ø¢Ø±Ø§ÛŒÙ‡â€ŒÛŒ dense Ø¨Ø§ ØµÙØ±Ù‡Ø§ÛŒ Ø²ÛŒØ§Ø¯\n#         out = np.zeros_like(flat, dtype=np.float32)\n#         out[idx] = data\n#         return out.reshape(X.shape)\n\ndef mat_to_amp(data_mat):\n    \"\"\"\n    Calculate amplitude of raw WiFi CSI data, then return its sparse version.\n    (ÙˆØ±ÙˆØ¯ÛŒ ØªØ§Ø¨Ø¹ ØªØºÛŒÛŒØ± Ù†Ú©Ø±Ø¯Ù‡)\n    \"\"\"\n    var_length = data_mat[\"trace\"].shape[0]\n    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n    data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n\n    # Ø®Ø±ÙˆØ¬ÛŒ sparse (CSR Ø§Ú¯Ø± SciPy Ø¨Ø§Ø´Ø¯)\n    return _to_sparse(data_csi_amp, keep_ratio=SPARSE_KEEP_RATIO, min_abs=SPARSE_MIN_ABS)\n\n# ØªÙ†Ø¸ÛŒÙ…Ø§Øª RPCA (Ù…ÛŒâ€ŒØªÙˆÙ†ÛŒ Ø¹ÙˆØ¶Ø´ÙˆÙ† Ú©Ù†ÛŒ)\nRPCA_MAX_ITER = 500\nRPCA_TOL = 1e-7\nRPCA_RHO = 1.5\nRPCA_MU_INIT = None     # None ÛŒØ¹Ù†ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±\nRPCA_LAMBDA = None      # None ÛŒØ¹Ù†ÛŒ 1/sqrt(max(m,n))\n\ndef _soft_threshold(X, tau):\n    return np.sign(X) * np.maximum(np.abs(X) - tau, 0.0)\n\ndef _svt(X, tau):\n    # Singular Value Thresholding\n    U, s, Vt = np.linalg.svd(X, full_matrices=False)\n    s_thr = np.maximum(s - tau, 0.0)\n    # Ø§Ú¯Ø± Ù‡Ù…Ù‡ ØµÙØ± Ø´Ø¯ØŒ Ø³Ø±ÛŒØ¹ Ø¨Ø±Ú¯Ø±Ø¯\n    if np.all(s_thr == 0):\n        return np.zeros_like(X)\n    return (U * s_thr) @ Vt\n\ndef _rpca_ialm(M, lam=None, mu=None, rho=1.5, max_iter=500, tol=1e-7):\n    \"\"\"\n    Robust PCA via Inexact Augmented Lagrange Multiplier (IALM)\n    Decompose: M = L + S\n    Returns: L, S (same shape as M)\n    \"\"\"\n    M = M.astype(np.float64, copy=False)\n    m, n = M.shape\n\n    if lam is None:\n        lam = 1.0 / np.sqrt(max(m, n))\n\n    # mu Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ (Ø®ÙˆØ¯Ú©Ø§Ø±)\n    if mu is None:\n        # ||M||_2 ØªÙ‚Ø±ÛŒØ¨Ø§Ù‹ Ø¨Ø²Ø±Ú¯â€ŒØªØ±ÛŒÙ† singular value Ø§Ø³Øª\n        norm2 = np.linalg.svd(M, compute_uv=False)[0] if M.size else 1.0\n        mu = 1.25 / (norm2 + 1e-12)\n\n    L = np.zeros_like(M)\n    S = np.zeros_like(M)\n    Y = np.zeros_like(M)\n\n    normM = np.linalg.norm(M, ord='fro') + 1e-12\n\n    for _ in range(max_iter):\n        # L update\n        L = _svt(M - S + (1.0/mu)*Y, 1.0/mu)\n\n        # S update (sparse)\n        S = _soft_threshold(M - L + (1.0/mu)*Y, lam/mu)\n\n        # dual update\n        R = M - L - S\n        Y = Y + mu * R\n\n        # stop\n        err = np.linalg.norm(R, ord='fro') / normM\n        if err < tol:\n            break\n\n        mu *= rho\n\n    return L.astype(np.float32), S.astype(np.float32)\n\n# def mat_to_amp(data_mat):\n#     \"\"\"\n#     Calculate amplitude of raw WiFi CSI data, then return RPCA sparse component S.\n#     (ÙˆØ±ÙˆØ¯ÛŒ ØªØ§Ø¨Ø¹ ØªØºÛŒÛŒØ± Ù†Ú©Ø±Ø¯Ù‡)\n#     \"\"\"\n#     var_length = data_mat[\"trace\"].shape[0]\n#     data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n#     data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n\n#     was_1d = (data_csi_amp.ndim == 1)\n#     M = data_csi_amp[:, None] if was_1d else data_csi_amp\n\n#     _, S = _rpca_ialm(\n#         M,\n#         lam=RPCA_LAMBDA,\n#         mu=RPCA_MU_INIT,\n#         rho=RPCA_RHO,\n#         max_iter=RPCA_MAX_ITER,\n#         tol=RPCA_TOL\n#     )\n\n#     if was_1d:\n#         S = S[:, 0]\n\n#     return S\n\ndef mat_to_amp(data_mat):\n    \"\"\"\n    Calculate amplitude of raw WiFi CSI data, then return RPCA low-rank component L.\n    (ÙˆØ±ÙˆØ¯ÛŒ ØªØ§Ø¨Ø¹ ØªØºÛŒÛŒØ± Ù†Ú©Ø±Ø¯Ù‡)\n    \"\"\"\n    var_length = data_mat[\"trace\"].shape[0]\n    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n    data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n\n    was_1d = (data_csi_amp.ndim == 1)\n    M = data_csi_amp[:, None] if was_1d else data_csi_amp\n\n    L, _ = _rpca_ialm(\n        M,\n        lam=RPCA_LAMBDA,\n        mu=RPCA_MU_INIT,\n        rho=RPCA_RHO,\n        max_iter=RPCA_MAX_ITER,\n        tol=RPCA_TOL\n    )\n\n    if was_1d:\n        L = L[:, 0]\n\n    return L\n\n\n\n\ndef parse_args():\n    \"\"\"\n    Parse arguments from input.\n    \"\"\"\n    var_args = argparse.ArgumentParser()\n    var_args.add_argument(\"--dir_mat\", default=\"/kaggle/input/wimans/wifi_csi/mat\", type=str)\n    var_args.add_argument(\"--dir_amp\", default=\"/kaggle/input/wimans/wifi_csi/amp\", type=str)\n    return var_args.parse_args()\n\n# if __name__ == \"__main__\":\n#     var_args = parse_args()\n#     extract_csi_amp(var_dir_mat=var_args.dir_mat, var_dir_amp=var_args.dir_amp)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:10:23.144799Z","iopub.execute_input":"2025-12-13T16:10:23.145480Z","iopub.status.idle":"2025-12-13T16:10:23.159750Z","shell.execute_reply.started":"2025-12-13T16:10:23.145454Z","shell.execute_reply":"2025-12-13T16:10:23.158973Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"---\nCell 5: that.py (WiFi-based Model THAT)\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          that.py\n[description]   implement and evaluate WiFi-based model THAT\n                https://github.com/windofshadow/THAT\n\"\"\"\n\n# All necessary libraries are imported in Cell 1.\n# from train import train   --> Defined in Cell 6.\n# from preset import preset --> Defined in Cell 2.\n\nclass Gaussian_Position(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n        super(Gaussian_Position, self).__init__()\n        var_embedding = torch.zeros([var_num_gaussian, var_dim_feature], dtype=torch.float)\n        self.var_embedding = torch.nn.Parameter(var_embedding, requires_grad=True)\n        torch.nn.init.xavier_uniform_(self.var_embedding)\n        var_position = torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian)\n        self.var_position = torch.nn.Parameter(var_position, requires_grad=False)\n        var_mu = torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0)\n        self.var_mu = torch.nn.Parameter(var_mu, requires_grad=True)\n        var_sigma = torch.tensor([50.0] * var_num_gaussian).unsqueeze(0)\n        self.var_sigma = torch.nn.Parameter(var_sigma, requires_grad=True)\n\n    def calculate_pdf(self, var_position, var_mu, var_sigma):\n        var_pdf = var_position - var_mu\n        var_pdf = - var_pdf * var_pdf\n        var_pdf = var_pdf / var_sigma / var_sigma / 2\n        var_pdf = var_pdf - torch.log(var_sigma)\n        return var_pdf\n\n    def forward(self, var_input):\n        var_pdf = self.calculate_pdf(self.var_position, self.var_mu, self.var_sigma)\n        var_pdf = torch.softmax(var_pdf, dim=-1)\n        var_position_encoding = torch.matmul(var_pdf, self.var_embedding)\n        var_output = var_input + var_position_encoding.unsqueeze(0)\n        return var_output\n\nclass Encoder(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n        super(Encoder, self).__init__()\n        self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n        self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n        self.layer_dropout_0 = torch.nn.Dropout(0.1)\n        self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n        layer_cnn = []\n        for var_size in var_size_cnn:\n            layer = torch.nn.Sequential(\n                torch.nn.Conv1d(var_dim_feature, var_dim_feature, var_size, padding=\"same\"),\n                torch.nn.BatchNorm1d(var_dim_feature),\n                torch.nn.Dropout(0.1),\n                torch.nn.LeakyReLU()\n            )\n            layer_cnn.append(layer)\n        self.layer_cnn = torch.nn.ModuleList(layer_cnn)\n        self.layer_dropout_1 = torch.nn.Dropout(0.1)\n\n    def forward(self, var_input):\n        var_t = var_input\n        var_t = self.layer_norm_0(var_t)\n        var_t, _ = self.layer_attention(var_t, var_t, var_t)\n        var_t = self.layer_dropout_0(var_t)\n        var_t = var_t + var_input\n        var_s = self.layer_norm_1(var_t)\n        var_s = torch.permute(var_s, (0, 2, 1))\n        var_c = torch.stack([layer(var_s) for layer in self.layer_cnn], dim=0)\n        var_s = torch.sum(var_c, dim=0) / len(self.layer_cnn)\n        var_s = self.layer_dropout_1(var_s)\n        var_s = torch.permute(var_s, (0, 2, 1))\n        var_output = var_s + var_t\n        return var_output\n\nclass THAT(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(THAT, self).__init__()\n        var_dim_feature = var_x_shape[-1]\n        var_dim_time = var_x_shape[-2]\n        var_dim_output = var_y_shape[-1]\n        # Left branch\n        self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n        var_num_left = 4\n        var_dim_left = var_dim_feature\n        self.layer_left_encoder = torch.nn.ModuleList([\n            Encoder(var_dim_feature=var_dim_left, var_num_head=10, var_size_cnn=[1, 3, 5])\n            for _ in range(var_num_left)\n        ])\n        self.layer_left_norm = torch.nn.LayerNorm(var_dim_left, eps=1e-6)\n        self.layer_left_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=8)\n        self.layer_left_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=16)\n        self.layer_left_dropout = torch.nn.Dropout(0.5)\n        # Right branch\n        self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        var_num_right = 1\n        var_dim_right = var_dim_time // 20\n        self.layer_right_encoder = torch.nn.ModuleList([\n            Encoder(var_dim_feature=var_dim_right, var_num_head=10, var_size_cnn=[1, 2, 3])\n            for _ in range(var_num_right)\n        ])\n        self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n        self.layer_right_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=2)\n        self.layer_right_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=4)\n        self.layer_right_dropout = torch.nn.Dropout(0.5)\n        self.layer_leakyrelu = torch.nn.LeakyReLU()\n        self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n\n    def forward(self, var_input):\n        var_t = var_input  # shape: (batch_size, time_steps, features)\n        # Left branch\n        var_left = torch.permute(var_t, (0, 2, 1))\n        var_left = self.layer_left_pooling(var_left)\n        var_left = torch.permute(var_left, (0, 2, 1))\n        var_left = self.layer_left_gaussian(var_left)\n        for layer in self.layer_left_encoder:\n            var_left = layer(var_left)\n        var_left = self.layer_left_norm(var_left)\n        var_left = torch.permute(var_left, (0, 2, 1))\n        var_left_0 = self.layer_leakyrelu(self.layer_left_cnn_0(var_left))\n        var_left_1 = self.layer_leakyrelu(self.layer_left_cnn_1(var_left))\n        var_left_0 = torch.sum(var_left_0, dim=-1)\n        var_left_1 = torch.sum(var_left_1, dim=-1)\n        var_left = torch.concat([var_left_0, var_left_1], dim=-1)\n        var_left = self.layer_left_dropout(var_left)\n        # Right branch\n        var_right = torch.permute(var_t, (0, 2, 1))\n        var_right = self.layer_right_pooling(var_right)\n        for layer in self.layer_right_encoder:\n            var_right = layer(var_right)\n        var_right = self.layer_right_norm(var_right)\n        var_right = torch.permute(var_right, (0, 2, 1))\n        var_right_0 = self.layer_leakyrelu(self.layer_right_cnn_0(var_right))\n        var_right_1 = self.layer_leakyrelu(self.layer_right_cnn_1(var_right))\n        var_right_0 = torch.sum(var_right_0, dim=-1)\n        var_right_1 = torch.sum(var_right_1, dim=-1)\n        var_right = torch.concat([var_right_0, var_right_1], dim=-1)\n        var_right = self.layer_right_dropout(var_right)\n        # Concatenate branches\n        var_t = torch.concat([var_left, var_right], dim=-1)\n        var_output = self.layer_output(var_t)\n        return var_output\n\ndef run_that(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n    \"\"\"\n    Run WiFi-based model THAT.\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    data_train_x = data_train_x.reshape(data_train_x.shape[0], data_train_x.shape[1], -1)\n    data_test_x = data_test_x.reshape(data_test_x.shape[0], data_test_x.shape[1], -1)\n    var_x_shape, var_y_shape = data_train_x[0].shape, data_train_y[0].reshape(-1).shape\n    data_train_set = TensorDataset(torch.from_numpy(data_train_x), torch.from_numpy(data_train_y))\n    data_test_set = TensorDataset(torch.from_numpy(data_test_x), torch.from_numpy(data_test_y))\n    \n    result = {}\n    result_accuracy = []\n    result_time_train = []\n    result_time_test = []\n    \n    # var_macs, var_params = get_model_complexity_info(THAT(var_x_shape, var_y_shape), var_x_shape, as_strings=False)\n    # print(\"Parameters:\", var_params, \"- FLOPs:\", var_macs * 2)\n    \n    for var_r in range(var_repeat):\n        print(\"Repeat\", var_r)\n        torch.random.manual_seed(var_r + 39)\n        if init_model is not None:\n            model_that = init_model\n            lr2 = preset[\"nn\"][\"lr\"] /10\n        else:\n            model_that = THAT(var_x_shape, var_y_shape).to(device)\n            lr2 = preset[\"nn\"][\"lr\"]\n\n        optimizer = torch.optim.Adam(model_that.parameters(), lr=lr2, weight_decay=0)\n        loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4] * var_y_shape[-1]).to(device))\n        var_time_0 = time.time()\n        \n        # Train\n        var_best_weight = train(model=model_that, optimizer=optimizer, loss=loss, \n                                  data_train_set=data_train_set, data_test_set=data_test_set,\n                                  var_threshold=preset[\"nn\"][\"threshold\"],\n                                  var_batch_size=preset[\"nn\"][\"batch_size\"],\n                                  var_epochs=preset[\"nn\"][\"epoch\"],\n                                  device=device)\n        var_time_1 = time.time()\n        \n        # Test\n        model_that.load_state_dict(var_best_weight)\n        with torch.no_grad():\n            predict_test_y = model_that(torch.from_numpy(data_test_x).to(device))\n        predict_test_y = (torch.sigmoid(predict_test_y) > preset[\"nn\"][\"threshold\"]).float()\n        predict_test_y = predict_test_y.detach().cpu().numpy()\n        var_time_2 = time.time()\n        \n        # Evaluate\n        data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n        predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n        result_acc = accuracy_score(data_test_y_c.astype(int), predict_test_y_c.astype(int))\n        result_dict = classification_report(data_test_y_c, predict_test_y_c, digits=6, zero_division=0, output_dict=True)\n        result[\"repeat_\" + str(var_r)] = result_dict\n        result_accuracy.append(result_acc)\n        result_time_train.append(var_time_1 - var_time_0)\n        result_time_test.append(var_time_2 - var_time_1)\n        print(\"repeat_\" + str(var_r), result_accuracy)\n        print(result)\n    \n    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n    # result[\"complexity\"] = {\"parameter\": var_params, \"flops\": var_macs * 2}\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:10:28.801413Z","iopub.execute_input":"2025-12-13T16:10:28.802093Z","iopub.status.idle":"2025-12-13T16:10:28.827923Z","shell.execute_reply.started":"2025-12-13T16:10:28.802069Z","shell.execute_reply":"2025-12-13T16:10:28.827319Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell7: for RESNET18 Model\n---\n---","metadata":{}},{"cell_type":"code","source":"# import os\n# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\n# import torch._dynamo\n# torch._dynamo.config.suppress_errors = True\n# import time\n# import torch\n# torch.cuda.empty_cache()\n# import numpy as np\n# from torch.utils.data import TensorDataset, DataLoader\n# from sklearn.metrics import accuracy_score, classification_report\n# import torchvision.models as models\n# from copy import deepcopy\n\n# torch.set_float32_matmul_precision(\"high\")\n# torch._dynamo.config.cache_size_limit = 65536\n\n# # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… preset Ù‚Ø¨Ù„Ø§Ù‹ ØªØ¹Ø±ÛŒÙ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ù‡\n# # preset = { \"nn\": {\"lr\": 1e-3, \"epoch\": 10, \"batch_size\": 4, \"threshold\": 0.5}, ... }\n\n# class ResNet18Model(torch.nn.Module):\n#     def __init__(self, var_x_shape, var_y_shape):\n#         super(ResNet18Model, self).__init__()\n#         model_resnet = models.resnet18(weights=None)\n#         model_resnet.conv1 = torch.nn.Conv2d(1, 64, 7, 3, 2, bias=False)\n#         in_features_fc = model_resnet.fc.in_features  # Ù…Ø¹Ù…ÙˆÙ„Ø§Ù‹ 512\n#         out_features_fc = var_y_shape[-1]\n#         model_resnet.fc = torch.nn.Linear(in_features_fc, out_features_fc)\n#         self.resnet = model_resnet\n\n#     def forward(self, var_input):\n#         var_input = var_input.reshape(var_input.size(0), 1, 3000, 270)\n#         return self.resnet(var_input)\n\n# def run_resnet(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10, init_model=None):\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     var_x_shape = data_train_x[0].shape\n#     var_y_shape = data_train_y[0].reshape(-1).shape\n\n#     # ØªØºÛŒÛŒØ± Ø´Ú©Ù„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø±ÙˆÛŒ CPU\n#     data_train_x = data_train_x.reshape(data_train_x.shape[0], 1, data_train_x.shape[1],\n#                                         data_train_x.shape[2]*data_train_x.shape[3]*data_train_x.shape[4])\n#     data_test_x  = data_test_x.reshape(data_test_x.shape[0], 1, data_test_x.shape[1],\n#                                        data_test_x.shape[2]*data_test_x.shape[3]*data_test_x.shape[4])\n    \n#     # Ø¯ÛŒØªØ§Ø³Øªâ€ŒÙ‡Ø§ Ø±ÙˆÛŒ CPU\n#     data_train_set = TensorDataset(torch.from_numpy(data_train_x).float(),\n#                                    torch.from_numpy(data_train_y).float())\n#     data_test_set  = TensorDataset(torch.from_numpy(data_test_x).float(),\n#                                    torch.from_numpy(data_test_y).float())\n    \n#     result = {}\n#     result_accuracy = []\n#     result_time_train = []\n#     result_time_test = []\n    \n#     for var_r in range(var_repeat):\n#         print(\"Repeat\", var_r)\n#         torch.random.manual_seed(var_r + 39)\n        \n#         # Ø³Ø§Ø®Øª Ù…Ø¯Ù„ Ùˆ Ø§Ù†ØªÙ‚Ø§Ù„ Ø¨Ù‡ GPU\n#         if init_model is not None:\n#             model_resnet = init_model\n#             lr2 = preset[\"nn\"][\"lr\"] /10\n            \n#         else:\n#             model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n#             lr2 = preset[\"nn\"][\"lr\"]\n\n#         optimizer = torch.optim.Adam(model_resnet.parameters(), lr=lr2, weight_decay=0)\n#         loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6] * var_y_shape[-1]).to(device))\n        \n#         # ØªØ§Ø¨Ø¹ Ø¢Ù…ÙˆØ²Ø´ Ø¯Ø§Ø®Ù„ÛŒØ› Ø¯ÛŒØªØ§ Ø±ÙˆÛŒ CPU Ø¨Ø§Ù‚ÛŒ Ù…ÛŒâ€ŒÙ…ÙˆÙ†Ù‡ Ùˆ ÙÙ‚Ø· Ù‡Ù†Ú¯Ø§Ù… Ù…Ø­Ø§Ø³Ø¨Ù‡ batch Ø¨Ù‡ GPU Ù…ÛŒØ±Ù‡\n#         def train_inner():\n#             train_loader = DataLoader(data_train_set, preset[\"nn\"][\"batch_size\"], shuffle=True, pin_memory=False)\n#             test_loader = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n#             best_accuracy = 0\n#             best_weight = None\n            \n#             for epoch in range(preset[\"nn\"][\"epoch\"]):\n#                 t0 = time.time()\n#                 model_resnet.train()\n#                 # Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø¢Ø®Ø±ÛŒÙ† batch Ø¢Ù…ÙˆØ²Ø´\n#                 last_train_loss = None\n#                 last_train_acc = None\n#                 for batch in train_loader:\n#                     batch_x, batch_y = batch\n#                     batch_x = batch_x.to(device)\n#                     batch_y = batch_y.to(device)\n#                     outputs = model_resnet(batch_x)\n#                     loss_val = loss_func(outputs, batch_y.reshape(batch_y.shape[0], -1).float())\n#                     optimizer.zero_grad()\n#                     loss_val.backward()\n#                     optimizer.step()\n#                     last_train_loss = loss_val.item()\n#                     # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚Øª Ø¢Ø®Ø±ÛŒÙ† batch Ø¢Ù…ÙˆØ²Ø´\n#                     train_preds = (torch.sigmoid(outputs) > preset[\"nn\"][\"threshold\"]).float()\n#                     last_train_acc = accuracy_score(batch_y.reshape(batch_y.shape[0], -1).detach().cpu().numpy().astype(int),\n#                                                     train_preds.detach().cpu().numpy().astype(int))\n                \n#                 # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª ØªØ³Øª Ø¨Ù‡ ØµÙˆØ±Øª batch Ø¨Ù‡ batch\n#                 model_resnet.eval()\n#                 all_preds = []\n#                 all_labels = []\n#                 test_loss_val = None\n#                 with torch.no_grad():\n#                     for t_batch in test_loader:\n#                         t_x, t_y = t_batch\n#                         t_x = t_x.to(device)\n#                         outputs_test = model_resnet(t_x)\n#                         outputs_test = (torch.sigmoid(outputs_test) > preset[\"nn\"][\"threshold\"]).float()\n#                         all_preds.append(outputs_test.detach().cpu().numpy())\n#                         all_labels.append(t_y.cpu().numpy())  # Ø§ÛŒÙ†Ø¬Ø§ ØªØºÛŒÛŒØ± Ø¯Ø§Ø¯ÛŒÙ…\n#                 preds_cat = np.vstack(all_preds)\n#                 labels_cat = np.vstack(all_labels)\n#                 print(\"preds_cat\",preds_cat.shape)\n#                 # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø´Ú©Ù„ (n, 6, 5)\n                \n#                 # preds_cat = preds_cat.reshape(-1, 6, 5)\n#                 # labels_cat = labels_cat.reshape(-1, 6, 5)\n\n#                 preds_cat = preds_cat.reshape(-1, 6)\n#                 labels_cat = labels_cat.reshape(-1, 6)\n                \n#                 # Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚ØªØŒ Ù…Ø³Ø·Ø­ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…\n#                 test_acc = accuracy_score(labels_cat.reshape(labels_cat.shape[0], -1).astype(int),\n#                                           preds_cat.reshape(preds_cat.shape[0], -1).astype(int))\n#                 epoch_time = time.time() - t0\n#                 print(f\"Epoch {epoch}/{preset['nn']['epoch']} - \"\n#                       f\"Train Loss: {(last_train_loss if last_train_loss is not None else 0.0):.6f}, \"\n#                       f\"Train Acc: {(last_train_acc if last_train_acc is not None else 0.0):.6f}, \"\n#                       f\"Test Loss: {(test_loss_val if test_loss_val is not None else 0.0):.6f}, \"\n#                       f\"Test Acc: {(test_acc if test_acc is not None else 0.0):.6f} - \"\n#                       f\"Time: {epoch_time:.4f}s\")\n\n#                 if test_acc > best_accuracy:\n#                     best_accuracy = test_acc\n#                     print('-----***-----')\n#                     print(best_accuracy)\n#                     best_weight = deepcopy(model_resnet.state_dict())\n#             return best_weight\n        \n#         t0_run = time.time()\n#         best_weight = train_inner()\n#         t1_run = time.time()\n        \n#         torch.save(model_resnet.state_dict(), f\"{name_run}_model_final.pt\")\n#         model_resnet.load_state_dict(best_weight)\n#         torch.save(model_resnet.state_dict(), f\"{name_run}_best_model.pt\")\n\n#         # bad age niaz bod load koni\n#         # model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n#         # model_resnet.load_state_dict(torch.load(\"resnet_model_repeat0.pt\"))\n#         # model_resnet.eval()\n\n        \n#         # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„ Ø±ÙˆÛŒ Ø¯ÛŒØªØ§Ø³Øª ØªØ³Øª (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² batchÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©)\n#         model_resnet.eval()\n#         all_preds = []\n#         test_loader_final = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n#         with torch.no_grad():\n#             for batch in test_loader_final:\n#                 batch_x, _ = batch\n#                 batch_x = batch_x.to(device)\n#                 all_preds.append(model_resnet(batch_x))\n#         preds_all = torch.cat(all_preds, dim=0)\n#         preds_final = (torch.sigmoid(preds_all) > preset[\"nn\"][\"threshold\"]).float().detach().cpu().numpy()\n#         t2_run = time.time()\n        \n#         data_test_y_np = data_test_y.reshape(-1, data_test_y.shape[-1])\n#         preds_final = preds_final.reshape(-1, data_test_y.shape[-1])\n#         acc_final = accuracy_score(data_test_y_np.astype(int), preds_final.astype(int))\n#         result[f\"repeat_{var_r}\"] = {\"accuracy\": acc_final}\n#         result_accuracy.append(acc_final)\n#         result_time_train.append(t1_run - t0_run)\n#         result_time_test.append(t2_run - t1_run)\n#         print(\"Repeat\", var_r, \"Final Test Accuracy:\", acc_final)\n    \n#     result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n#     result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n#     result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n#     return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:10:44.327575Z","iopub.execute_input":"2025-12-13T16:10:44.327851Z","iopub.status.idle":"2025-12-13T16:10:44.336489Z","shell.execute_reply.started":"2025-12-13T16:10:44.327829Z","shell.execute_reply":"2025-12-13T16:10:44.335725Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"---\nCell 9: train.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          train.py\n[description]   function to train WiFi-based models\n\"\"\"\n\n# All necessary libraries are imported in Cell 1.\n\ntorch.set_float32_matmul_precision(\"high\")\ntorch._dynamo.config.cache_size_limit = 65536\n\ndef train(model, optimizer, loss, data_train_set, data_test_set, var_threshold, var_batch_size, var_epochs, device):\n    \"\"\"\n    Generic training function for WiFi-based models.\n    \"\"\"\n    # Ø¯ÛŒØªØ§ Ø±Ùˆ Ø±ÙˆÛŒ CPU Ù†Ú¯Ù‡ Ù…ÛŒâ€ŒØ¯Ø§Ø±ÛŒÙ… (pin_memory=False)\n    data_train_loader = DataLoader(data_train_set, var_batch_size, shuffle=True, pin_memory=False)\n    data_test_loader = DataLoader(data_test_set, batch_size=len(data_test_set), shuffle=False, pin_memory=False)\n    \n    var_best_accuracy = -1.0\n    var_best_weight   = deepcopy(model.state_dict())\n    \n    \n    for var_epoch in range(var_epochs):\n        var_time_e0 = time.time()\n        model.train()\n        for data_batch in data_train_loader:\n            data_batch_x, data_batch_y = data_batch\n            # Ø§Ù†ØªÙ‚Ø§Ù„ Ù…ÙˆÙ‚ØªÛŒ Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ GPU ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ forward pass\n            data_batch_x = data_batch_x.to(device)\n            data_batch_y = data_batch_y.to(device)\n            predict_train_y = model(data_batch_x)\n            var_loss_train = loss(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n            optimizer.zero_grad()\n            var_loss_train.backward()\n            optimizer.step()\n        \n        # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¯Ù‚Øª Ø±ÙˆÛŒ Ø¢Ø®Ø±ÛŒÙ† batch Ùˆ Ø§Ù†ØªÙ‚Ø§Ù„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ CPU\n        predict_train_y = (torch.sigmoid(predict_train_y) > var_threshold).float()\n        data_batch_y = data_batch_y.detach().cpu().numpy()\n        predict_train_y = predict_train_y.detach().cpu().numpy()\n        \n        predict_train_y = predict_train_y.reshape(-1, data_batch_y.shape[-1])\n        data_batch_y = data_batch_y.reshape(-1, data_batch_y.shape[-1])\n        var_accuracy_train = accuracy_score(data_batch_y.astype(int), predict_train_y.astype(int))\n        \n        model.eval()\n        with torch.no_grad():\n            data_test_x, data_test_y = next(iter(data_test_loader))\n            # Ø§Ù†ØªÙ‚Ø§Ù„ Ù…ÙˆÙ‚ØªÛŒ Ø¯ÛŒØªØ§ ØªØ³Øª Ø¨Ù‡ GPU Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§Øª\n            data_test_x = data_test_x.to(device)\n            data_test_y = data_test_y.to(device)\n            \n            predict_test_y = model(data_test_x)\n            var_loss_test = loss(predict_test_y, data_test_y.reshape(data_test_y.shape[0], -1).float())\n            \n            predict_test_y = (torch.sigmoid(predict_test_y) > var_threshold).float()\n            \n            # Ø§Ù†ØªÙ‚Ø§Ù„ Ù†ØªØ§ÛŒØ¬ Ø¨Ù‡ CPU Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ\n            data_test_y = data_test_y.detach().cpu().numpy()\n            predict_test_y = predict_test_y.detach().cpu().numpy()\n            \n            predict_test_y = predict_test_y.reshape(-1, data_test_y.shape[-1])\n            data_test_y = data_test_y.reshape(-1, data_test_y.shape[-1])\n            var_accuracy_test = accuracy_score(data_test_y.astype(int), predict_test_y.astype(int))\n        \n        print(f\"Epoch {var_epoch}/{var_epochs}\",\n              \"- %.6fs\"%(time.time() - var_time_e0),\n              \"- Loss %.6f\"%var_loss_train.cpu(),\n              \"- Accuracy %.6f\"%var_accuracy_train,\n              \"- Test Loss %.6f\"%var_loss_test.cpu(),\n              \"- Test Accuracy %.6f\"%var_accuracy_test)\n            \n        if var_accuracy_test > var_best_accuracy:\n            var_best_accuracy = var_accuracy_test\n            print('-----***-----')\n            print(var_best_accuracy)\n            var_best_weight = deepcopy(model.state_dict())\n\n    torch.save(model.state_dict(), f\"{name_run}_model_final.pt\")\n    torch.save(var_best_weight, f\"{name_run}_best_model.pt\")\n\n    \n    return var_best_weight\n\n\n\n# === importsÙ Ù„Ø§Ø²Ù… Ø±Ø§ ÛŒÚ©â€ŒØ¨Ø§Ø± Ø¨Ø§Ù„Ø§ÛŒ ÙØ§ÛŒÙ„ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù† ===\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport matplotlib.pyplot as plt\n\n# ---------- ØªØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ----------\ndef save_confusion_matrix(model, data_loader, threshold, device, pdf_path):\n    \"\"\"\n    Runs the model on `data_loader`, builds a confusion matrix and writes it to `pdf_path`.\n    \"\"\"\n    model.eval()\n    y_true, y_pred = [], []\n\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n\n            preds = (torch.sigmoid(logits) > threshold).float().cpu().numpy().ravel()\n            yb    = yb.cpu().numpy().ravel()\n\n            y_true.extend(yb)\n            y_pred.extend(preds)\n\n    cm  = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots()\n    ConfusionMatrixDisplay(cm).plot(ax=ax)\n    ax.set_title(\"Confusion Matrix â€“ Test\")\n\n    with PdfPages(pdf_path) as pdf:\n        pdf.savefig(fig)\n    plt.close(fig)\n# ---------------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:10:47.685195Z","iopub.execute_input":"2025-12-13T16:10:47.685509Z","iopub.status.idle":"2025-12-13T16:10:48.219145Z","shell.execute_reply.started":"2025-12-13T16:10:47.685489Z","shell.execute_reply":"2025-12-13T16:10:48.218616Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"---\nCell 11: run.py\n---\n---","metadata":{}},{"cell_type":"code","source":"import gc\nimport torch\ngc.collect()           \ntorch.cuda.empty_cache()  \ntorch.cuda.ipc_collect()  \n\n\n\n\n\"\"\"\n[file]          run.py\n[description]   run WiFi-based models and optionally save a multiclass confusion matrix\n\"\"\"\n\nimport argparse\nimport json\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib.backends.backend_pdf import PdfPages\n\n# from preset import preset, name_run\n# from load_data import load_data_x, load_data_y, encode_data_y\n# from lstm import run_lstm, LSTMM\n# from bilstm import run_bilstm, BiLSTMM\n# from that import run_that, THAT\n# from resnet import run_resnet, ResNet18Model\n# from strf import run_strf  # if you have the ST-RF implementation\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\",   default=preset[\"model\"],  type=str)\n    parser.add_argument(\"--task\",    default=preset[\"task\"],   type=str)\n    parser.add_argument(\"--repeat\",  default=preset[\"repeat\"], type=int)\n    parser.add_argument(\"--save_cm\", action=\"store_true\",\n                        help=\"Save a multiclass confusion matrix of the best model to PDF\")\n    args, _ = parser.parse_known_args()\n    return args\n\ndef save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes):\n    \"\"\"\n    Given a model that outputs one-hot logits for a multiclass task,\n    convert to predicted classes via argmax, then plot and save a\n    num_classes Ã— num_classes confusion matrix to pdf_path.\n    \"\"\"\n    model.eval()\n    y_true = []\n    y_pred = []\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n            # predicted class is index of max logit\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            trues = torch.argmax(yb, dim=1).cpu().numpy()\n            y_pred.extend(preds.tolist())\n            y_true.extend(trues.tolist())\n\n    labels = list(range(num_classes))\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    disp.plot(ax=ax, xticks_rotation=\"vertical\")\n    ax.set_title(\"Confusion Matrix\")\n    with PdfPages(pdf_path) as pdf:\n        pdf.savefig(fig)\n    plt.close(fig)\n\ndef run():\n    args       = parse_args()\n    var_model  = args.model\n    var_task   = args.task\n    var_repeat = args.repeat\n\n    # --- Load and encode the data ---\n    data_pd_y = load_data_y(\n        preset[\"path\"][\"data_y\"],\n        var_environment=preset[\"data\"][\"environment\"],\n        var_wifi_band=preset[\"data\"][\"wifi_band\"],\n        var_num_users=preset[\"data\"][\"num_users\"]\n    )\n    labels = data_pd_y[\"label\"].tolist()\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], labels)\n    data_y = encode_data_y(data_pd_y, var_task)\n\n    train_x, test_x, train_y, test_y = train_test_split(\n        data_x, data_y, test_size=0.2, shuffle=True, random_state=39\n    )\n\n    # --- Select which model runner to use ---\n    if var_model == \"ST-RF\":\n        from strf import run_strf\n        run_model = run_strf\n    elif var_model == \"LSTM\":\n        run_model = run_lstm\n    elif var_model == \"bi-LSTM\":\n        run_model = run_bilstm\n    elif var_model == \"THAT\":\n        run_model = run_that\n    elif var_model == \"ResNet18\":\n        run_model = run_resnet\n    else:\n        raise ValueError(f\"Unknown model: {var_model}\")\n\n    # --- Train and evaluate ---\n    print(f\"Running model: {var_model}\")\n    result = run_model(train_x, train_y, test_x, test_y, var_repeat)\n    result[\"model\"] = var_model\n    result[\"task\"]  = var_task\n    result[\"data\"]  = preset[\"data\"]\n    result[\"nn\"]    = preset[\"nn\"]\n    print(result)\n\n    # --- Save results to JSON ---\n    with open(preset[\"path\"][\"save\"], \"w\") as f:\n        json.dump(result, f, indent=4)\n\n    # --- Optionally save a multiclass confusion matrix ---\n    # if args.save_cm:\n    if Confusion_matrix == 1:\n        # 1) completely release GPU memory used for training\n        del run_model                      # if 'model' from training is still in scope\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n    \n        # 2) reshape input only if the network is sequenceâ€‘based\n        if var_model in (\"LSTM\", \"bi-LSTM\", \"THAT\"):\n            test_x_cm = test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n        else:                           # ResNet18, STâ€‘RF\n            test_x_cm = test_x\n    \n        # 3) build the *same* architecture on CPU and load its weights\n        device_cm = torch.device(\"cpu\")\n        if var_model == \"LSTM\":\n            model_cm = LSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"bi-LSTM\":\n            model_cm = BiLSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"THAT\":\n            model_cm = THAT(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"ResNet18\":\n            model_cm = ResNet18Model(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        else:\n            raise ValueError(f\"Confusion matrix not supported for {var_model}\")\n    \n        best_path = f\"/kaggle/working/{name_run}_best_model.pt\"\n        model_cm.load_state_dict(torch.load(best_path, map_location=device_cm))\n        model_cm.eval()\n    \n        # 4) DataLoader on CPU with a safe batch size\n        test_ds = TensorDataset(torch.from_numpy(test_x_cm).float(),\n                                torch.from_numpy(test_y).float())\n        test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n    \n        # 5) save the confusion matrix PDF\n        num_classes = test_y.shape[1]\n        pdf_name = f\"{name_run}_confusion_matrix.pdf\"\n        save_multiclass_confusion_matrix(model_cm,test_loader,device_cm,pdf_name,num_classes)\n        print(f\"âœ… Saved confusion matrix (classes 0â€“{num_classes-1}) to {pdf_name}\")\nif __name__ == \"__main__\":\n    print(\"start\")\n    run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-13T16:10:53.196178Z","iopub.execute_input":"2025-12-13T16:10:53.196647Z"}},"outputs":[{"name":"stdout","text":"start\nRunning model: THAT\nRepeat 0\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py:370: UserWarning: Using padding='same' with even kernel lengths and odd dilation may require a zero-padded copy of the input be created (Triggered internally at ../aten/src/ATen/native/Convolution.cpp:1036.)\n  return F.conv1d(\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0/100 - 6.205999s - Loss 2.374682 - Accuracy 0.098958 - Test Loss 1.242724 - Test Accuracy 0.320513\n-----***-----\n0.32051282051282054\nEpoch 1/100 - 5.020604s - Loss 0.897016 - Accuracy 0.270833 - Test Loss 0.684795 - Test Accuracy 0.556145\n-----***-----\n0.5561450044208665\nEpoch 2/100 - 5.035375s - Loss 0.823703 - Accuracy 0.312500 - Test Loss 0.580699 - Test Accuracy 0.547303\nEpoch 3/100 - 5.017757s - Loss 0.637039 - Accuracy 0.328125 - Test Loss 0.568325 - Test Accuracy 0.513263\nEpoch 4/100 - 5.075988s - Loss 0.651615 - Accuracy 0.411458 - Test Loss 0.515813 - Test Accuracy 0.545535\nEpoch 5/100 - 5.022692s - Loss 0.611124 - Accuracy 0.401042 - Test Loss 0.541409 - Test Accuracy 0.558798\n-----***-----\n0.5587975243147657\nEpoch 6/100 - 5.028437s - Loss 0.541251 - Accuracy 0.390625 - Test Loss 0.510128 - Test Accuracy 0.529620\nEpoch 7/100 - 5.006376s - Loss 0.581135 - Accuracy 0.442708 - Test Loss 0.498790 - Test Accuracy 0.550398\nEpoch 8/100 - 5.025301s - Loss 0.630980 - Accuracy 0.364583 - Test Loss 0.519903 - Test Accuracy 0.541998\nEpoch 9/100 - 5.046513s - Loss 0.534138 - Accuracy 0.505208 - Test Loss 0.502916 - Test Accuracy 0.541998\nEpoch 10/100 - 5.022166s - Loss 0.527053 - Accuracy 0.442708 - Test Loss 0.472808 - Test Accuracy 0.551724\nEpoch 11/100 - 5.017740s - Loss 0.463127 - Accuracy 0.531250 - Test Loss 0.481560 - Test Accuracy 0.568081\n-----***-----\n0.5680813439434129\nEpoch 12/100 - 5.030876s - Loss 0.570379 - Accuracy 0.328125 - Test Loss 0.454357 - Test Accuracy 0.551724\nEpoch 13/100 - 5.031576s - Loss 0.427664 - Accuracy 0.500000 - Test Loss 0.473984 - Test Accuracy 0.561450\nEpoch 14/100 - 5.035207s - Loss 0.477848 - Accuracy 0.432292 - Test Loss 0.451407 - Test Accuracy 0.537135\nEpoch 15/100 - 5.014203s - Loss 0.494897 - Accuracy 0.453125 - Test Loss 0.450289 - Test Accuracy 0.565871\nEpoch 16/100 - 5.027651s - Loss 0.467896 - Accuracy 0.479167 - Test Loss 0.452740 - Test Accuracy 0.557471\nEpoch 17/100 - 5.026616s - Loss 0.467110 - Accuracy 0.437500 - Test Loss 0.437126 - Test Accuracy 0.569850\n-----***-----\n0.5698496905393458\nEpoch 18/100 - 5.034265s - Loss 0.453999 - Accuracy 0.437500 - Test Loss 0.434752 - Test Accuracy 0.542882\nEpoch 19/100 - 5.028192s - Loss 0.314960 - Accuracy 0.619792 - Test Loss 0.465591 - Test Accuracy 0.555703\nEpoch 20/100 - 5.038250s - Loss 0.451605 - Accuracy 0.411458 - Test Loss 0.458549 - Test Accuracy 0.561892\nEpoch 21/100 - 5.045064s - Loss 0.356008 - Accuracy 0.567708 - Test Loss 0.435684 - Test Accuracy 0.554377\nEpoch 22/100 - 5.023442s - Loss 0.339451 - Accuracy 0.567708 - Test Loss 0.452424 - Test Accuracy 0.569850\nEpoch 23/100 - 5.024418s - Loss 0.283195 - Accuracy 0.562500 - Test Loss 0.438423 - Test Accuracy 0.573386\n-----***-----\n0.5733863837312113\nEpoch 24/100 - 5.030883s - Loss 0.299763 - Accuracy 0.619792 - Test Loss 0.448339 - Test Accuracy 0.553492\nEpoch 25/100 - 5.031169s - Loss 0.338355 - Accuracy 0.510417 - Test Loss 0.450942 - Test Accuracy 0.561892\nEpoch 26/100 - 5.031585s - Loss 0.276489 - Accuracy 0.635417 - Test Loss 0.447215 - Test Accuracy 0.575155\n-----***-----\n0.5751547303271441\nEpoch 27/100 - 5.023490s - Loss 0.311454 - Accuracy 0.593750 - Test Loss 0.451043 - Test Accuracy 0.573828\nEpoch 28/100 - 5.018030s - Loss 0.278763 - Accuracy 0.619792 - Test Loss 0.462495 - Test Accuracy 0.555703\nEpoch 29/100 - 5.030777s - Loss 0.289659 - Accuracy 0.651042 - Test Loss 0.442164 - Test Accuracy 0.551282\nEpoch 30/100 - 5.044359s - Loss 0.262373 - Accuracy 0.656250 - Test Loss 0.489599 - Test Accuracy 0.573828\nEpoch 31/100 - 5.035066s - Loss 0.230755 - Accuracy 0.645833 - Test Loss 0.493242 - Test Accuracy 0.567197\nEpoch 32/100 - 5.041919s - Loss 0.209556 - Accuracy 0.666667 - Test Loss 0.515824 - Test Accuracy 0.584881\n-----***-----\n0.5848806366047745\nEpoch 33/100 - 5.033938s - Loss 0.212003 - Accuracy 0.703125 - Test Loss 0.488178 - Test Accuracy 0.557471\nEpoch 34/100 - 5.040424s - Loss 0.225691 - Accuracy 0.609375 - Test Loss 0.490356 - Test Accuracy 0.571618\nEpoch 35/100 - 5.021813s - Loss 0.228450 - Accuracy 0.651042 - Test Loss 0.486279 - Test Accuracy 0.573386\nEpoch 36/100 - 5.027442s - Loss 0.187498 - Accuracy 0.687500 - Test Loss 0.524564 - Test Accuracy 0.572060\nEpoch 37/100 - 5.020258s - Loss 0.227551 - Accuracy 0.671875 - Test Loss 0.494145 - Test Accuracy 0.569850\nEpoch 38/100 - 5.036392s - Loss 0.189106 - Accuracy 0.729167 - Test Loss 0.535560 - Test Accuracy 0.583112\nEpoch 39/100 - 5.013774s - Loss 0.146230 - Accuracy 0.755208 - Test Loss 0.512278 - Test Accuracy 0.573828\nEpoch 40/100 - 5.039262s - Loss 0.189732 - Accuracy 0.713542 - Test Loss 0.550111 - Test Accuracy 0.580902\nEpoch 41/100 - 5.018107s - Loss 0.160585 - Accuracy 0.703125 - Test Loss 0.568510 - Test Accuracy 0.576923\nEpoch 42/100 - 5.032544s - Loss 0.170716 - Accuracy 0.713542 - Test Loss 0.555083 - Test Accuracy 0.589302\n-----***-----\n0.5893015030946065\nEpoch 43/100 - 5.024489s - Loss 0.136899 - Accuracy 0.791667 - Test Loss 0.590142 - Test Accuracy 0.586207\nEpoch 44/100 - 5.045365s - Loss 0.129841 - Accuracy 0.786458 - Test Loss 0.600685 - Test Accuracy 0.595049\n-----***-----\n0.5950486295313882\nEpoch 45/100 - 5.029992s - Loss 0.117957 - Accuracy 0.812500 - Test Loss 0.624399 - Test Accuracy 0.590186\nEpoch 46/100 - 5.025101s - Loss 0.159752 - Accuracy 0.723958 - Test Loss 0.687688 - Test Accuracy 0.586649\nEpoch 47/100 - 5.020306s - Loss 0.186757 - Accuracy 0.718750 - Test Loss 0.608890 - Test Accuracy 0.576039\nEpoch 48/100 - 5.022146s - Loss 0.144940 - Accuracy 0.755208 - Test Loss 0.740087 - Test Accuracy 0.584439\nEpoch 49/100 - 5.029800s - Loss 0.179922 - Accuracy 0.750000 - Test Loss 0.668224 - Test Accuracy 0.594607\nEpoch 50/100 - 5.026471s - Loss 0.143921 - Accuracy 0.692708 - Test Loss 0.713505 - Test Accuracy 0.586649\nEpoch 51/100 - 5.029834s - Loss 0.140724 - Accuracy 0.734375 - Test Loss 0.712290 - Test Accuracy 0.594607\nEpoch 52/100 - 5.048860s - Loss 0.119009 - Accuracy 0.765625 - Test Loss 0.681713 - Test Accuracy 0.591512\nEpoch 53/100 - 5.032181s - Loss 0.117101 - Accuracy 0.734375 - Test Loss 0.710844 - Test Accuracy 0.589302\nEpoch 54/100 - 5.037016s - Loss 0.110992 - Accuracy 0.791667 - Test Loss 0.741444 - Test Accuracy 0.588859\nEpoch 55/100 - 5.033157s - Loss 0.121172 - Accuracy 0.765625 - Test Loss 0.780892 - Test Accuracy 0.597259\n-----***-----\n0.5972590627763041\nEpoch 56/100 - 5.040116s - Loss 0.165394 - Accuracy 0.760417 - Test Loss 0.718993 - Test Accuracy 0.594607\nEpoch 57/100 - 5.025636s - Loss 0.159802 - Accuracy 0.781250 - Test Loss 0.783120 - Test Accuracy 0.593280\nEpoch 58/100 - 5.032208s - Loss 0.116398 - Accuracy 0.817708 - Test Loss 0.836298 - Test Accuracy 0.595933\nEpoch 59/100 - 5.021958s - Loss 0.087072 - Accuracy 0.807292 - Test Loss 0.764749 - Test Accuracy 0.589744\nEpoch 60/100 - 5.027847s - Loss 0.070856 - Accuracy 0.848958 - Test Loss 0.746491 - Test Accuracy 0.585323\nEpoch 61/100 - 5.020520s - Loss 0.110805 - Accuracy 0.796875 - Test Loss 0.779808 - Test Accuracy 0.594164\nEpoch 62/100 - 5.034393s - Loss 0.077329 - Accuracy 0.848958 - Test Loss 0.854912 - Test Accuracy 0.590628\nEpoch 63/100 - 5.019734s - Loss 0.088511 - Accuracy 0.869792 - Test Loss 0.801671 - Test Accuracy 0.596375\nEpoch 64/100 - 5.032839s - Loss 0.110151 - Accuracy 0.765625 - Test Loss 0.788301 - Test Accuracy 0.594607\nEpoch 65/100 - 5.011108s - Loss 0.078110 - Accuracy 0.869792 - Test Loss 0.880916 - Test Accuracy 0.589302\nEpoch 66/100 - 5.021091s - Loss 0.085787 - Accuracy 0.890625 - Test Loss 0.969054 - Test Accuracy 0.590186\nEpoch 67/100 - 5.019890s - Loss 0.089986 - Accuracy 0.791667 - Test Loss 0.909911 - Test Accuracy 0.591512\nEpoch 68/100 - 5.031866s - Loss 0.103617 - Accuracy 0.817708 - Test Loss 0.871212 - Test Accuracy 0.598585\n-----***-----\n0.5985853227232537\nEpoch 69/100 - 5.024035s - Loss 0.077192 - Accuracy 0.838542 - Test Loss 0.949690 - Test Accuracy 0.591954\nEpoch 70/100 - 5.025212s - Loss 0.082597 - Accuracy 0.848958 - Test Loss 0.923525 - Test Accuracy 0.594607\nEpoch 71/100 - 5.025929s - Loss 0.067298 - Accuracy 0.875000 - Test Loss 0.996002 - Test Accuracy 0.601680\n-----***-----\n0.6016799292661361\nEpoch 72/100 - 5.028156s - Loss 0.091555 - Accuracy 0.817708 - Test Loss 1.000659 - Test Accuracy 0.593280\nEpoch 73/100 - 5.018327s - Loss 0.063964 - Accuracy 0.864583 - Test Loss 0.973084 - Test Accuracy 0.595049\n","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"---\nCell 12: Few-shot Learning\n---\n---","metadata":{}},{"cell_type":"code","source":"# import gc\n# import torch\n# import shutil\n# import json\n# from sklearn.model_selection import train_test_split\n# from torch.utils.data import DataLoader, TensorDataset\n# import matplotlib.pyplot as plt\n# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n# from matplotlib.backends.backend_pdf import PdfPages\n\n# gc.collect()           \n# torch.cuda.empty_cache()  \n# torch.cuda.ipc_collect()\n\n# # ---------- helper: save multiclass confusion matrix ------------------\n# def save_multiclass_confusion_matrix(model, data_loader, pdf_path, num_classes):\n#     \"\"\"\n#     Forwardâ€‘pass on CPU, collect predictions, and write an NÃ—N confusion matrix\n#     to a singleâ€‘page PDF (pdf_path).\n#     \"\"\"\n#     model.eval()\n#     y_true, y_pred = [], []\n#     with torch.no_grad():\n#         for xb, yb in data_loader:\n#             logits = model(xb.cpu())                       # ensure CPU\n#             preds  = torch.argmax(logits, dim=1).numpy()\n#             trues  = torch.argmax(yb, dim=1).numpy()\n#             y_pred.extend(preds.tolist())\n#             y_true.extend(trues.tolist())\n\n#     labels = list(range(num_classes))\n#     cm  = confusion_matrix(y_true, y_pred, labels=labels)\n#     disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n#     fig, ax = plt.subplots(figsize=(8, 8))\n#     disp.plot(ax=ax, xticks_rotation=\"vertical\")\n#     ax.set_title(\"Fewâ€‘shot Confusion Matrix\")\n#     with PdfPages(pdf_path) as pdf:\n#         pdf.savefig(fig)\n#     plt.close(fig)\n\n# # -------------------- pick run_* function ------------------------------\n# if preset[\"model\"] == \"ST-RF\":\n#     run_model = run_strf\n# elif preset[\"model\"] == \"LSTM\":\n#     run_model = run_lstm\n# elif preset[\"model\"] == \"bi-LSTM\":\n#     run_model = run_bilstm\n# elif preset[\"model\"] == \"THAT\":\n#     run_model = run_that\n# elif preset[\"model\"] == \"ResNet18\":\n#     run_model = run_resnet\n# else:\n#     raise ValueError(f\"No fewâ€‘shot implementation for {preset['model']}.\")\n\n# # ------------------------ load / split data ----------------------------\n# data_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n#                         var_environment=[dest_env],\n#                         var_wifi_band=preset[\"data\"][\"wifi_band\"],\n#                         var_num_users=preset[\"data\"][\"num_users\"])\n\n# labels_list = data_pd_y[\"label\"].tolist()\n# data_x = load_data_x(preset[\"path\"][\"data_x\"], labels_list)\n# data_y = encode_data_y(data_pd_y, preset[\"task\"])\n\n# train_x, test_x, train_y, test_y = train_test_split(\n#     data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n\n# # Few-shot sample size\n# train_x = train_x[:few_shot_num_samples]\n# train_y = train_y[:few_shot_num_samples]\n\n# # ----------------------- fewâ€‘shot training -----------------------------\n# original_epochs = preset[\"nn\"][\"epoch\"]\n# preset[\"nn\"][\"epoch\"] = few_shot_epochs\n\n# # Load the best model weights\n# best_model_path = f\"{name_run}_best_model.pt\"\n\n# # Initialize the model \n# if preset[\"model\"] == \"LSTM\":\n#     model = LSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n#     # print('train_y_[0].shape:', train_y[0].shape)\n#     # print('train_x_[0].shape:', train_x[0].reshape(train_x[0].shape[0], -1).shape)\n# elif preset[\"model\"] == \"bi-LSTM\":\n#     model = BiLSTMM(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n# elif preset[\"model\"] == \"THAT\":\n#     model = THAT(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n# elif preset[\"model\"] == \"ResNet18\":\n#     model = ResNet18Model(train_x[0].reshape(train_x[0].shape[0], -1).shape, train_y[0].shape)  # Replace with your model initialization\n# else:\n#     raise ValueError(f\"Model {preset['model']} not supported!\")\n\n# # Load the weights into the model\n# model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n# model = model.to('cuda')\n\n# # Fine-tune the model on few-shot data (note: `run_model` should now return only the result)\n# result = run_model(train_x, train_y, test_x, test_y, var_repeat=1, init_model=model)\n# print(result)\n\n# # --------------------- save fewâ€‘shot checkpoints -----------------------\n# # After fine-tuning, save the model\n# torch.save(model.state_dict(), f\"{name_run}_fewshot_final_model.pt\")\n# torch.save(model.state_dict(), f\"{name_run}_fewshot_best_model.pt\")\n\n# # ------------------- confusion matrix on CPU ---------------------------\n# if Confusion_matrix == 1 and preset[\"model\"] != \"ST-RF\":\n\n#     # reshape for sequence models\n#     test_x_rs = (test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n#                  if preset[\"model\"] in (\"LSTM\", \"bi-LSTM\", \"THAT\") else test_x)\n\n#     # instantiate identical architecture on CPU\n#     if preset[\"model\"] == \"LSTM\":\n#         model_cpu = LSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n#     elif preset[\"model\"] == \"bi-LSTM\":\n#         model_cpu = BiLSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n#     elif preset[\"model\"] == \"THAT\":\n#         model_cpu = THAT(test_x_rs[0].shape, test_y[0].shape).cpu()\n#     else:  # ResNet18\n#         model_cpu = ResNet18Model(test_x_rs[0].shape, test_y[0].shape).cpu()\n\n#     # load weights\n#     model_cpu.load_state_dict(torch.load(f\"{name_run}_fewshot_best_model.pt\", map_location=\"cpu\"))\n\n#     # CPU DataLoader with a safe batch size\n#     test_ds = TensorDataset(torch.from_numpy(test_x_rs).float(),\n#                             torch.from_numpy(test_y).float())\n#     test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n\n#     pdf_name = f\"{name_run}_fewshot_confusion_matrix.pdf\"\n#     num_classes = test_y.shape[1]\n#     save_multiclass_confusion_matrix(model_cpu, test_loader, pdf_name, num_classes)\n#     print(f\"âœ… Saved fewâ€‘shot confusion matrix (classes 0â€“{num_classes-1}) to {pdf_name}\")\n\n# # ----------------------- restore & persist -----------------------------\n# preset[\"nn\"][\"epoch\"] = original_epochs\n\n# # Save the final result to JSON\n# with open(\"result_fewshot.json\", \"w\") as f:\n#     json.dump(result, f, indent=4)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport scipy.io as scio\nimport time\nimport torch\nimport gc\nfrom numpy.linalg import svd\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\nfrom copy import deepcopy\nimport json\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch._dynamo\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport matplotlib.pyplot as plt\n\n# --- ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…ÛŒ ---\ntorch.cuda.empty_cache()\ntorch.set_float32_matmul_precision(\"high\")\n\n# --------------------------\n# 1. ØªÙ†Ø¸ÛŒÙ…Ø§Øª (Configuration)\n# --------------------------\npreset = {\n    \"model\": \"THAT\",          \n    \"task\": \"activity\",       \n    \"repeat\": 1,\n    \"path\": {\n        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   \n        \"data_y\": \"/kaggle/input/wimans/annotation.csv\", \n    },\n    \"data\": {\n        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  \n        \"wifi_band\": [\"2.4\"],                         \n        \"environment\": [\"classroom\"],                 \n        \"length\": 3000,\n        \n        # 1.0 = 100% data (Full run) | 0.1 = 10% data (Quick test)\n        \"subset_ratio\": 0.5,  \n    },\n    \"nn\": {\n        \"lr\": 1e-3,           \n        \"epoch\": 80,          \n        \"batch_size\": 32,    \n        \"threshold\": 0.5,\n        \"patience\": 5,        \n        \"factor\": 0.5,        \n        \"min_lr\": 1e-6        \n    },\n    \"encoding\": {\n        \"activity\": {\n            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n        },\n    },\n}\n\n# --------------------------\n# 2. ØªÙˆØ§Ø¨Ø¹ RPCA Ùˆ Ù„ÙˆØ¯ Ø¯ÛŒØªØ§\n# --------------------------\ndef soft_threshold(x, epsilon):\n    return np.maximum(np.abs(x) - epsilon, 0) * np.sign(x)\n\ndef robust_pca(M, max_iter=10, tol=1e-4):\n    n1, n2 = M.shape\n    lambda_param = 1 / np.sqrt(max(n1, n2))\n    Y = M / np.maximum(np.linalg.norm(M, 2), np.linalg.norm(M, np.inf) / lambda_param)\n    L = np.zeros_like(M)\n    S = np.zeros_like(M)\n    mu = 1.25 / np.linalg.norm(M, 2)\n    rho = 1.5\n    for i in range(max_iter):\n        temp_L = M - S + (1/mu) * Y\n        U, Sigma, Vt = svd(temp_L, full_matrices=False)\n        Sigma_thresh = soft_threshold(Sigma, 1/mu)\n        L_new = np.dot(U * Sigma_thresh, Vt)\n        temp_S = M - L_new + (1/mu) * Y\n        S_new = soft_threshold(temp_S, lambda_param/mu)\n        error = np.linalg.norm(M - L_new - S_new, 'fro') / np.linalg.norm(M, 'fro')\n        L = L_new; S = S_new\n        if error < tol: break\n        Y = Y + mu * (M - L - S)\n        mu = min(mu * rho, 1e7)\n    return L, S\n\ndef load_data_y(var_path_data_y, var_environment=None, var_wifi_band=None, var_num_users=None):\n    data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n    if var_environment is not None: data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n    if var_wifi_band is not None: data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n    if var_num_users is not None: data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n    return data_pd_y\n\ndef load_data_x(var_path_data_x, var_label_list, use_rpca=True):\n    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n    data_x = []\n    mode_str = \"WITH RPCA\" if use_rpca else \"RAW DATA (No RPCA)\"\n    print(f\"Loading {len(var_path_list)} samples - Mode: {mode_str}...\")\n    for i, var_path in enumerate(var_path_list):\n        if i % 100 == 0 and i > 0: print(f\"Processing {i}/{len(var_path_list)}...\")\n        data_csi = np.load(var_path) \n        data_csi_2d = data_csi.reshape(data_csi.shape[0], -1)\n        target_len = preset[\"data\"][\"length\"]\n        current_len = data_csi_2d.shape[0]\n        var_pad_length = target_len - current_len\n        if var_pad_length > 0: data_csi_pad = np.pad(data_csi_2d, ((0, var_pad_length), (0, 0)), mode='constant')\n        else: data_csi_pad = data_csi_2d[:target_len, :]\n        if use_rpca:\n            L, S = robust_pca(data_csi_pad)\n            final_sample = np.concatenate([L, S], axis=1) \n        else:\n            final_sample = data_csi_pad\n        data_x.append(final_sample)\n    data_x = np.array(data_x)\n    return data_x\n\ndef encode_data_y(data_pd_y, var_task):\n    if var_task == \"activity\": return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    return encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n\ndef encode_activity(data_pd_y, var_encoding):\n    cols = [f\"user_{i}_activity\" for i in range(1, 7)]\n    data = data_pd_y[cols].to_numpy(copy=True).astype(str)\n    return np.array([[var_encoding[y] for y in sample] for sample in data])\n\n# --------------------------\n# 3. Ù…Ø¯Ù„ THAT\n# --------------------------\nclass Gaussian_Position(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n        super(Gaussian_Position, self).__init__()\n        self.var_embedding = torch.nn.Parameter(torch.zeros([var_num_gaussian, var_dim_feature]), requires_grad=True)\n        torch.nn.init.xavier_uniform_(self.var_embedding)\n        self.var_position = torch.nn.Parameter(torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian), requires_grad=False)\n        self.var_mu = torch.nn.Parameter(torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0), requires_grad=True)\n        self.var_sigma = torch.nn.Parameter(torch.tensor([50.0] * var_num_gaussian).unsqueeze(0), requires_grad=True)\n    def forward(self, var_input):\n        var_pdf = - (self.var_position - self.var_mu)**2 / (2 * self.var_sigma**2) - torch.log(self.var_sigma)\n        var_pdf = torch.softmax(var_pdf, dim=-1)\n        return var_input + torch.matmul(var_pdf, self.var_embedding).unsqueeze(0)\n\nclass Encoder(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n        super(Encoder, self).__init__()\n        self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n        self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n        self.layer_dropout_0 = torch.nn.Dropout(0.1)\n        self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n        self.layer_cnn = torch.nn.ModuleList([torch.nn.Sequential(torch.nn.Conv1d(var_dim_feature, var_dim_feature, s, padding=\"same\"), torch.nn.BatchNorm1d(var_dim_feature), torch.nn.Dropout(0.1), torch.nn.LeakyReLU()) for s in var_size_cnn])\n        self.layer_dropout_1 = torch.nn.Dropout(0.1)\n    def forward(self, var_input):\n        var_t = self.layer_norm_0(var_input)\n        var_t, _ = self.layer_attention(var_t, var_t, var_t)\n        var_t = self.layer_dropout_0(var_t) + var_input\n        var_s = self.layer_norm_1(var_t).permute(0, 2, 1)\n        var_c = torch.stack([l(var_s) for l in self.layer_cnn], dim=0)\n        var_s = self.layer_dropout_1((torch.sum(var_c, dim=0) / len(self.layer_cnn)).permute(0, 2, 1))\n        return var_s + var_t\n\nclass THAT(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(THAT, self).__init__()\n        var_dim_feature, var_dim_time = var_x_shape[-1], var_x_shape[-2]\n        var_dim_output = var_y_shape[-1]\n        self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n        self.layer_left_encoder = torch.nn.ModuleList([Encoder(var_dim_feature, 10, [1, 3, 5]) for _ in range(4)])\n        self.layer_left_norm = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n        self.layer_left_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_feature, 128, k) for k in [8, 16]])\n        self.layer_left_dropout = torch.nn.Dropout(0.5)\n        var_dim_right = var_dim_time // 20\n        self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        self.layer_right_encoder = torch.nn.ModuleList([Encoder(var_dim_right, 10, [1, 2, 3])])\n        self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n        self.layer_right_cnn = torch.nn.ModuleList([torch.nn.Conv1d(var_dim_right, 16, k) for k in [2, 4]])\n        self.layer_right_dropout = torch.nn.Dropout(0.5)\n        self.layer_leakyrelu = torch.nn.LeakyReLU()\n        self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n    def forward(self, var_input):\n        v_l = self.layer_left_gaussian(self.layer_left_pooling(var_input.permute(0, 2, 1)).permute(0, 2, 1))\n        for l in self.layer_left_encoder: v_l = l(v_l)\n        v_l = self.layer_left_norm(v_l).permute(0, 2, 1)\n        v_l = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_l)), dim=-1) for cnn in self.layer_left_cnn], dim=-1)\n        v_l = self.layer_left_dropout(v_l)\n        v_r = self.layer_right_pooling(var_input.permute(0, 2, 1))\n        for l in self.layer_right_encoder: v_r = l(v_r)\n        v_r = self.layer_right_norm(v_r).permute(0, 2, 1)\n        v_r = torch.cat([torch.sum(self.layer_leakyrelu(cnn(v_r)), dim=-1) for cnn in self.layer_right_cnn], dim=-1)\n        v_r = self.layer_right_dropout(v_r)\n        return self.layer_output(torch.cat([v_l, v_r], dim=-1))\n\n# --------------------------\n# 4. Training Loop\n# --------------------------\ndef train(model, optimizer, loss_fn, train_loader, test_loader, threshold, epochs, device, model_path):\n    best_acc = -1.0\n    best_w = deepcopy(model.state_dict())\n    \n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='max', factor=preset[\"nn\"][\"factor\"], patience=preset[\"nn\"][\"patience\"],\n        min_lr=preset[\"nn\"][\"min_lr\"], verbose=True\n    )\n    \n    for epoch in range(epochs):\n        t0 = time.time()\n        model.train()\n        \n        # --- [MODIFIED] Using requested variable names ---\n        for data_batch_x, data_batch_y in train_loader:\n            data_batch_x = data_batch_x.to(device)\n            data_batch_y = data_batch_y.to(device)\n            \n            optimizer.zero_grad()\n            \n            predict_train_y = model(data_batch_x)\n            \n            # --- [REQUESTED LINE] ---\n            loss_value = loss_fn(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n            \n            loss_value.backward()\n            optimizer.step()\n            \n        model.eval()\n        with torch.no_grad():\n            tx, ty = next(iter(test_loader))\n            tx, ty = tx.to(device), ty.to(device)\n            pred_t = model(tx)\n            \n            p_cls = (torch.sigmoid(pred_t) > threshold).float().cpu().numpy()\n            t_cls = ty.cpu().numpy()\n            acc = accuracy_score(t_cls.reshape(-1, t_cls.shape[-1]), p_cls.reshape(-1, t_cls.shape[-1]))\n            \n        scheduler.step(acc)\n        current_lr = optimizer.param_groups[0]['lr']\n        print(f\"Ep {epoch+1}/{epochs} | LR: {current_lr:.6f} | L_tr: {loss_value.item():.4f} | Acc: {acc:.4f}\")\n        \n        if acc > best_acc:\n            best_acc = acc\n            best_w = deepcopy(model.state_dict())\n            \n    torch.save(best_w, model_path)\n    return best_w\n\ndef save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes, title_text):\n    model.eval()\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb) \n            logits = logits.reshape(-1, num_classes) \n            yb = yb.reshape(-1, num_classes)        \n            y_pred.extend(torch.argmax(logits, dim=1).cpu().numpy().tolist())\n            y_true.extend(torch.argmax(yb, dim=1).cpu().numpy().tolist())\n    \n    labels = list(range(num_classes))\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n    fig, ax = plt.subplots(figsize=(12, 12))\n    disp.plot(ax=ax, xticks_rotation=\"vertical\", cmap='Blues')\n    ax.set_title(title_text)\n    with PdfPages(pdf_path) as pdf: pdf.savefig(fig)\n    plt.close(fig)\n\n# --------------------------\n# 5. Ø§Ø¬Ø±Ø§\n# --------------------------\ndef run_experiment(scenario_name, use_rpca):\n    print(f\"\\n################################################\")\n    print(f\"STARTING SCENARIO: {scenario_name}\")\n    print(f\"################################################\")\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    current_run_name = f\"{preset['model']}_{preset['task']}_{scenario_name}\"\n    model_save_path = f\"{current_run_name}_best_model.pt\"\n    json_save_path = f\"result_{current_run_name}.json\"\n    pdf_save_path = f\"Confusion_{current_run_name}.pdf\"\n    \n    # 1. Load Labels\n    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], preset[\"data\"][\"environment\"], preset[\"data\"][\"wifi_band\"], preset[\"data\"][\"num_users\"])\n    \n    # Apply Subset Ratio\n    subset_ratio = preset[\"data\"][\"subset_ratio\"]\n    if subset_ratio < 1.0:\n        data_pd_y = data_pd_y.sample(frac=subset_ratio, random_state=42).reset_index(drop=True)\n        print(f\"*** DEBUG MODE: Using {subset_ratio*100}% of data ({len(data_pd_y)} samples) ***\")\n    \n    # 2. Load X\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], data_pd_y[\"label\"].tolist(), use_rpca=use_rpca)\n    data_y = encode_data_y(data_pd_y, preset[\"task\"])\n    \n    # 3. Split\n    train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n    train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n    test_ds = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n    train_loader = DataLoader(train_ds, batch_size=preset[\"nn\"][\"batch_size\"], shuffle=True)\n    test_loader = DataLoader(test_ds, batch_size=len(test_ds), shuffle=False)\n    \n    result = {\"accuracy\": []}\n    \n    for r in range(preset[\"repeat\"]):\n        print(f\"--- Repeat {r+1}/{preset['repeat']} ---\")\n        torch.random.manual_seed(r + 39)\n        \n        model = THAT(train_x[0].shape, train_y[0].reshape(-1).shape).to(device)\n        optimizer = torch.optim.Adam(model.parameters(), lr=preset[\"nn\"][\"lr\"])\n        loss_fn = torch.nn.BCEWithLogitsLoss()\n        \n        best_w = train(model, optimizer, loss_fn, train_loader, test_loader, \n                       preset[\"nn\"][\"threshold\"], preset[\"nn\"][\"epoch\"], device, model_save_path)\n        \n        model.load_state_dict(best_w)\n        with torch.no_grad():\n            preds = model(torch.from_numpy(test_x).to(device))\n            preds_reshaped = (torch.sigmoid(preds) > preset[\"nn\"][\"threshold\"]).float().cpu().numpy().reshape(-1, 9)\n            targets_reshaped = test_y.reshape(-1, 9)\n            acc = accuracy_score(targets_reshaped, preds_reshaped)\n            result[\"accuracy\"].append(acc)\n            \n    print(f\"Final Accuracy ({scenario_name}): {np.mean(result['accuracy']):.4f}\")\n    with open(json_save_path, \"w\") as f: json.dump(result, f, indent=4)\n    \n    print(\"Generating Confusion Matrix...\")\n    model_cm = THAT(test_x[0].shape, test_y[0].reshape(-1).shape).to(\"cpu\")\n    model_cm.load_state_dict(torch.load(model_save_path, map_location=\"cpu\"))\n    cm_loader = DataLoader(TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y)), batch_size=32)\n    num_classes = test_y.shape[2] \n    title = f\"Confusion Matrix: {scenario_name} (Acc: {np.mean(result['accuracy']):.2f} - {subset_ratio*100}% Data)\"\n    save_multiclass_confusion_matrix(model_cm, cm_loader, \"cpu\", pdf_save_path, num_classes, title)\n    \n    del model, model_cm, train_x, test_x, data_x\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(f\"Done with {scenario_name}.\\n\")\n\ndef run():\n    scenarios = [\n        (\"RPCA\", True),\n        (\"RAW\", False)\n    ]\n    for name, rpca_flag in scenarios:\n        run_experiment(name, rpca_flag)\n\nif __name__ == \"__main__\":\n    run()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T13:48:21.536089Z","iopub.execute_input":"2025-11-24T13:48:21.536388Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}