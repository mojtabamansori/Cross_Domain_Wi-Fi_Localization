{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7638081,"sourceType":"datasetVersion","datasetId":4451316}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"---\nCell 1: Library Imports\n---\n---","metadata":{}},{"cell_type":"code","source":"# Cell 1: Library Imports\nimport os\nimport argparse\nimport numpy as np\nimport pandas as pd\nimport scipy.io as scio\nimport time\nimport torch\ntorch.cuda.empty_cache()\nimport torch._dynamo\nfrom torch.utils.data import TensorDataset, DataLoader\n# from ptflops import get_model_complexity_info\nfrom sklearn.metrics import classification_report, accuracy_score\nfrom copy import deepcopy\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nimport torch\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:01:57.276426Z","iopub.execute_input":"2025-05-04T22:01:57.276731Z","iopub.status.idle":"2025-05-04T22:01:59.470540Z","shell.execute_reply.started":"2025-05-04T22:01:57.276710Z","shell.execute_reply":"2025-05-04T22:01:59.469875Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell 2: preset.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          preset.py\n[description]   default settings of WiFi-based models\n\"\"\"\n\npreset = {\n    # define model\n    \"model\": \"ResNet18\",  # \"ST-RF\", \"MLP\", \"LSTM\", \"CNN-1D\", \"CNN-2D\", \"CLSTM\", \"ABLSTM\", \"THAT\", \"bi-LSTM\", \"ResNet18\"\n    # define task\n    \"task\": \"count\",  # \"identity\", \"activity\", \"location\", \"count\"\n    # number of repeated experiments\n    \"repeat\": 1,\n    # path of data\n    \"path\": {\n        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",   # directory of CSI amplitude files \n        \"data_y\": \"/kaggle/input/wimans/annotation.csv\", # path of annotation file\n        \"save\": \"result_lstm_epoch=80_batchsize=32_envs=empty_room_wifiband=2.4.json\"               # path to save results\n    },\n    # data selection for experiments\n    \"data\": {\n        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],  # select number(s) of users\n        \"wifi_band\": [\"2.4\"],                         # select WiFi band(s)\n        \"environment\": [\"classroom\"],                 # select environment(s) [\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\n        \"length\": 3000,                               # default length of CSI\n    },\n    # hyperparameters of models\n    \"nn\": {\n        \"lr\": 1e-3,           # learning rate\n        \"epoch\": 300,         # number of epochs\n        \"batch_size\": 64,    # batch size\n        \"threshold\": 0.5,     # threshold to binarize sigmoid outputs\n    },\n    # encoding of activities and locations\n    \"encoding\": {\n        \"activity\": {  # encoding of different activities\n            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n        },\n        \"location\": {  # encoding of different locations\n            \"nan\":  [0, 0, 0, 0, 0],\n            \"a\":    [1, 0, 0, 0, 0],\n            \"b\":    [0, 1, 0, 0, 0],\n            \"c\":    [0, 0, 1, 0, 0],\n            \"d\":    [0, 0, 0, 1, 0],\n            \"e\":    [0, 0, 0, 0, 1],\n        },\n    },\n}\n\n\n# Few-shot parameters (manually set)\ndest_env = \"empty_room\"       # Destination environment[\"classroom\"], [\"meeting_room\"], [\"empty_room\"]\nfew_shot_epochs = 100         # Number of epochs for few-shot training\nfew_shot_num_samples = 5     # Number of samples to use from the destination test data\n\nConfusion_matrix = 1\n\nname_run = \"few={},{},{},m={},t={},epoch={},batch={},environment={}\".format(dest_env, few_shot_epochs, few_shot_num_samples, preset[\"model\"], preset[\"task\"], preset[\"nn\"][\"epoch\"], preset[\"nn\"][\"batch_size\"], preset[\"data\"][\"environment\"])\nprint(name_run)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:01:59.471666Z","iopub.execute_input":"2025-05-04T22:01:59.472138Z","iopub.status.idle":"2025-05-04T22:01:59.481458Z","shell.execute_reply.started":"2025-05-04T22:01:59.472113Z","shell.execute_reply":"2025-05-04T22:01:59.480564Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell 3: load_data.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          load_data.py\n[description]   load annotation file and CSI amplitude, and encode labels\n\"\"\"\nfrom sklearn.preprocessing import OneHotEncoder\nimport numpy as np\n\n# Note: All necessary libraries (os, numpy, pandas, etc.) are imported in Cell 1.\n# from preset import preset   --> preset is already defined in Cell 2.\n\ndef load_data_y(var_path_data_y,\n                var_environment=None, \n                var_wifi_band=None, \n                var_num_users=None):\n    \"\"\"\n    Load annotation file (*.csv) as a pandas dataframe and filter by environment, WiFi band, and number of users.\n    \"\"\"\n    data_pd_y = pd.read_csv(var_path_data_y, dtype=str)\n    if var_environment is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n    if var_wifi_band is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n    if var_num_users is not None:\n        data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n    return data_pd_y\n\ndef load_data_x(var_path_data_x, var_label_list):\n    \"\"\"\n    Load CSI amplitude (*.npy) files based on a label list.\n    \"\"\"\n    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n    data_x = []\n    for var_path in var_path_list:\n        data_csi = np.load(var_path)\n        var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n        data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n        data_x.append(data_csi_pad)\n    data_x = np.array(data_x)\n    return data_x\n\ndef encode_data_y(data_pd_y, var_task):\n    \"\"\"\n    Encode labels according to specific task.\n    \"\"\"\n    if var_task == \"identity\":\n        data_y = encode_identity(data_pd_y)\n    elif var_task == \"activity\":\n        data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    elif var_task == \"location\":\n        data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n    elif var_task == \"count\":\n        data_y = encode_count(data_pd_y, preset[\"encoding\"][\"location\"])\n    return data_y\n\ndef encode_identity(data_pd_y):\n    \"\"\"\n    Onehot encoding for identity labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_identity_y[data_identity_y != \"nan\"] = 1\n    data_identity_y[data_identity_y == \"nan\"] = 0\n    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n    return data_identity_onehot_y\n\n\n\ndef encode_activity(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for activity labels.\n    \"\"\"\n    data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n                                    \"user_3_activity\", \"user_4_activity\", \n                                    \"user_5_activity\", \"user_6_activity\"]]\n    data_activity_y = data_activity_pd_y.to_numpy(copy=True).astype(str)\n    data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n    return data_activity_onehot_y\n\ndef encode_location(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for location labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_location_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n    return data_location_onehot_y\n\n# Test functions (optional)\ndef test_load_data_y():\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"classroom\"]).describe())\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"]).describe())\n    print(load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=[\"1\", \"2\", \"3\"]).describe())\n\ndef test_load_data_x():\n    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"], var_environment=[\"meeting_room\"], var_wifi_band=[\"2.4\"], var_num_users=None)\n    var_label_list = data_pd_y[\"label\"].to_list()\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n    print(data_x.shape)\n\ndef test_encode_identity():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_identity_onehot_y = encode_identity(data_pd_y)\n    print(data_identity_onehot_y.shape)\n    print(data_identity_onehot_y[2000])\n\ndef test_encode_activity():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n    print(data_activity_onehot_y.shape)\n    print(data_activity_onehot_y[1560])\n\ndef test_encode_location():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n    print(data_location_onehot_y.shape)\n    print(data_location_onehot_y[1560])\n\ndef encode_count(data_pd_y, var_encoding):\n    \"\"\"\n    Onehot encoding for identity labels.\n    \"\"\"\n    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n                                    \"user_3_location\", \"user_4_location\", \n                                    \"user_5_location\", \"user_6_location\"]]\n    data_identity_y = data_location_pd_y.to_numpy(copy=True).astype(str)\n    data_identity_y[data_identity_y != \"nan\"] = 1\n    data_identity_y[data_identity_y == \"nan\"] = 0\n    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n    print(\"data_identity_onehot_y\",data_identity_onehot_y.shape)\n    count_data = np.sum(data_identity_onehot_y, axis=1)\n    print(\"count_data\",count_data.shape)\n    count_data = count_data.reshape(-1, 1)  # shape = (11286, 1)\n    encoder = OneHotEncoder(sparse=False)  \n    count_data_onehot = encoder.fit_transform(count_data)\n    print(count_data_onehot.shape)  \n    count_data_onehot = count_data_onehot.astype(\"int8\")\n\n    return count_data_onehot\n\n\ndef test_encode_count():\n    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype=str)\n    data_count_onehot_y = encode_count(data_pd_y)\n    print(data_count_onehot_y.shape)\n    print(data_count_onehot_y[20])\n\n# if __name__ == \"__main__\":\n#     test_encode_count()\n#     test_load_data_y()\n#     test_load_data_x()\n#     test_encode_identity()\n#     test_encode_activity()\n#     test_encode_location()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:01:59.483109Z","iopub.execute_input":"2025-05-04T22:01:59.483422Z","iopub.status.idle":"2025-05-04T22:01:59.507797Z","shell.execute_reply.started":"2025-05-04T22:01:59.483390Z","shell.execute_reply":"2025-05-04T22:01:59.507132Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell 4: preprocess.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          preprocess.py\n[description]   preprocess WiFi CSI data\n\"\"\"\n\n# All necessary libraries are already imported in Cell 1.\n\ndef mat_to_amp(data_mat):\n    \"\"\"\n    Calculate amplitude of raw WiFi CSI data.\n    \"\"\"\n    var_length = data_mat[\"trace\"].shape[0]\n    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n    data_csi_amp = np.array(data_csi_amp, dtype=np.float32)\n    return data_csi_amp\n\ndef extract_csi_amp(var_dir_mat, var_dir_amp):\n    \"\"\"\n    Read raw WiFi CSI (*.mat) files, calculate CSI amplitude, and save as (*.npy).\n    \"\"\"\n    var_path_mat = os.listdir(var_dir_mat)\n    for var_c, var_path in enumerate(var_path_mat):\n        data_mat = scio.loadmat(os.path.join(var_dir_mat, var_path))\n        data_csi_amp = mat_to_amp(data_mat)\n        # print(var_c, data_csi_amp.shape)\n        var_path_save = os.path.join(var_dir_amp, var_path.replace(\".mat\", \".npy\"))\n        with open(var_path_save, \"wb\") as var_file:\n            np.save(var_file, data_csi_amp)\n\ndef parse_args():\n    \"\"\"\n    Parse arguments from input.\n    \"\"\"\n    var_args = argparse.ArgumentParser()\n    var_args.add_argument(\"--dir_mat\", default=\"/kaggle/input/wimans/wifi_csi/mat\", type=str)\n    var_args.add_argument(\"--dir_amp\", default=\"/kaggle/input/wimans/wifi_csi/amp\", type=str)\n    return var_args.parse_args()\n\n# if __name__ == \"__main__\":\n#     var_args = parse_args()\n#     extract_csi_amp(var_dir_mat=var_args.dir_mat, var_dir_amp=var_args.dir_amp)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:01:59.508860Z","iopub.execute_input":"2025-05-04T22:01:59.509107Z","iopub.status.idle":"2025-05-04T22:01:59.521761Z","shell.execute_reply.started":"2025-05-04T22:01:59.509056Z","shell.execute_reply":"2025-05-04T22:01:59.520963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell 5: that.py (WiFi-based Model THAT)\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          that.py\n[description]   implement and evaluate WiFi-based model THAT\n                https://github.com/windofshadow/THAT\n\"\"\"\n\n# All necessary libraries are imported in Cell 1.\n# from train import train   --> Defined in Cell 6.\n# from preset import preset --> Defined in Cell 2.\n\nclass Gaussian_Position(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_dim_time, var_num_gaussian=10):\n        super(Gaussian_Position, self).__init__()\n        var_embedding = torch.zeros([var_num_gaussian, var_dim_feature], dtype=torch.float)\n        self.var_embedding = torch.nn.Parameter(var_embedding, requires_grad=True)\n        torch.nn.init.xavier_uniform_(self.var_embedding)\n        var_position = torch.arange(0.0, var_dim_time).unsqueeze(1).repeat(1, var_num_gaussian)\n        self.var_position = torch.nn.Parameter(var_position, requires_grad=False)\n        var_mu = torch.arange(0.0, var_dim_time, var_dim_time/var_num_gaussian).unsqueeze(0)\n        self.var_mu = torch.nn.Parameter(var_mu, requires_grad=True)\n        var_sigma = torch.tensor([50.0] * var_num_gaussian).unsqueeze(0)\n        self.var_sigma = torch.nn.Parameter(var_sigma, requires_grad=True)\n\n    def calculate_pdf(self, var_position, var_mu, var_sigma):\n        var_pdf = var_position - var_mu\n        var_pdf = - var_pdf * var_pdf\n        var_pdf = var_pdf / var_sigma / var_sigma / 2\n        var_pdf = var_pdf - torch.log(var_sigma)\n        return var_pdf\n\n    def forward(self, var_input):\n        var_pdf = self.calculate_pdf(self.var_position, self.var_mu, self.var_sigma)\n        var_pdf = torch.softmax(var_pdf, dim=-1)\n        var_position_encoding = torch.matmul(var_pdf, self.var_embedding)\n        var_output = var_input + var_position_encoding.unsqueeze(0)\n        return var_output\n\nclass Encoder(torch.nn.Module):\n    def __init__(self, var_dim_feature, var_num_head=10, var_size_cnn=[1, 3, 5]):\n        super(Encoder, self).__init__()\n        self.layer_norm_0 = torch.nn.LayerNorm(var_dim_feature, eps=1e-6)\n        self.layer_attention = torch.nn.MultiheadAttention(var_dim_feature, var_num_head, batch_first=True)\n        self.layer_dropout_0 = torch.nn.Dropout(0.1)\n        self.layer_norm_1 = torch.nn.LayerNorm(var_dim_feature, 1e-6)\n        layer_cnn = []\n        for var_size in var_size_cnn:\n            layer = torch.nn.Sequential(\n                torch.nn.Conv1d(var_dim_feature, var_dim_feature, var_size, padding=\"same\"),\n                torch.nn.BatchNorm1d(var_dim_feature),\n                torch.nn.Dropout(0.1),\n                torch.nn.LeakyReLU()\n            )\n            layer_cnn.append(layer)\n        self.layer_cnn = torch.nn.ModuleList(layer_cnn)\n        self.layer_dropout_1 = torch.nn.Dropout(0.1)\n\n    def forward(self, var_input):\n        var_t = var_input\n        var_t = self.layer_norm_0(var_t)\n        var_t, _ = self.layer_attention(var_t, var_t, var_t)\n        var_t = self.layer_dropout_0(var_t)\n        var_t = var_t + var_input\n        var_s = self.layer_norm_1(var_t)\n        var_s = torch.permute(var_s, (0, 2, 1))\n        var_c = torch.stack([layer(var_s) for layer in self.layer_cnn], dim=0)\n        var_s = torch.sum(var_c, dim=0) / len(self.layer_cnn)\n        var_s = self.layer_dropout_1(var_s)\n        var_s = torch.permute(var_s, (0, 2, 1))\n        var_output = var_s + var_t\n        return var_output\n\nclass THAT(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(THAT, self).__init__()\n        var_dim_feature = var_x_shape[-1]\n        var_dim_time = var_x_shape[-2]\n        var_dim_output = var_y_shape[-1]\n        # Left branch\n        self.layer_left_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        self.layer_left_gaussian = Gaussian_Position(var_dim_feature, var_dim_time // 20)\n        var_num_left = 4\n        var_dim_left = var_dim_feature\n        self.layer_left_encoder = torch.nn.ModuleList([\n            Encoder(var_dim_feature=var_dim_left, var_num_head=10, var_size_cnn=[1, 3, 5])\n            for _ in range(var_num_left)\n        ])\n        self.layer_left_norm = torch.nn.LayerNorm(var_dim_left, eps=1e-6)\n        self.layer_left_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=8)\n        self.layer_left_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_left, out_channels=128, kernel_size=16)\n        self.layer_left_dropout = torch.nn.Dropout(0.5)\n        # Right branch\n        self.layer_right_pooling = torch.nn.AvgPool1d(kernel_size=20, stride=20)\n        var_num_right = 1\n        var_dim_right = var_dim_time // 20\n        self.layer_right_encoder = torch.nn.ModuleList([\n            Encoder(var_dim_feature=var_dim_right, var_num_head=10, var_size_cnn=[1, 2, 3])\n            for _ in range(var_num_right)\n        ])\n        self.layer_right_norm = torch.nn.LayerNorm(var_dim_right, eps=1e-6)\n        self.layer_right_cnn_0 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=2)\n        self.layer_right_cnn_1 = torch.nn.Conv1d(in_channels=var_dim_right, out_channels=16, kernel_size=4)\n        self.layer_right_dropout = torch.nn.Dropout(0.5)\n        self.layer_leakyrelu = torch.nn.LeakyReLU()\n        self.layer_output = torch.nn.Linear(256 + 32, var_dim_output)\n\n    def forward(self, var_input):\n        var_t = var_input  # shape: (batch_size, time_steps, features)\n        # Left branch\n        var_left = torch.permute(var_t, (0, 2, 1))\n        var_left = self.layer_left_pooling(var_left)\n        var_left = torch.permute(var_left, (0, 2, 1))\n        var_left = self.layer_left_gaussian(var_left)\n        for layer in self.layer_left_encoder:\n            var_left = layer(var_left)\n        var_left = self.layer_left_norm(var_left)\n        var_left = torch.permute(var_left, (0, 2, 1))\n        var_left_0 = self.layer_leakyrelu(self.layer_left_cnn_0(var_left))\n        var_left_1 = self.layer_leakyrelu(self.layer_left_cnn_1(var_left))\n        var_left_0 = torch.sum(var_left_0, dim=-1)\n        var_left_1 = torch.sum(var_left_1, dim=-1)\n        var_left = torch.concat([var_left_0, var_left_1], dim=-1)\n        var_left = self.layer_left_dropout(var_left)\n        # Right branch\n        var_right = torch.permute(var_t, (0, 2, 1))\n        var_right = self.layer_right_pooling(var_right)\n        for layer in self.layer_right_encoder:\n            var_right = layer(var_right)\n        var_right = self.layer_right_norm(var_right)\n        var_right = torch.permute(var_right, (0, 2, 1))\n        var_right_0 = self.layer_leakyrelu(self.layer_right_cnn_0(var_right))\n        var_right_1 = self.layer_leakyrelu(self.layer_right_cnn_1(var_right))\n        var_right_0 = torch.sum(var_right_0, dim=-1)\n        var_right_1 = torch.sum(var_right_1, dim=-1)\n        var_right = torch.concat([var_right_0, var_right_1], dim=-1)\n        var_right = self.layer_right_dropout(var_right)\n        # Concatenate branches\n        var_t = torch.concat([var_left, var_right], dim=-1)\n        var_output = self.layer_output(var_t)\n        return var_output\n\ndef run_that(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10):\n    \"\"\"\n    Run WiFi-based model THAT.\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    data_train_x = data_train_x.reshape(data_train_x.shape[0], data_train_x.shape[1], -1)\n    data_test_x = data_test_x.reshape(data_test_x.shape[0], data_test_x.shape[1], -1)\n    var_x_shape, var_y_shape = data_train_x[0].shape, data_train_y[0].reshape(-1).shape\n    data_train_set = TensorDataset(torch.from_numpy(data_train_x), torch.from_numpy(data_train_y))\n    data_test_set = TensorDataset(torch.from_numpy(data_test_x), torch.from_numpy(data_test_y))\n    \n    result = {}\n    result_accuracy = []\n    result_time_train = []\n    result_time_test = []\n    \n    # var_macs, var_params = get_model_complexity_info(THAT(var_x_shape, var_y_shape), var_x_shape, as_strings=False)\n    # print(\"Parameters:\", var_params, \"- FLOPs:\", var_macs * 2)\n    \n    for var_r in range(var_repeat):\n        print(\"Repeat\", var_r)\n        torch.random.manual_seed(var_r + 39)\n        model_that = THAT(var_x_shape, var_y_shape).to(device)\n        optimizer = torch.optim.Adam(model_that.parameters(), lr=preset[\"nn\"][\"lr\"], weight_decay=0)\n        loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4] * var_y_shape[-1]).to(device))\n        var_time_0 = time.time()\n        \n        # Train\n        var_best_weight = train(model=model_that, optimizer=optimizer, loss=loss, \n                                  data_train_set=data_train_set, data_test_set=data_test_set,\n                                  var_threshold=preset[\"nn\"][\"threshold\"],\n                                  var_batch_size=preset[\"nn\"][\"batch_size\"],\n                                  var_epochs=preset[\"nn\"][\"epoch\"],\n                                  device=device)\n        var_time_1 = time.time()\n        \n        # Test\n        model_that.load_state_dict(var_best_weight)\n        with torch.no_grad():\n            predict_test_y = model_that(torch.from_numpy(data_test_x).to(device))\n        predict_test_y = (torch.sigmoid(predict_test_y) > preset[\"nn\"][\"threshold\"]).float()\n        predict_test_y = predict_test_y.detach().cpu().numpy()\n        var_time_2 = time.time()\n        \n        # Evaluate\n        data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n        predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n        result_acc = accuracy_score(data_test_y_c.astype(int), predict_test_y_c.astype(int))\n        result_dict = classification_report(data_test_y_c, predict_test_y_c, digits=6, zero_division=0, output_dict=True)\n        result[\"repeat_\" + str(var_r)] = result_dict\n        result_accuracy.append(result_acc)\n        result_time_train.append(var_time_1 - var_time_0)\n        result_time_test.append(var_time_2 - var_time_1)\n        print(\"repeat_\" + str(var_r), result_accuracy)\n        print(result)\n    \n    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n    # result[\"complexity\"] = {\"parameter\": var_params, \"flops\": var_macs * 2}\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:01:59.522604Z","iopub.execute_input":"2025-05-04T22:01:59.522864Z","iopub.status.idle":"2025-05-04T22:01:59.549654Z","shell.execute_reply.started":"2025-05-04T22:01:59.522837Z","shell.execute_reply":"2025-05-04T22:01:59.548548Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell6: for LSTM Model (lstm.py)\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          lstm.py\n[description]   implement and evaluate WiFi-based model LSTM\n\"\"\"\nimport torch._dynamo\n# torch._dynamo.config.suppress_errors = True\nimport time\nimport torch\ntorch.cuda.empty_cache()\nimport numpy as np\nfrom torch.utils.data import TensorDataset\n# from ptflops import get_model_complexity_info\nfrom sklearn.metrics import classification_report, accuracy_score\n# from preset import preset\n\nclass LSTMM(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(LSTMM, self).__init__()\n        var_dim_input = var_x_shape[-1]\n        var_dim_output = var_y_shape[-1]\n        self.layer_norm = torch.nn.BatchNorm1d(var_dim_input)\n        self.layer_pooling = torch.nn.AvgPool1d(10, 10)\n        self.layer_lstm = torch.nn.LSTM(input_size=var_dim_input,\n                                        hidden_size=512, \n                                        batch_first=True)\n        self.layer_linear = torch.nn.Linear(512, var_dim_output)\n\n    def forward(self, var_input):\n        var_t = var_input\n        var_t = torch.permute(var_t, (0, 2, 1))\n        var_t = self.layer_norm(var_t)\n        var_t = self.layer_pooling(var_t)\n        var_t = torch.permute(var_t, (0, 2, 1))\n        var_t, _ = self.layer_lstm(var_t)\n        var_t = var_t[:, -1, :]\n        var_t = self.layer_linear(var_t)\n        var_output = var_t\n        return var_output\n\ndef run_lstm(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10):\n    \"\"\"\n    Run WiFi-based model LSTM.\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    data_train_x = data_train_x.reshape(data_train_x.shape[0], data_train_x.shape[1], -1)\n    data_test_x = data_test_x.reshape(data_test_x.shape[0], data_test_x.shape[1], -1)\n    \n    var_x_shape, var_y_shape = data_train_x[0].shape, data_train_y[0].reshape(-1).shape\n    \n    data_train_set = TensorDataset(torch.from_numpy(data_train_x), torch.from_numpy(data_train_y))\n    data_test_set = TensorDataset(torch.from_numpy(data_test_x), torch.from_numpy(data_test_y))\n    \n    result = {}\n    result_accuracy = []\n    result_time_train = []\n    result_time_test = []\n    \n    # var_macs, var_params = get_model_complexity_info(LSTMM(var_x_shape, var_y_shape), var_x_shape, as_strings=False)\n    # print(\"Parameters:\", var_params, \"- FLOPs:\", var_macs * 2)\n    \n    for var_r in range(var_repeat):\n        print(\"Repeat\", var_r)\n        torch.random.manual_seed(var_r + 39)\n        model_lstm = LSTMM(var_x_shape, var_y_shape).to(device)\n        optimizer = torch.optim.Adam(model_lstm.parameters(), \n                                     lr=preset[\"nn\"][\"lr\"],\n                                     weight_decay=0)\n        loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6] * var_y_shape[-1]).to(device))\n        var_time_0 = time.time()\n        \n        # Train\n        var_best_weight = train(model=model_lstm, \n                                optimizer=optimizer, \n                                loss=loss, \n                                data_train_set=data_train_set,\n                                data_test_set=data_test_set,\n                                var_threshold=preset[\"nn\"][\"threshold\"],\n                                var_batch_size=preset[\"nn\"][\"batch_size\"],\n                                var_epochs=preset[\"nn\"][\"epoch\"],\n                                device=device)\n        var_time_1 = time.time()\n        \n        # Test\n        model_lstm.load_state_dict(var_best_weight)\n        with torch.no_grad():\n            predict_test_y = model_lstm(torch.from_numpy(data_test_x).to(device))\n            \n        predict_test_y = (torch.sigmoid(predict_test_y) > preset[\"nn\"][\"threshold\"]).float()\n        predict_test_y = predict_test_y.detach().cpu().numpy()\n        var_time_2 = time.time()\n        \n        # Evaluate\n        data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n        predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n        result_acc = accuracy_score(data_test_y_c.astype(int), predict_test_y_c.astype(int))\n        result_dict = classification_report(data_test_y_c, predict_test_y_c, digits=6, zero_division=0, output_dict=True)\n        result[\"repeat_\" + str(var_r)] = result_dict\n        result_accuracy.append(result_acc)\n        result_time_train.append(var_time_1 - var_time_0)\n        result_time_test.append(var_time_2 - var_time_1)\n        print(\"repeat_\" + str(var_r), result_accuracy)\n        print(result)\n    \n    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n    # result[\"complexity\"] = {\"parameter\": var_params, \"flops\": var_macs * 2}\n    \n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:01:59.550381Z","iopub.execute_input":"2025-05-04T22:01:59.550607Z","iopub.status.idle":"2025-05-04T22:01:59.571378Z","shell.execute_reply.started":"2025-05-04T22:01:59.550589Z","shell.execute_reply":"2025-05-04T22:01:59.570434Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell7: for RESNET18 Model\n---\n---","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n\nimport torch._dynamo\ntorch._dynamo.config.suppress_errors = True\nimport time\nimport torch\ntorch.cuda.empty_cache()\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom sklearn.metrics import accuracy_score, classification_report\nimport torchvision.models as models\nfrom copy import deepcopy\n\ntorch.set_float32_matmul_precision(\"high\")\ntorch._dynamo.config.cache_size_limit = 65536\n\n# فرض می‌کنیم preset قبلاً تعریف شده باشه\n# preset = { \"nn\": {\"lr\": 1e-3, \"epoch\": 10, \"batch_size\": 4, \"threshold\": 0.5}, ... }\n\nclass ResNet18Model(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(ResNet18Model, self).__init__()\n        model_resnet = models.resnet18(weights=None)\n        model_resnet.conv1 = torch.nn.Conv2d(1, 64, 7, 3, 2, bias=False)\n        in_features_fc = model_resnet.fc.in_features  # معمولاً 512\n        out_features_fc = var_y_shape[-1]\n        model_resnet.fc = torch.nn.Linear(in_features_fc, out_features_fc)\n        self.resnet = model_resnet\n\n    def forward(self, var_input):\n        var_input = var_input.reshape(var_input.size(0), 1, 3000, 270)\n        return self.resnet(var_input)\n\ndef run_resnet(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    var_x_shape = data_train_x[0].shape\n    var_y_shape = data_train_y[0].reshape(-1).shape\n\n    # تغییر شکل داده‌ها روی CPU\n    data_train_x = data_train_x.reshape(data_train_x.shape[0], 1, data_train_x.shape[1],\n                                        data_train_x.shape[2]*data_train_x.shape[3]*data_train_x.shape[4])\n    data_test_x  = data_test_x.reshape(data_test_x.shape[0], 1, data_test_x.shape[1],\n                                       data_test_x.shape[2]*data_test_x.shape[3]*data_test_x.shape[4])\n    \n    # دیتاست‌ها روی CPU\n    data_train_set = TensorDataset(torch.from_numpy(data_train_x).float(),\n                                   torch.from_numpy(data_train_y).float())\n    data_test_set  = TensorDataset(torch.from_numpy(data_test_x).float(),\n                                   torch.from_numpy(data_test_y).float())\n    \n    result = {}\n    result_accuracy = []\n    result_time_train = []\n    result_time_test = []\n    \n    for var_r in range(var_repeat):\n        print(\"Repeat\", var_r)\n        torch.random.manual_seed(var_r + 39)\n        \n        # ساخت مدل و انتقال به GPU\n        model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n        optimizer = torch.optim.Adam(model_resnet.parameters(), lr=preset[\"nn\"][\"lr\"], weight_decay=0)\n        loss_func = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6] * var_y_shape[-1]).to(device))\n        \n        # تابع آموزش داخلی؛ دیتا روی CPU باقی می‌مونه و فقط هنگام محاسبه batch به GPU میره\n        def train_inner():\n            train_loader = DataLoader(data_train_set, preset[\"nn\"][\"batch_size\"], shuffle=True, pin_memory=False)\n            test_loader = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n            best_accuracy = 0\n            best_weight = None\n            \n            for epoch in range(preset[\"nn\"][\"epoch\"]):\n                t0 = time.time()\n                model_resnet.train()\n                # متغیرهای مربوط به آخرین batch آموزش\n                last_train_loss = None\n                last_train_acc = None\n                for batch in train_loader:\n                    batch_x, batch_y = batch\n                    batch_x = batch_x.to(device)\n                    batch_y = batch_y.to(device)\n                    outputs = model_resnet(batch_x)\n                    loss_val = loss_func(outputs, batch_y.reshape(batch_y.shape[0], -1).float())\n                    optimizer.zero_grad()\n                    loss_val.backward()\n                    optimizer.step()\n                    last_train_loss = loss_val.item()\n                    # محاسبه دقت آخرین batch آموزش\n                    train_preds = (torch.sigmoid(outputs) > preset[\"nn\"][\"threshold\"]).float()\n                    last_train_acc = accuracy_score(batch_y.reshape(batch_y.shape[0], -1).detach().cpu().numpy().astype(int),\n                                                    train_preds.detach().cpu().numpy().astype(int))\n                \n                # ارزیابی روی دیتاست تست به صورت batch به batch\n                model_resnet.eval()\n                all_preds = []\n                all_labels = []\n                test_loss_val = None\n                with torch.no_grad():\n                    for t_batch in test_loader:\n                        t_x, t_y = t_batch\n                        t_x = t_x.to(device)\n                        outputs_test = model_resnet(t_x)\n                        outputs_test = (torch.sigmoid(outputs_test) > preset[\"nn\"][\"threshold\"]).float()\n                        all_preds.append(outputs_test.detach().cpu().numpy())\n                        all_labels.append(t_y.cpu().numpy())  # اینجا تغییر دادیم\n                preds_cat = np.vstack(all_preds)\n                labels_cat = np.vstack(all_labels)\n                print(\"preds_cat\",preds_cat.shape)\n                # تبدیل به شکل (n, 6, 5)\n                \n                # preds_cat = preds_cat.reshape(-1, 6, 5)\n                # labels_cat = labels_cat.reshape(-1, 6, 5)\n\n                preds_cat = preds_cat.reshape(-1, 6)\n                labels_cat = labels_cat.reshape(-1, 6)\n                \n                # برای محاسبه دقت، مسطح می‌کنیم\n                test_acc = accuracy_score(labels_cat.reshape(labels_cat.shape[0], -1).astype(int),\n                                          preds_cat.reshape(preds_cat.shape[0], -1).astype(int))\n                epoch_time = time.time() - t0\n                print(f\"Epoch {epoch}/{preset['nn']['epoch']} - \"\n                      f\"Train Loss: {(last_train_loss if last_train_loss is not None else 0.0):.6f}, \"\n                      f\"Train Acc: {(last_train_acc if last_train_acc is not None else 0.0):.6f}, \"\n                      f\"Test Loss: {(test_loss_val if test_loss_val is not None else 0.0):.6f}, \"\n                      f\"Test Acc: {(test_acc if test_acc is not None else 0.0):.6f} - \"\n                      f\"Time: {epoch_time:.4f}s\")\n\n                if test_acc > best_accuracy:\n                    best_accuracy = test_acc\n                    print('-----***-----')\n                    print(best_accuracy)\n                    best_weight = deepcopy(model_resnet.state_dict())\n            return best_weight\n        \n        t0_run = time.time()\n        best_weight = train_inner()\n        t1_run = time.time()\n        \n        torch.save(model_resnet.state_dict(), f\"{name_run}_model_final.pt\")\n        model_resnet.load_state_dict(best_weight)\n        torch.save(model_resnet.state_dict(), f\"{name_run}_best_model.pt\")\n\n        # bad age niaz bod load koni\n        # model_resnet = ResNet18Model(var_x_shape, var_y_shape).to(device)\n        # model_resnet.load_state_dict(torch.load(\"resnet_model_repeat0.pt\"))\n        # model_resnet.eval()\n\n        \n        # ارزیابی نهایی مدل روی دیتاست تست (استفاده از batchهای کوچک)\n        model_resnet.eval()\n        all_preds = []\n        test_loader_final = DataLoader(data_test_set, preset[\"nn\"][\"batch_size\"], shuffle=False, pin_memory=False)\n        with torch.no_grad():\n            for batch in test_loader_final:\n                batch_x, _ = batch\n                batch_x = batch_x.to(device)\n                all_preds.append(model_resnet(batch_x))\n        preds_all = torch.cat(all_preds, dim=0)\n        preds_final = (torch.sigmoid(preds_all) > preset[\"nn\"][\"threshold\"]).float().detach().cpu().numpy()\n        t2_run = time.time()\n        \n        data_test_y_np = data_test_y.reshape(-1, data_test_y.shape[-1])\n        preds_final = preds_final.reshape(-1, data_test_y.shape[-1])\n        acc_final = accuracy_score(data_test_y_np.astype(int), preds_final.astype(int))\n        result[f\"repeat_{var_r}\"] = {\"accuracy\": acc_final}\n        result_accuracy.append(acc_final)\n        result_time_train.append(t1_run - t0_run)\n        result_time_test.append(t2_run - t1_run)\n        print(\"Repeat\", var_r, \"Final Test Accuracy:\", acc_final)\n    \n    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:01:59.572395Z","iopub.execute_input":"2025-05-04T22:01:59.572760Z","iopub.status.idle":"2025-05-04T22:02:00.139008Z","shell.execute_reply.started":"2025-05-04T22:01:59.572728Z","shell.execute_reply":"2025-05-04T22:02:00.138352Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell8: for bi-LSTM Model\n---\n---","metadata":{}},{"cell_type":"code","source":"import torch._dynamo\ntorch._dynamo.config.suppress_errors = True\nimport time\nimport torch\ntorch.cuda.empty_cache()\nimport numpy as np\nfrom torch.utils.data import TensorDataset\nfrom sklearn.metrics import classification_report, accuracy_score\n\nclass BiLSTMM(torch.nn.Module):\n    def __init__(self, var_x_shape, var_y_shape):\n        super(BiLSTMM, self).__init__()\n        var_dim_input = var_x_shape[-1]\n        var_dim_output = var_y_shape[-1]\n        self.layer_norm = torch.nn.BatchNorm1d(var_dim_input)\n        self.layer_pooling = torch.nn.AvgPool1d(10, 10)\n        # استفاده از LSTM دو جهته (bidirectional)\n        self.layer_lstm = torch.nn.LSTM(input_size=var_dim_input,\n                                        hidden_size=512, \n                                        batch_first=True,\n                                        bidirectional=True)\n        # تغییر ابعاد ورودی لایه linear به 512*2\n        self.layer_linear = torch.nn.Linear(512 * 2, var_dim_output)\n\n    def forward(self, var_input):\n        var_t = var_input\n        var_t = torch.permute(var_t, (0, 2, 1))\n        var_t = self.layer_norm(var_t)\n        var_t = self.layer_pooling(var_t)\n        var_t = torch.permute(var_t, (0, 2, 1))\n        var_t, _ = self.layer_lstm(var_t)\n        var_t = var_t[:, -1, :]\n        var_t = self.layer_linear(var_t)\n        var_output = var_t\n        return var_output\n\ndef run_bilstm(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat=10):\n    \"\"\"\n    Run WiFi-based model bi-LSTM.\n    \"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    data_train_x = data_train_x.reshape(data_train_x.shape[0], data_train_x.shape[1], -1)\n    data_test_x = data_test_x.reshape(data_test_x.shape[0], data_test_x.shape[1], -1)\n    \n    var_x_shape, var_y_shape = data_train_x[0].shape, data_train_y[0].reshape(-1).shape\n    \n    data_train_set = TensorDataset(torch.from_numpy(data_train_x), torch.from_numpy(data_train_y))\n    data_test_set = TensorDataset(torch.from_numpy(data_test_x), torch.from_numpy(data_test_y))\n    \n    result = {}\n    result_accuracy = []\n    result_time_train = []\n    result_time_test = []\n    \n    for var_r in range(var_repeat):\n        print(\"Repeat\", var_r)\n        torch.random.manual_seed(var_r + 39)\n        model_bilstm = BiLSTMM(var_x_shape, var_y_shape).to(device)\n        optimizer = torch.optim.Adam(model_bilstm.parameters(), \n                                     lr=preset[\"nn\"][\"lr\"],\n                                     weight_decay=0)\n        loss = torch.nn.BCEWithLogitsLoss(pos_weight=torch.tensor([6] * var_y_shape[-1]).to(device))\n        var_time_0 = time.time()\n        \n        var_best_weight = train(model=model_bilstm, \n                                optimizer=optimizer, \n                                loss=loss, \n                                data_train_set=data_train_set,\n                                data_test_set=data_test_set,\n                                var_threshold=preset[\"nn\"][\"threshold\"],\n                                var_batch_size=preset[\"nn\"][\"batch_size\"],\n                                var_epochs=preset[\"nn\"][\"epoch\"],\n                                device=device)\n        var_time_1 = time.time()\n        \n        model_bilstm.load_state_dict(var_best_weight)\n\n\n        \n        with torch.no_grad():\n            predict_test_y = model_bilstm(torch.from_numpy(data_test_x).to(device))\n            \n        predict_test_y = (torch.sigmoid(predict_test_y) > preset[\"nn\"][\"threshold\"]).float()\n        predict_test_y = predict_test_y.detach().cpu().numpy()\n        var_time_2 = time.time()\n        \n        data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n        predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n        result_acc = accuracy_score(data_test_y_c.astype(int), predict_test_y_c.astype(int))\n        result_dict = classification_report(data_test_y_c, predict_test_y_c, digits=6, zero_division=0, output_dict=True)\n        result[\"repeat_\" + str(var_r)] = result_dict\n        result_accuracy.append(result_acc)\n        result_time_train.append(var_time_1 - var_time_0)\n        result_time_test.append(var_time_2 - var_time_1)\n        print(\"repeat_\" + str(var_r), result_accuracy)\n        print(result)\n    \n    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n    \n    return result\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:02:00.141348Z","iopub.execute_input":"2025-05-04T22:02:00.141572Z","iopub.status.idle":"2025-05-04T22:02:00.156012Z","shell.execute_reply.started":"2025-05-04T22:02:00.141554Z","shell.execute_reply":"2025-05-04T22:02:00.155253Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell 9: train.py\n---\n---","metadata":{}},{"cell_type":"code","source":"\"\"\"\n[file]          train.py\n[description]   function to train WiFi-based models\n\"\"\"\n\n# All necessary libraries are imported in Cell 1.\n\ntorch.set_float32_matmul_precision(\"high\")\ntorch._dynamo.config.cache_size_limit = 65536\n\ndef train(model, optimizer, loss, data_train_set, data_test_set, var_threshold, var_batch_size, var_epochs, device):\n    \"\"\"\n    Generic training function for WiFi-based models.\n    \"\"\"\n    # دیتا رو روی CPU نگه می‌داریم (pin_memory=False)\n    data_train_loader = DataLoader(data_train_set, var_batch_size, shuffle=True, pin_memory=False)\n    data_test_loader = DataLoader(data_test_set, batch_size=len(data_test_set), shuffle=False, pin_memory=False)\n\n    var_best_accuracy = 0\n    var_best_weight = None\n    \n    var_best_accuracy = -1.0\n    var_best_weight   = deepcopy(model.state_dict())\n    \n    \n    \n    for var_epoch in range(var_epochs):\n        var_time_e0 = time.time()\n        model.train()\n        for data_batch in data_train_loader:\n            data_batch_x, data_batch_y = data_batch\n            # انتقال موقتی داده به GPU فقط برای forward pass\n            data_batch_x = data_batch_x.to(device)\n            data_batch_y = data_batch_y.to(device)\n            predict_train_y = model(data_batch_x)\n            var_loss_train = loss(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n            optimizer.zero_grad()\n            var_loss_train.backward()\n            optimizer.step()\n        \n        # محاسبه دقت روی آخرین batch و انتقال نتایج به CPU\n        predict_train_y = (torch.sigmoid(predict_train_y) > var_threshold).float()\n        data_batch_y = data_batch_y.detach().cpu().numpy()\n        predict_train_y = predict_train_y.detach().cpu().numpy()\n        \n        predict_train_y = predict_train_y.reshape(-1, data_batch_y.shape[-1])\n        data_batch_y = data_batch_y.reshape(-1, data_batch_y.shape[-1])\n        var_accuracy_train = accuracy_score(data_batch_y.astype(int), predict_train_y.astype(int))\n        \n        model.eval()\n        with torch.no_grad():\n            data_test_x, data_test_y = next(iter(data_test_loader))\n            # انتقال موقتی دیتا تست به GPU برای محاسبات\n            data_test_x = data_test_x.to(device)\n            data_test_y = data_test_y.to(device)\n            \n            predict_test_y = model(data_test_x)\n            var_loss_test = loss(predict_test_y, data_test_y.reshape(data_test_y.shape[0], -1).float())\n            \n            predict_test_y = (torch.sigmoid(predict_test_y) > var_threshold).float()\n            \n            # انتقال نتایج به CPU برای ارزیابی\n            data_test_y = data_test_y.detach().cpu().numpy()\n            predict_test_y = predict_test_y.detach().cpu().numpy()\n            \n            predict_test_y = predict_test_y.reshape(-1, data_test_y.shape[-1])\n            data_test_y = data_test_y.reshape(-1, data_test_y.shape[-1])\n            var_accuracy_test = accuracy_score(data_test_y.astype(int), predict_test_y.astype(int))\n        \n        print(f\"Epoch {var_epoch}/{var_epochs}\",\n              \"- %.6fs\"%(time.time() - var_time_e0),\n              \"- Loss %.6f\"%var_loss_train.cpu(),\n              \"- Accuracy %.6f\"%var_accuracy_train,\n              \"- Test Loss %.6f\"%var_loss_test.cpu(),\n              \"- Test Accuracy %.6f\"%var_accuracy_test)\n            \n        if var_accuracy_test > var_best_accuracy:\n            var_best_accuracy = var_accuracy_test\n            print('-----***-----')\n            print(var_best_accuracy)\n            var_best_weight = deepcopy(model.state_dict())\n\n    torch.save(model.state_dict(), f\"{name_run}_model_final.pt\")\n    torch.save(var_best_weight, f\"{name_run}_best_model.pt\")\n\n    \n    return var_best_weight\n\n\n\n# === importsِ لازم را یک‌بار بالای فایل اضافه کن ===\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib.backends.backend_pdf import PdfPages\nimport matplotlib.pyplot as plt\n\n# ---------- تابع کمکی ----------\ndef save_confusion_matrix(model, data_loader, threshold, device, pdf_path):\n    \"\"\"\n    Runs the model on `data_loader`, builds a confusion matrix and writes it to `pdf_path`.\n    \"\"\"\n    model.eval()\n    y_true, y_pred = [], []\n\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n\n            preds = (torch.sigmoid(logits) > threshold).float().cpu().numpy().ravel()\n            yb    = yb.cpu().numpy().ravel()\n\n            y_true.extend(yb)\n            y_pred.extend(preds)\n\n    cm  = confusion_matrix(y_true, y_pred)\n    fig, ax = plt.subplots()\n    ConfusionMatrixDisplay(cm).plot(ax=ax)\n    ax.set_title(\"Confusion Matrix – Test\")\n\n    with PdfPages(pdf_path) as pdf:\n        pdf.savefig(fig)\n    plt.close(fig)\n# ---------------------------------\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:02:00.157103Z","iopub.execute_input":"2025-05-04T22:02:00.157363Z","iopub.status.idle":"2025-05-04T22:02:00.180101Z","shell.execute_reply.started":"2025-05-04T22:02:00.157344Z","shell.execute_reply":"2025-05-04T22:02:00.179252Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\nCell 10: run.py\n---\n---","metadata":{}},{"cell_type":"code","source":"# \"\"\"\n# [file]          run.py\n# [description]   run WiFi-based models\n# \"\"\"\n\n# # All necessary libraries are imported in Cell 1.\n# # from model import *   --> Make sure the proper model functions (e.g., run_that) are defined in the respective cells.\n# # from preset import preset --> Already defined in Cell 2.\n# # from load_data import load_data_x, load_data_y, encode_data_y --> Defined in Cell 3.\n\n# def parse_args():\n#     var_args = argparse.ArgumentParser()\n#     var_args.add_argument(\"--model\", default=preset[\"model\"], type=str)\n#     var_args.add_argument(\"--task\", default=preset[\"task\"], type=str)\n#     var_args.add_argument(\"--repeat\", default=preset[\"repeat\"], type=int)\n#     args, _ = var_args.parse_known_args()  # پارامترهای اضافی نادیده گرفته می‌شن\n#     return args\n\n# def run():\n#     \"\"\"\n#     Run WiFi-based models.\n#     \"\"\"\n#     var_args = parse_args()\n#     var_task = var_args.task\n#     var_model = var_args.model\n#     var_repeat = var_args.repeat\n    \n#     data_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n#                             var_environment=preset[\"data\"][\"environment\"], \n#                             var_wifi_band=preset[\"data\"][\"wifi_band\"], \n#                             var_num_users=preset[\"data\"][\"num_users\"])\n#     var_label_list = data_pd_y[\"label\"].to_list()\n#     data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n#     data_y = encode_data_y(data_pd_y, var_task)\n#     print(\"========================1111111==========\")\n#     print(data_y[0])\n#     print(data_y[5])\n#     print(data_y[10])\n#     print(data_y.shape)\n#     print(\"==========================11111111========\")\n#     data_train_x, data_test_x, data_train_y, data_test_y = train_test_split(data_x, data_y, \n#                                                                             test_size=0.2, \n#                                                                             shuffle=True, \n#                                                                             random_state=39)\n#     print('-------------------------------------00000000-----')\n#     print(data_test_y[5])\n#     print(data_test_y[10])\n#     print(data_test_y[15])\n#     print('-------------------------------------00000000-----')\n#     if var_model == \"ST-RF\":\n#         run_model = run_strf\n#     elif var_model == \"LSTM\":\n#         run_model = run_lstm\n#     elif var_model == \"bi-LSTM\":\n#         run_model = run_bilstm\n#     elif var_model == \"THAT\":\n#         run_model = run_that\n#     elif var_model == \"ResNet18\":\n#         run_model = run_resnet\n        \n#     print(var_model)\n#     result = run_model(data_train_x, data_train_y, data_test_x, data_test_y, var_repeat)\n#     result[\"model\"] = var_model\n#     result[\"task\"] = var_task\n#     result[\"data\"] = preset[\"data\"]\n#     result[\"nn\"] = preset[\"nn\"]\n#     print(result)\n    \n#     with open(preset[\"path\"][\"save\"], 'w') as var_file:\n#         json.dump(result, var_file, indent=4)\n\n# if __name__ == \"__main__\":\n#     print('start')\n#     run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:02:00.180937Z","iopub.execute_input":"2025-05-04T22:02:00.181224Z","iopub.status.idle":"2025-05-04T22:02:00.199704Z","shell.execute_reply.started":"2025-05-04T22:02:00.181204Z","shell.execute_reply":"2025-05-04T22:02:00.198799Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport torch\ngc.collect()           \ntorch.cuda.empty_cache()  \ntorch.cuda.ipc_collect()  \n\n\n\n\n\"\"\"\n[file]          run.py\n[description]   run WiFi-based models and optionally save a multiclass confusion matrix\n\"\"\"\n\nimport argparse\nimport json\nimport torch\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib.backends.backend_pdf import PdfPages\n\n# from preset import preset, name_run\n# from load_data import load_data_x, load_data_y, encode_data_y\n# from lstm import run_lstm, LSTMM\n# from bilstm import run_bilstm, BiLSTMM\n# from that import run_that, THAT\n# from resnet import run_resnet, ResNet18Model\n# from strf import run_strf  # if you have the ST-RF implementation\n\ndef parse_args():\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"--model\",   default=preset[\"model\"],  type=str)\n    parser.add_argument(\"--task\",    default=preset[\"task\"],   type=str)\n    parser.add_argument(\"--repeat\",  default=preset[\"repeat\"], type=int)\n    parser.add_argument(\"--save_cm\", action=\"store_true\",\n                        help=\"Save a multiclass confusion matrix of the best model to PDF\")\n    args, _ = parser.parse_known_args()\n    return args\n\ndef save_multiclass_confusion_matrix(model, data_loader, device, pdf_path, num_classes):\n    \"\"\"\n    Given a model that outputs one-hot logits for a multiclass task,\n    convert to predicted classes via argmax, then plot and save a\n    num_classes × num_classes confusion matrix to pdf_path.\n    \"\"\"\n    model.eval()\n    y_true = []\n    y_pred = []\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            xb = xb.to(device)\n            logits = model(xb)\n            # predicted class is index of max logit\n            preds = torch.argmax(logits, dim=1).cpu().numpy()\n            trues = torch.argmax(yb, dim=1).cpu().numpy()\n            y_pred.extend(preds.tolist())\n            y_true.extend(trues.tolist())\n\n    labels = list(range(num_classes))\n    cm = confusion_matrix(y_true, y_pred, labels=labels)\n    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    disp.plot(ax=ax, xticks_rotation=\"vertical\")\n    ax.set_title(\"Confusion Matrix\")\n    with PdfPages(pdf_path) as pdf:\n        pdf.savefig(fig)\n    plt.close(fig)\n\ndef run():\n    args       = parse_args()\n    var_model  = args.model\n    var_task   = args.task\n    var_repeat = args.repeat\n\n    # --- Load and encode the data ---\n    data_pd_y = load_data_y(\n        preset[\"path\"][\"data_y\"],\n        var_environment=preset[\"data\"][\"environment\"],\n        var_wifi_band=preset[\"data\"][\"wifi_band\"],\n        var_num_users=preset[\"data\"][\"num_users\"]\n    )\n    labels = data_pd_y[\"label\"].tolist()\n    data_x = load_data_x(preset[\"path\"][\"data_x\"], labels)\n    data_y = encode_data_y(data_pd_y, var_task)\n\n    train_x, test_x, train_y, test_y = train_test_split(\n        data_x, data_y, test_size=0.2, shuffle=True, random_state=39\n    )\n\n    # --- Select which model runner to use ---\n    if var_model == \"ST-RF\":\n        from strf import run_strf\n        run_model = run_strf\n    elif var_model == \"LSTM\":\n        run_model = run_lstm\n    elif var_model == \"bi-LSTM\":\n        run_model = run_bilstm\n    elif var_model == \"THAT\":\n        run_model = run_that\n    elif var_model == \"ResNet18\":\n        run_model = run_resnet\n    else:\n        raise ValueError(f\"Unknown model: {var_model}\")\n\n    # --- Train and evaluate ---\n    print(f\"Running model: {var_model}\")\n    result = run_model(train_x, train_y, test_x, test_y, var_repeat)\n    result[\"model\"] = var_model\n    result[\"task\"]  = var_task\n    result[\"data\"]  = preset[\"data\"]\n    result[\"nn\"]    = preset[\"nn\"]\n    print(result)\n\n    # --- Save results to JSON ---\n    with open(preset[\"path\"][\"save\"], \"w\") as f:\n        json.dump(result, f, indent=4)\n\n    # --- Optionally save a multiclass confusion matrix ---\n    # if args.save_cm:\n    if Confusion_matrix == 1:\n        # 1) completely release GPU memory used for training\n        del run_model                      # if 'model' from training is still in scope\n        torch.cuda.empty_cache()\n        torch.cuda.ipc_collect()\n    \n        # 2) reshape input only if the network is sequence‑based\n        if var_model in (\"LSTM\", \"bi-LSTM\", \"THAT\"):\n            test_x_cm = test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n        else:                           # ResNet18, ST‑RF\n            test_x_cm = test_x\n    \n        # 3) build the *same* architecture on CPU and load its weights\n        device_cm = torch.device(\"cpu\")\n        if var_model == \"LSTM\":\n            model_cm = LSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"bi-LSTM\":\n            model_cm = BiLSTMM(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"THAT\":\n            model_cm = THAT(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        elif var_model == \"ResNet18\":\n            model_cm = ResNet18Model(test_x_cm[0].shape, test_y[0].shape).to(device_cm)\n        else:\n            raise ValueError(f\"Confusion matrix not supported for {var_model}\")\n    \n        best_path = f\"/kaggle/working/{name_run}_best_model.pt\"\n        model_cm.load_state_dict(torch.load(best_path, map_location=device_cm))\n        model_cm.eval()\n    \n        # 4) DataLoader on CPU with a safe batch size\n        test_ds = TensorDataset(torch.from_numpy(test_x_cm).float(),\n                                torch.from_numpy(test_y).float())\n        test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n    \n        # 5) save the confusion matrix PDF\n        num_classes = test_y.shape[1]\n        pdf_name = f\"{name_run}_confusion_matrix.pdf\"\n        save_multiclass_confusion_matrix(model_cm,test_loader,device_cm,pdf_name,num_classes)\n        print(f\"✅ Saved confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\nif __name__ == \"__main__\":\n    print(\"start\")\n    run()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:02:00.200672Z","iopub.execute_input":"2025-05-04T22:02:00.200981Z","iopub.status.idle":"2025-05-04T22:05:23.425474Z","shell.execute_reply.started":"2025-05-04T22:02:00.200952Z","shell.execute_reply":"2025-05-04T22:05:23.424677Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import gc\nimport torch\nimport shutil\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nfrom matplotlib.backends.backend_pdf import PdfPages\n\ngc.collect()           \ntorch.cuda.empty_cache()  \ntorch.cuda.ipc_collect()\n\n# ---------- helper: save multiclass confusion matrix ------------------\ndef save_multiclass_confusion_matrix(model, data_loader, pdf_path, num_classes):\n    \"\"\"\n    Forward‑pass on CPU, collect predictions, and write an N×N confusion matrix\n    to a single‑page PDF (pdf_path).\n    \"\"\"\n    model.eval()\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for xb, yb in data_loader:\n            logits = model(xb.cpu())                       # ensure CPU\n            preds  = torch.argmax(logits, dim=1).numpy()\n            trues  = torch.argmax(yb, dim=1).numpy()\n            y_pred.extend(preds.tolist())\n            y_true.extend(trues.tolist())\n\n    labels = list(range(num_classes))\n    cm  = confusion_matrix(y_true, y_pred, labels=labels)\n    disp = ConfusionMatrixDisplay(cm, display_labels=labels)\n    fig, ax = plt.subplots(figsize=(8, 8))\n    disp.plot(ax=ax, xticks_rotation=\"vertical\")\n    ax.set_title(\"Few‑shot Confusion Matrix\")\n    with PdfPages(pdf_path) as pdf:\n        pdf.savefig(fig)\n    plt.close(fig)\n\n# -------------------- pick run_* function ------------------------------\nif preset[\"model\"] == \"ST-RF\":\n    run_model = run_strf\nelif preset[\"model\"] == \"LSTM\":\n    run_model = run_lstm\nelif preset[\"model\"] == \"bi-LSTM\":\n    run_model = run_bilstm\nelif preset[\"model\"] == \"THAT\":\n    run_model = run_that\nelif preset[\"model\"] == \"ResNet18\":\n    run_model = run_resnet\nelse:\n    raise ValueError(f\"No few‑shot implementation for {preset['model']}.\")\n\n# ------------------------ load / split data ----------------------------\ndata_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n                        var_environment=[dest_env],\n                        var_wifi_band=preset[\"data\"][\"wifi_band\"],\n                        var_num_users=preset[\"data\"][\"num_users\"])\n\nlabels_list = data_pd_y[\"label\"].tolist()\ndata_x = load_data_x(preset[\"path\"][\"data_x\"], labels_list)\ndata_y = encode_data_y(data_pd_y, preset[\"task\"])\n\ntrain_x, test_x, train_y, test_y = train_test_split(\n    data_x, data_y, test_size=0.2, shuffle=True, random_state=39)\n\n# Few-shot sample size\ntrain_x = train_x[:few_shot_num_samples]\ntrain_y = train_y[:few_shot_num_samples]\n\n# ----------------------- few‑shot training -----------------------------\noriginal_epochs = preset[\"nn\"][\"epoch\"]\npreset[\"nn\"][\"epoch\"] = few_shot_epochs\n\n# Load the best model weights\nbest_model_path = f\"{name_run}_best_model.pt\"\n\n# Initialize the model\nif preset[\"model\"] == \"LSTM\":\n    model = LSTMM(train_x[0].shape, train_y[0].shape)  # Replace with your model initialization\nelif preset[\"model\"] == \"bi-LSTM\":\n    model = BiLSTMM(train_x[0].shape, train_y[0].shape)  # Replace with your model initialization\nelif preset[\"model\"] == \"THAT\":\n    model = THAT(train_x[0].shape, train_y[0].shape)  # Replace with your model initialization\nelif preset[\"model\"] == \"ResNet18\":\n    model = ResNet18Model(train_x[0].shape, train_y[0].shape)  # Replace with your model initialization\nelse:\n    raise ValueError(f\"Model {preset['model']} not supported!\")\n\n# Load the weights into the model\nmodel.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n\n# Fine-tune the model on few-shot data (note: `run_model` should now return only the result)\nresult = run_model(train_x, train_y, test_x, test_y, var_repeat=1)\nprint(result)\n\n# --------------------- save few‑shot checkpoints -----------------------\n# After fine-tuning, save the model\ntorch.save(model.state_dict(), f\"{name_run}_fewshot_final_model.pt\")\ntorch.save(model.state_dict(), f\"{name_run}_fewshot_best_model.pt\")\n\n# ------------------- confusion matrix on CPU ---------------------------\nif Confusion_matrix == 1 and preset[\"model\"] != \"ST-RF\":\n\n    # reshape for sequence models\n    test_x_rs = (test_x.reshape(test_x.shape[0], test_x.shape[1], -1)\n                 if preset[\"model\"] in (\"LSTM\", \"bi-LSTM\", \"THAT\") else test_x)\n\n    # instantiate identical architecture on CPU\n    if preset[\"model\"] == \"LSTM\":\n        model_cpu = LSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n    elif preset[\"model\"] == \"bi-LSTM\":\n        model_cpu = BiLSTMM(test_x_rs[0].shape, test_y[0].shape).cpu()\n    elif preset[\"model\"] == \"THAT\":\n        model_cpu = THAT(test_x_rs[0].shape, test_y[0].shape).cpu()\n    else:  # ResNet18\n        model_cpu = ResNet18Model(test_x_rs[0].shape, test_y[0].shape).cpu()\n\n    # load weights\n    model_cpu.load_state_dict(torch.load(f\"{name_run}_fewshot_best_model.pt\", map_location=\"cpu\"))\n\n    # CPU DataLoader with a safe batch size\n    test_ds = TensorDataset(torch.from_numpy(test_x_rs).float(),\n                            torch.from_numpy(test_y).float())\n    test_loader = DataLoader(test_ds, batch_size=64, shuffle=False)\n\n    pdf_name = f\"{name_run}_fewshot_confusion_matrix.pdf\"\n    num_classes = test_y.shape[1]\n    save_multiclass_confusion_matrix(model_cpu, test_loader, pdf_name, num_classes)\n    print(f\"✅ Saved few‑shot confusion matrix (classes 0–{num_classes-1}) to {pdf_name}\")\n\n# ----------------------- restore & persist -----------------------------\npreset[\"nn\"][\"epoch\"] = original_epochs\n\n# Save the final result to JSON\nwith open(\"result_fewshot.json\", \"w\") as f:\n    json.dump(result, f, indent=4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-04T22:09:25.431730Z","iopub.execute_input":"2025-05-04T22:09:25.432090Z","iopub.status.idle":"2025-05-04T22:11:43.460809Z","shell.execute_reply.started":"2025-05-04T22:09:25.432046Z","shell.execute_reply":"2025-05-04T22:11:43.459833Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}