{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238fea8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:40.172003Z",
     "iopub.status.busy": "2025-01-15T06:52:40.171654Z",
     "iopub.status.idle": "2025-01-15T06:52:44.754334Z",
     "shell.execute_reply": "2025-01-15T06:52:44.753299Z"
    },
    "papermill": {
     "duration": 4.588978,
     "end_time": "2025-01-15T06:52:44.755936",
     "exception": false,
     "start_time": "2025-01-15T06:52:40.166958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ptflops\r\n",
      "  Downloading ptflops-0.7.4-py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from ptflops) (2.4.1+cu121)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.16.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (3.1.4)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->ptflops) (2024.6.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->ptflops) (2.1.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->ptflops) (1.3.0)\r\n",
      "Downloading ptflops-0.7.4-py3-none-any.whl (19 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: ptflops\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed ptflops-0.7.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "251ac379",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:44.763707Z",
     "iopub.status.busy": "2025-01-15T06:52:44.763436Z",
     "iopub.status.idle": "2025-01-15T06:52:50.150260Z",
     "shell.execute_reply": "2025-01-15T06:52:50.149441Z"
    },
    "papermill": {
     "duration": 5.392232,
     "end_time": "2025-01-15T06:52:50.151855",
     "exception": false,
     "start_time": "2025-01-15T06:52:44.759623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import Swinv2Config, Swinv2ForImageClassification\n",
    "\n",
    "import torch\n",
    "# تنظیمات مدل Swinv2 برای ورودی تک‌کاناله و ۳۰ کلاس خروجی\n",
    "configuration = Swinv2Config(\n",
    "    num_channels=1,  # ورودی تک‌کاناله\n",
    "    num_labels=30,   # تعداد کلاس‌های خروجی\n",
    "    embed_dim=96,    # ابعاد تعبیه برای معماری 'tiny'\n",
    "    depths=[2, 2, 6, 2],  # عمق هر لایه در رمزگذار ترنسفورمر\n",
    "    num_heads=[3, 6, 12, 24],  # تعداد سرهای توجه در هر لایه\n",
    "    window_size=8,   # اندازه پنجره برای مکانیزم توجه\n",
    "    drop_path_rate=0.1,  # نرخ حذف مسیر برای منظم‌سازی\n",
    ")\n",
    "\n",
    "# ایجاد مدل Swinv2 با تنظیمات مشخص‌شده\n",
    "model = Swinv2ForImageClassification(configuration)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c2ec69e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:50.159356Z",
     "iopub.status.busy": "2025-01-15T06:52:50.158957Z",
     "iopub.status.idle": "2025-01-15T06:52:50.162217Z",
     "shell.execute_reply": "2025-01-15T06:52:50.161438Z"
    },
    "papermill": {
     "duration": 0.008232,
     "end_time": "2025-01-15T06:52:50.163508",
     "exception": false,
     "start_time": "2025-01-15T06:52:50.155276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "058df69b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:50.170395Z",
     "iopub.status.busy": "2025-01-15T06:52:50.170188Z",
     "iopub.status.idle": "2025-01-15T06:52:50.176926Z",
     "shell.execute_reply": "2025-01-15T06:52:50.176367Z"
    },
    "papermill": {
     "duration": 0.011582,
     "end_time": "2025-01-15T06:52:50.178081",
     "exception": false,
     "start_time": "2025-01-15T06:52:50.166499",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[file]          preset.py\n",
    "[description]   default settings of WiFi-based models\n",
    "\"\"\"\n",
    "#\n",
    "##\n",
    "preset = {\n",
    "    #\n",
    "    ## define model\n",
    "    \"model\": \"resnet\",                                    # \"ST-RF\", \"MLP\", \"LSTM\", \"CNN-1D\", \"CNN-2D\", \"CLSTM\", \"ABLSTM\", \"THAT\",\"Swin\"\n",
    "    #\n",
    "    ## define task\n",
    "    \"task\": \"location\",                                 # \"identity\", \"activity\", \"location\"\n",
    "    #\n",
    "    ## number of repeated experiments\n",
    "    \"repeat\": 2,\n",
    "    #\n",
    "\n",
    "    #\n",
    "    ## data selection for experiments\n",
    "    \"data\": {\n",
    "        \"num_users\": [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\"],    # select number(s) of users, (e.g., [\"0\", \"1\"], [\"2\", \"3\", \"4\", \"5\"])\n",
    "        \"wifi_band\": [\"2.4\"],                           # select WiFi band(s) (e.g., [\"2.4\"], [\"5\"], [\"2.4\", \"5\"])\n",
    "        \"environment\": [\"meeting_room\"],                   # select environment(s) (e.g., [\"classroom\"], [\"meeting_room\"], [\"empty_room\"])\n",
    "        \"length\": 3000,                                 # default length of CSI\n",
    "    },\n",
    "    #\n",
    "    ## hyperparameters of models\n",
    "    \"nn\": {\n",
    "        \"lr\": 1e-2,                                     # learning rate\n",
    "        \"epoch\": 120,                                   # number of epochs\n",
    "        \"batch_size\": 4,                              # batch size\n",
    "        \"threshold\": 0.5,                               # threshold to binarize sigmoid outputs\n",
    "    },\n",
    "## path of data\n",
    "    \"path\": {\n",
    "        \"data_x\": \"/kaggle/input/wimans/wifi_csi/amp\",               # directory of CSI amplitude files\n",
    "        \"data_y\": \"/kaggle/input/wimans/annotation.csv\",             # path of annotation file\n",
    "        \"save\": f\"result_swin_epoch=120_batchsize=4_envs=meeting_room_wifiband=2.4.json\"                           # path to save results\n",
    "    },\n",
    "    #\n",
    "    ## encoding of activities and locations\n",
    "    \"encoding\": {\n",
    "        \"activity\": {                                   # encoding of different activities\n",
    "            \"nan\":      [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"nothing\":  [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"walk\":     [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
    "            \"rotation\": [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "            \"jump\":     [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "            \"wave\":     [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "            \"lie_down\": [0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
    "            \"pick_up\":  [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
    "            \"sit_down\": [0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
    "            \"stand_up\": [0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
    "        },\n",
    "        \"location\": {                                   # encoding of different locations\n",
    "            \"nan\":  [0, 0, 0, 0, 0],\n",
    "            \"a\":    [1, 0, 0, 0, 0],\n",
    "            \"b\":    [0, 1, 0, 0, 0],\n",
    "            \"c\":    [0, 0, 1, 0, 0],\n",
    "            \"d\":    [0, 0, 0, 1, 0],\n",
    "            \"e\":    [0, 0, 0, 0, 1],\n",
    "        },\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c0d8e33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:50.184928Z",
     "iopub.status.busy": "2025-01-15T06:52:50.184729Z",
     "iopub.status.idle": "2025-01-15T06:52:51.679698Z",
     "shell.execute_reply": "2025-01-15T06:52:51.678991Z"
    },
    "papermill": {
     "duration": 1.500136,
     "end_time": "2025-01-15T06:52:51.681305",
     "exception": false,
     "start_time": "2025-01-15T06:52:50.181169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import device\n",
    "from torch.nn import Module\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "torch._dynamo.config.cache_size_limit = 65536\n",
    "\n",
    "\n",
    "def train(model: Module,\n",
    "          optimizer: Optimizer,\n",
    "          loss: Module,\n",
    "          data_train_set: TensorDataset,\n",
    "          data_test_set: TensorDataset,\n",
    "          var_threshold: float,\n",
    "          var_batch_size: int,\n",
    "          var_epochs: int,\n",
    "          device: device):\n",
    "    data_train_loader = DataLoader(data_train_set, var_batch_size, shuffle=True, pin_memory=True)\n",
    "    data_test_loader = DataLoader(data_test_set, var_batch_size)\n",
    "\n",
    "    var_best_accuracy = 0\n",
    "    var_best_weight = None\n",
    "\n",
    "    # شمارنده‌ای برای بررسی عدم بهبود در دقت تست\n",
    "    no_improvement_epochs = 0\n",
    "\n",
    "    for var_epoch in tqdm(range(var_epochs)):\n",
    "        # --------------------------\n",
    "        # Training\n",
    "        # --------------------------\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        total_train_accuracy = 0\n",
    "        train_batches = 0\n",
    "\n",
    "        for batch_index, data_batch in enumerate(data_train_loader):\n",
    "            data_batch_x, data_batch_y = data_batch\n",
    "            data_batch_x = data_batch_x.to(device)\n",
    "            data_batch_y = data_batch_y.to(device)\n",
    "\n",
    "            predict_train_y = model(data_batch_x)[\"logits\"]\n",
    "            \n",
    "            var_loss_train = loss(predict_train_y, data_batch_y.reshape(data_batch_y.shape[0], -1).float())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            var_loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate batch accuracy\n",
    "            predict_train_y = (torch.sigmoid(predict_train_y) > var_threshold).float()\n",
    "            data_batch_y = data_batch_y.detach().cpu().numpy()\n",
    "            predict_train_y = predict_train_y.detach().cpu().numpy()\n",
    "            predict_train_y = predict_train_y.reshape(-1, data_batch_y.shape[-1])\n",
    "            data_batch_y = data_batch_y.reshape(-1, data_batch_y.shape[-1])\n",
    "            batch_accuracy = accuracy_score(data_batch_y.astype(float), predict_train_y.astype(float))\n",
    "\n",
    "            total_train_loss += var_loss_train.item()\n",
    "            total_train_accuracy += batch_accuracy\n",
    "            train_batches += 1\n",
    "\n",
    "            # print(\n",
    "            #     f\"Epoch {var_epoch + 1}, Batch {batch_index + 1}/{len(data_train_loader)}, Batch Accuracy: {batch_accuracy:.6f}\"\n",
    "            # )\n",
    "\n",
    "        # Calculate average training accuracy and loss\n",
    "        average_train_loss = total_train_loss / train_batches\n",
    "        average_train_accuracy = total_train_accuracy / train_batches\n",
    "        print(\n",
    "            f\"Epoch {var_epoch}/{var_epochs} - Average Training Loss: {average_train_loss:.6f} - \"\n",
    "            f\"Average Training Accuracy: {average_train_accuracy:.6f}\"\n",
    "        )\n",
    "\n",
    "        # --------------------------\n",
    "        # Testing\n",
    "        # --------------------------\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "        total_test_accuracy = 0\n",
    "        test_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data_batch in data_test_loader:\n",
    "                data_test_x, data_test_y = data_batch\n",
    "                data_test_x = data_test_x.to(device)\n",
    "                data_test_y = data_test_y.to(device)\n",
    "\n",
    "                predict_test_y = model(data_test_x)[\"logits\"]\n",
    "                var_loss_test = loss(predict_test_y, data_test_y.reshape(data_test_y.shape[0], -1).float())\n",
    "                predict_test_y = (torch.sigmoid(predict_test_y) > var_threshold).float()\n",
    "\n",
    "                data_test_y = data_test_y.detach().cpu().numpy()\n",
    "                predict_test_y = predict_test_y.detach().cpu().numpy()\n",
    "                predict_test_y = predict_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "                data_test_y = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "\n",
    "                batch_accuracy = accuracy_score(data_test_y.astype(float), predict_test_y.astype(float))\n",
    "                total_test_loss += var_loss_test.item()\n",
    "                total_test_accuracy += batch_accuracy\n",
    "                test_batches += 1\n",
    "\n",
    "                # print(\n",
    "                #     f\"Epoch {var_epoch}/{var_epochs} - Test Loss: {var_loss_test.cpu().item():.6f} - Test Accuracy: {batch_accuracy:.6f}\"\n",
    "                # )\n",
    "\n",
    "        # Calculate average testing accuracy and loss\n",
    "        average_test_loss = total_test_loss / test_batches\n",
    "        average_test_accuracy = total_test_accuracy / test_batches\n",
    "        print(\n",
    "            f\"Epoch {var_epoch}/{var_epochs} - Average Test Loss: {average_test_loss:.6f} - \"\n",
    "            f\"Average Test Accuracy: {average_test_accuracy:.6f}\"\n",
    "        )\n",
    "        print('---***---')\n",
    "\n",
    "        # --------------------------\n",
    "        # بررسی بهترین دقت تست\n",
    "        # --------------------------\n",
    "        if average_test_accuracy > var_best_accuracy:\n",
    "            var_best_accuracy = average_test_accuracy\n",
    "            var_best_weight = deepcopy(model.state_dict())\n",
    "            torch.save(var_best_weight, 'best_swin_epoch=120_batchsize=4_envs=meeting_room_wifiband=2.4.pth')\n",
    "            print(f\"New best model saved with accuracy: {var_best_accuracy:.6f}\")\n",
    "            print('---------------------------***---------------------------')\n",
    "\n",
    "            # اگر مدل بهتر شده بود، شمارنده‌ی عدم بهبود را صفر می‌کنیم\n",
    "            no_improvement_epochs = 0\n",
    "        else:\n",
    "            # اگر مدل بهتر نشد، شمارنده را افزایش می‌دهیم\n",
    "            no_improvement_epochs += 1\n",
    "\n",
    "            # اگر 10 اپوک متوالی دقت تست بهبود پیدا نکرد، لرنینگ ریت را کاهش بده\n",
    "            if no_improvement_epochs == 10:\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] *= 0.1  # این ضریب را می‌توانید به دلخواه تغییر دهید\n",
    "                print(f\"Learning rate decreased to {optimizer.param_groups[0]['lr']}\")\n",
    "                no_improvement_epochs = 0\n",
    "\n",
    "    return var_best_weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79f805af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:51.688673Z",
     "iopub.status.busy": "2025-01-15T06:52:51.688311Z",
     "iopub.status.idle": "2025-01-15T06:52:51.734437Z",
     "shell.execute_reply": "2025-01-15T06:52:51.733792Z"
    },
    "papermill": {
     "duration": 0.051468,
     "end_time": "2025-01-15T06:52:51.736074",
     "exception": false,
     "start_time": "2025-01-15T06:52:51.684606",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[file]          preprocess.py\n",
    "[description]   preprocess WiFi CSI data\n",
    "\"\"\"\n",
    "#\n",
    "##\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "\n",
    "#\n",
    "##\n",
    "def mat_to_amp(data_mat):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : calculate amplitude of raw WiFi CSI data\n",
    "    [parameter]\n",
    "    : data_mat: dict, raw WiFi CSI data from *.mat files\n",
    "    [return]\n",
    "    : data_csi_amp: numpy array, CSI amplitude\n",
    "    \"\"\"\n",
    "    #\n",
    "    ## \n",
    "    var_length = data_mat[\"trace\"].shape[0]\n",
    "    #\n",
    "    data_csi_amp = [abs(data_mat[\"trace\"][var_t][0][0][0][-1]) for var_t in range(var_length)]\n",
    "    #\n",
    "    data_csi_amp = np.array(data_csi_amp, dtype = np.float32)\n",
    "    #\n",
    "    return data_csi_amp\n",
    "\n",
    "#\n",
    "##\n",
    "def extract_csi_amp(var_dir_mat, \n",
    "                    var_dir_amp):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : read raw WiFi CSI files (*.mat), calcuate CSI amplitude, and save amplitude (*.npy)\n",
    "    [parameter]\n",
    "    : var_dir_mat: string, directory to read raw WiFi CSI files (*.mat)\n",
    "    : var_dir_amp: string, directory to save WiFi CSI amplitude (*.npy)\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    var_path_mat = os.listdir(var_dir_mat)\n",
    "    #\n",
    "    for var_c, var_path in enumerate(var_path_mat):\n",
    "        #\n",
    "        data_mat = scio.loadmat(os.path.join(var_dir_mat, var_path))\n",
    "        #\n",
    "        data_csi_amp = mat_to_amp(data_mat)\n",
    "        #\n",
    "        print(var_c, data_csi_amp.shape)\n",
    "        #\n",
    "        var_path_save = os.path.join(var_dir_amp, var_path.replace(\".mat\", \".npy\"))\n",
    "        #\n",
    "        with open(var_path_save, \"wb\") as var_file:\n",
    "            np.save(var_file, data_csi_amp)\n",
    "\n",
    "#\n",
    "##\n",
    "\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6c24b7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:51.743235Z",
     "iopub.status.busy": "2025-01-15T06:52:51.742963Z",
     "iopub.status.idle": "2025-01-15T06:52:52.485803Z",
     "shell.execute_reply": "2025-01-15T06:52:52.485090Z"
    },
    "papermill": {
     "duration": 0.748146,
     "end_time": "2025-01-15T06:52:52.487438",
     "exception": false,
     "start_time": "2025-01-15T06:52:51.739292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[file]          load_data.py\n",
    "[description]   load annotation file and CSI amplitude, and encode labels\n",
    "\"\"\"\n",
    "#\n",
    "##\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#\n",
    "\n",
    "#\n",
    "##\n",
    "def load_data_y(var_path_data_y,\n",
    "                var_environment = None, \n",
    "                var_wifi_band = None, \n",
    "                var_num_users = None):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : load annotation file (*.csv) as a pandas dataframe\n",
    "    : according to selected environment(s), WiFi band(s), and number(s) of users\n",
    "    [parameter]\n",
    "    : var_path_data_y: string, path of annotation file\n",
    "    : var_environment: list, selected environment(s), e.g., [\"classroom\"]\n",
    "    : var_wifi_band: list, selected WiFi band(s), e.g., [\"2.4\"]\n",
    "    : var_num_users: list, selected number(s) of users, e.g., [\"0\", \"1\", \"2\"]\n",
    "    [return]\n",
    "    : data_pd_y: pandas dataframe, labels of selected data\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_pd_y = pd.read_csv(var_path_data_y, dtype = str)\n",
    "    #\n",
    "    if var_environment is not None:\n",
    "        data_pd_y = data_pd_y[data_pd_y[\"environment\"].isin(var_environment)]\n",
    "    #\n",
    "    if var_wifi_band is not None:\n",
    "        data_pd_y = data_pd_y[data_pd_y[\"wifi_band\"].isin(var_wifi_band)]\n",
    "    #\n",
    "    if var_num_users is not None:\n",
    "        data_pd_y = data_pd_y[data_pd_y[\"number_of_users\"].isin(var_num_users)]\n",
    "    #\n",
    "    return data_pd_y\n",
    "\n",
    "#\n",
    "##\n",
    "def load_data_x(var_path_data_x, \n",
    "                var_label_list):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : load CSI amplitude (*.npy)\n",
    "    : according to a label list of selected data\n",
    "    [parameter]\n",
    "    : var_path_data_x: string, directory of CSI amplitude files\n",
    "    : var_label_list: list, selected labels\n",
    "    [return]\n",
    "    : data_x: numpy array, CSI amplitude\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    var_path_list = [os.path.join(var_path_data_x, var_label + \".npy\") for var_label in var_label_list]\n",
    "    #\n",
    "    data_x = []\n",
    "    #\n",
    "    for var_path in var_path_list:\n",
    "        #\n",
    "        data_csi = np.load(var_path)\n",
    "        #\n",
    "        var_pad_length = preset[\"data\"][\"length\"] - data_csi.shape[0]\n",
    "        #\n",
    "        data_csi_pad = np.pad(data_csi, ((var_pad_length, 0), (0, 0), (0, 0), (0, 0)))\n",
    "        #\n",
    "        data_x.append(data_csi_pad)\n",
    "    #\n",
    "    data_x = np.array(data_x)\n",
    "    #\n",
    "    return data_x\n",
    "\n",
    "#\n",
    "##\n",
    "def encode_data_y(data_pd_y, \n",
    "                  var_task):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : encode labels according to specific task\n",
    "    [parameter]\n",
    "    : data_pd_y: pandas dataframe, labels of different tasks\n",
    "    : var_task: string, indicate task\n",
    "    [return]\n",
    "    : data_y: numpy array, label encoding of task\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    if var_task == \"identity\":\n",
    "        #\n",
    "        data_y = encode_identity(data_pd_y)\n",
    "    #\n",
    "    elif var_task == \"activity\":\n",
    "        #\n",
    "        data_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "    #\n",
    "    elif var_task == \"location\":\n",
    "        #\n",
    "        data_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "    #\n",
    "    return data_y\n",
    "\n",
    "#\n",
    "##\n",
    "def encode_identity(data_pd_y):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : encode identity labels in a pandas dataframe\n",
    "    [parameter]\n",
    "    : data_pd_y: pandas dataframe, labels of different tasks\n",
    "    [return]\n",
    "    : data_identity_onehot_y: numpy array, onehot encoding for identity labels\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "                                    \"user_3_location\", \"user_4_location\", \n",
    "                                    \"user_5_location\", \"user_6_location\"]]\n",
    "    # \n",
    "    data_identity_y = data_location_pd_y.to_numpy(copy = True).astype(str)\n",
    "    #\n",
    "    data_identity_y[data_identity_y != \"nan\"] = 1\n",
    "    data_identity_y[data_identity_y == \"nan\"] = 0\n",
    "    #\n",
    "    data_identity_onehot_y = data_identity_y.astype(\"int8\")\n",
    "    #\n",
    "    return data_identity_onehot_y\n",
    "\n",
    "#\n",
    "##\n",
    "def encode_activity(data_pd_y, \n",
    "                    var_encoding):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : encode activity labels in a pandas dataframe\n",
    "    [parameter]\n",
    "    : data_pd_y: pandas dataframe, labels of different tasks\n",
    "    : var_encoding: dict, encoding of different activities\n",
    "    [return]\n",
    "    : data_activity_onehot_y: numpy array, onehot encoding for activity labels\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_activity_pd_y = data_pd_y[[\"user_1_activity\", \"user_2_activity\", \n",
    "                                    \"user_3_activity\", \"user_4_activity\", \n",
    "                                    \"user_5_activity\", \"user_6_activity\"]]\n",
    "    #\n",
    "    data_activity_y = data_activity_pd_y.to_numpy(copy = True).astype(str)\n",
    "    #\n",
    "    data_activity_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_activity_y])\n",
    "    #\n",
    "    return data_activity_onehot_y\n",
    "\n",
    "#\n",
    "##\n",
    "def encode_location(data_pd_y, \n",
    "                    var_encoding):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : encode location labels in a pandas dataframe\n",
    "    [parameter]\n",
    "    : data_pd_y: pandas dataframe, labels of different tasks\n",
    "    : var_encoding: dict, encoding of different locations\n",
    "    [return]\n",
    "    : data_location_onehot_y: numpy array, onehot encoding for location labels\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_location_pd_y = data_pd_y[[\"user_1_location\", \"user_2_location\", \n",
    "                                    \"user_3_location\", \"user_4_location\", \n",
    "                                    \"user_5_location\", \"user_6_location\"]]\n",
    "    #\n",
    "    data_location_y = data_location_pd_y.to_numpy(copy = True).astype(str)\n",
    "    #\n",
    "    data_location_onehot_y = np.array([[var_encoding[var_y] for var_y in var_sample] for var_sample in data_location_y])\n",
    "    #\n",
    "    return data_location_onehot_y\n",
    "\n",
    "#\n",
    "##\n",
    "def test_load_data_y():\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : test load_data_y() function\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    print(load_data_y(preset[\"path\"][\"data_y\"], \n",
    "                      var_environment = [\"classroom\"]).describe())\n",
    "    #\n",
    "    print(load_data_y(preset[\"path\"][\"data_y\"], \n",
    "                      var_environment = [\"meeting_room\"], \n",
    "                      var_wifi_band = [\"2.4\"]).describe())\n",
    "    #\n",
    "    print(load_data_y(preset[\"path\"][\"data_y\"], \n",
    "                      var_environment = [\"meeting_room\"], \n",
    "                      var_wifi_band = [\"2.4\"], \n",
    "                      var_num_users = [\"1\", \"2\", \"3\"]).describe())\n",
    "\n",
    "#\n",
    "##\n",
    "def test_load_data_x():\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : test load_data_x() function\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n",
    "                            var_environment = [\"meeting_room\"], \n",
    "                            var_wifi_band = [\"2.4\"], \n",
    "                            var_num_users = None)\n",
    "    #\n",
    "    var_label_list = data_pd_y[\"label\"].to_list()\n",
    "    #\n",
    "    data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n",
    "    #\n",
    "    print(data_x.shape)\n",
    "\n",
    "#\n",
    "##\n",
    "def test_encode_identity():\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : test encode_identity() function\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype = str)\n",
    "    #\n",
    "    data_identity_onehot_y = encode_identity(data_pd_y)\n",
    "    #\n",
    "    print(data_identity_onehot_y.shape)\n",
    "    #\n",
    "    print(data_identity_onehot_y[2000])\n",
    "\n",
    "#\n",
    "##\n",
    "def test_encode_activity():\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : test encode_activity() function\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype = str)\n",
    "    #\n",
    "    data_activity_onehot_y = encode_activity(data_pd_y, preset[\"encoding\"][\"activity\"])\n",
    "    #\n",
    "    print(data_activity_onehot_y.shape)\n",
    "    #\n",
    "    print(data_activity_onehot_y[1560])\n",
    "\n",
    "#\n",
    "##\n",
    "def test_encode_location():\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : test encode_location() function\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    data_pd_y = pd.read_csv(preset[\"path\"][\"data_y\"], dtype = str)\n",
    "    #\n",
    "    data_location_onehot_y = encode_location(data_pd_y, preset[\"encoding\"][\"location\"])\n",
    "    #\n",
    "    print(data_location_onehot_y.shape)\n",
    "    #\n",
    "    print(data_location_onehot_y[1560])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0c498cc",
   "metadata": {
    "_cell_guid": "01510161-47b0-4a61-abe2-679533b9e5e5",
    "_uuid": "39c5fb7b-cc9c-46a8-b98c-be21120c0f13",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:52.495277Z",
     "iopub.status.busy": "2025-01-15T06:52:52.494843Z",
     "iopub.status.idle": "2025-01-15T06:52:55.098050Z",
     "shell.execute_reply": "2025-01-15T06:52:55.097372Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.608768,
     "end_time": "2025-01-15T06:52:55.099627",
     "exception": false,
     "start_time": "2025-01-15T06:52:52.490859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[file]          run.py\n",
    "[description]   run WiFi-based models\n",
    "\"\"\"\n",
    "#\n",
    "##\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "#\n",
    "from torch.utils.data import TensorDataset\n",
    "from ptflops import get_model_complexity_info\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "#\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##\n",
    "def parse_args():\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : parse arguments from input\n",
    "    \"\"\"\n",
    "    #\n",
    "    ##\n",
    "    var_args = argparse.ArgumentParser()\n",
    "    #\n",
    "    var_args.add_argument(\"--model\", default = preset[\"model\"], type = str)\n",
    "    var_args.add_argument(\"--task\", default = preset[\"task\"], type = str)\n",
    "    var_args.add_argument(\"--repeat\", default = preset[\"repeat\"], type = int)\n",
    "    #\n",
    "    return var_args.parse_args()\n",
    "\n",
    "\n",
    "def run_resnet(data_train_x,\n",
    "             data_train_y,\n",
    "             data_test_x,\n",
    "             data_test_y,\n",
    "             var_repeat=10):\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : run model (ResNet18 instead of THAT) for WiFi-based classification\n",
    "\n",
    "    [parameter]\n",
    "    : data_train_x: numpy array, CSI amplitude to train model  -> shape: (N, T, F)\n",
    "    : data_train_y: numpy array, labels to train model        -> shape: (N, #classes) (یا (N,) در صورت تک‌خروجی)\n",
    "    : data_test_x:  numpy array, CSI amplitude to test model  -> shape: (M, T, F)\n",
    "    : data_test_y:  numpy array, labels to test model         -> shape: (M, #classes)\n",
    "    : var_repeat:   int, number of repeated experiments\n",
    "\n",
    "    [return]\n",
    "    : result: dict, results of experiments\n",
    "    \"\"\"\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # ================================ Preprocess ================================\n",
    "    # reshape data for ResNet: (batch, 1, time, feature)\n",
    "    data_train_x = data_train_x.reshape(data_train_x.shape[0], 1, data_train_x.shape[1], data_train_x.shape[2]*data_train_x.shape[3]*data_train_x.shape[4])\n",
    "    data_test_x  = data_test_x.reshape(data_test_x.shape[0], 1, data_test_x.shape[1], data_test_x.shape[2]*data_test_x.shape[3]*data_test_x.shape[4])\n",
    "\n",
    "    # در نسخه‌های قدیمی torchvision که از in_chans پشتیبانی نمی‌کند، برای سازگاری با مدل Swin\n",
    "    # باید کانال ورودی از 1 به 3 تکرار شود (تبدیل به [batch, 3, ...]).\n",
    "    # این کار هیچ دیتایی را حذف نمی‌کند، بلکه همان کانال را تکرار می‌کند.\n",
    "\n",
    "\n",
    "    # ساخت دیتاست\n",
    "    data_train_set = TensorDataset(torch.from_numpy(data_train_x).float(),\n",
    "                                   torch.from_numpy(data_train_y).float())\n",
    "    data_test_set  = TensorDataset(torch.from_numpy(data_test_x).float(),\n",
    "                                   torch.from_numpy(data_test_y).float())\n",
    "\n",
    "    # مشخص کردن shape ورودی و خروجی\n",
    "    var_x_shape = data_train_x[0].shape  # (3, time, feature)  بعد از تکرار کانال‌ها\n",
    "    var_y_shape = data_train_y[0].reshape(-1).shape  # (num_of_classes, )\n",
    "\n",
    "    # ================================ تعریف مدل (Swin به جای ResNet18) ================================\n",
    "    # 1) ساخت مدل Swin (به جای ResNet18)\n",
    "    # توجه کنید که چون نسخه‌های قدیمی torchvision به in_chans پشتیبانی نمی‌دهند،\n",
    "    # از پارامتر in_chans=1 صرف‌نظر و صرفاً ورودی را سه‌کاناله می‌کنیم.\n",
    "    model_resnet = model\n",
    "\n",
    "    # 2) تغییر لایه‌ی ورودی (conv1) مخصوص ResNet بود، در Swin این بخش نیاز به دستکاری ندارد.\n",
    "    # model_resnet.conv1 = torch.nn.Conv2d(\n",
    "    #     in_channels=1,\n",
    "    #     out_channels=64,\n",
    "    #     kernel_size=7,\n",
    "    #     stride=2,\n",
    "    #     padding=3,\n",
    "    #     bias=False\n",
    "    # )\n",
    "    print\n",
    "    # 3) تغییر خروجی نهایی (fc) تا به تعداد کلاس‌های ما باشد:\n",
    "    out_features_fc = var_y_shape[-1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # =========================== Train & Evaluate ===========================\n",
    "    result = {}\n",
    "    result_accuracy = []\n",
    "    result_time_train = []\n",
    "    result_time_test = []\n",
    "\n",
    "    for var_r in range(var_repeat):\n",
    "        print(\"Repeat\", var_r)\n",
    "\n",
    "        # برای تکرارپذیری\n",
    "        torch.random.manual_seed(var_r + 39)\n",
    "\n",
    "        # کپی تازه از مدل برای هر تکرار\n",
    "        model_resnet_loop = model\n",
    "        # model_resnet_loop.conv1 = torch.nn.Conv2d(\n",
    "        #     in_channels=1,\n",
    "        #     out_channels=64,\n",
    "        #     kernel_size=7,\n",
    "        #     stride=2,\n",
    "        #     padding=3,\n",
    "        #     bias=False\n",
    "        # )\n",
    "\n",
    "        # انتقال به GPU/CPU\n",
    "        model_resnet_loop = model_resnet_loop.to(device)\n",
    "\n",
    "        # تعریف بهینه‌ساز\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model_resnet_loop.parameters(),\n",
    "            lr=preset[\"nn\"][\"lr\"],\n",
    "            weight_decay=0\n",
    "        )\n",
    "\n",
    "        # اگر مسئله‌ی شما Multi-Label باشد از BCEWithLogitsLoss استفاده می‌شود\n",
    "        # اگر Multi-Class (با softmax) باشد از CrossEntropyLoss استفاده کنید.\n",
    "        loss_func = torch.nn.BCEWithLogitsLoss(\n",
    "            pos_weight=torch.tensor([4] * out_features_fc).to(device)\n",
    "        )\n",
    "  \n",
    "        var_time_0 = time.time()\n",
    "\n",
    "        # -------------------------------- Train --------------------------------\n",
    "        var_best_weight = train(\n",
    "            model=model_resnet_loop,\n",
    "            optimizer=optimizer,\n",
    "            loss=loss_func,\n",
    "            data_train_set=data_train_set,\n",
    "            data_test_set=data_test_set,\n",
    "            var_threshold=preset[\"nn\"][\"threshold\"],\n",
    "            var_batch_size=preset[\"nn\"][\"batch_size\"],\n",
    "            var_epochs=preset[\"nn\"][\"epoch\"],\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        var_time_1 = time.time()\n",
    "\n",
    "        # -------------------------------- Test ---------------------------------\n",
    "        model_resnet_loop.load_state_dict(var_best_weight)\n",
    "        model_resnet_loop.eval()  # Set the model to evaluation mode\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predict_test_y_list = []\n",
    "            data_test_y_list = []\n",
    "\n",
    "            for data_batch in DataLoader(data_test_set, batch_size=preset[\"nn\"][\"batch_size\"], shuffle=False):\n",
    "                data_test_x, data_test_y = data_batch\n",
    "                data_test_x = data_test_x.to(device)\n",
    "                data_test_y = data_test_y.to(device)\n",
    "\n",
    "                predict_test_y = model_resnet_loop(data_test_x)[\"logits\"]\n",
    "                predict_test_y = torch.sigmoid(predict_test_y)  # Apply sigmoid for BCEWithLogitsLoss\n",
    "                predict_test_y_list.append(predict_test_y.cpu().numpy())\n",
    "                data_test_y_list.append(data_test_y.cpu().numpy())\n",
    "\n",
    "            # Concatenate results\n",
    "            predict_test_y = np.vstack(predict_test_y_list)\n",
    "            data_test_y = np.vstack(data_test_y_list)\n",
    "\n",
    "            # Apply thresholding\n",
    "            predict_test_y = (predict_test_y > preset[\"nn\"][\"threshold\"]).astype(float)\n",
    "\n",
    "        var_time_2 = time.time()\n",
    "\n",
    "        # ------------------------------- Evaluate -------------------------------\n",
    "        data_test_y_c = data_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "        predict_test_y_c = predict_test_y.reshape(-1, data_test_y.shape[-1])\n",
    "\n",
    "        # Accuracy\n",
    "        result_acc = accuracy_score(\n",
    "            data_test_y_c.astype(int),\n",
    "            predict_test_y_c.astype(int)\n",
    "        )\n",
    "\n",
    "        # classification report\n",
    "        result_dict = classification_report(\n",
    "            data_test_y_c,\n",
    "            predict_test_y_c,\n",
    "            digits=6,\n",
    "            zero_division=0,\n",
    "            output_dict=True\n",
    "        )\n",
    "\n",
    "        result[f\"repeat_{var_r}\"] = result_dict\n",
    "\n",
    "        result_accuracy.append(result_acc)\n",
    "        result_time_train.append(var_time_1 - var_time_0)\n",
    "        result_time_test.append(var_time_2 - var_time_1)\n",
    "\n",
    "        print(\"repeat_\", var_r, result_accuracy)\n",
    "        print(result)\n",
    "\n",
    "    # جمع‌بندی نتایج تکرارها\n",
    "    result[\"accuracy\"] = {\"avg\": np.mean(result_accuracy), \"std\": np.std(result_accuracy)}\n",
    "    result[\"time_train\"] = {\"avg\": np.mean(result_time_train), \"std\": np.std(result_time_train)}\n",
    "    result[\"time_test\"] = {\"avg\": np.mean(result_time_test), \"std\": np.std(result_time_test)}\n",
    "    result[\"complexity\"] = {\"parameter\": var_params, \"flops\": var_macs * 2}\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "##\n",
    "def run():\n",
    "    \"\"\"\n",
    "    [description]\n",
    "    : run WiFi-based models\n",
    "    \"\"\"\n",
    "    #\n",
    "    ## parse arguments from input\n",
    "\n",
    "    #\n",
    "    var_task = \"location\"\n",
    "    var_model = \"resnet\"\n",
    "    var_repeat = 2\n",
    "    #\n",
    "    ## load annotation file as labels\n",
    "    data_pd_y = load_data_y(preset[\"path\"][\"data_y\"],\n",
    "                            var_environment = preset[\"data\"][\"environment\"],\n",
    "                            var_wifi_band = preset[\"data\"][\"wifi_band\"],\n",
    "                            var_num_users = preset[\"data\"][\"num_users\"])\n",
    "    #\n",
    "    var_label_list = data_pd_y[\"label\"].to_list()\n",
    "    #\n",
    "    ## load CSI amplitude\n",
    "    data_x = load_data_x(preset[\"path\"][\"data_x\"], var_label_list)\n",
    "    #\n",
    "    ## encode labels\n",
    "    data_y = encode_data_y(data_pd_y, var_task)\n",
    "    #\n",
    "    ## a training set (80%) and a test set (20%)\n",
    "    data_train_x, data_test_x, data_train_y, data_test_y = train_test_split(data_x, data_y,\n",
    "                                                                            test_size = 0.2,\n",
    "                                                                            shuffle = True,\n",
    "                                                                            random_state = 39)\n",
    "    print(var_model)\n",
    "    #\n",
    "    ## select a WiFi-based model\n",
    "    # if var_model == \"ST-RF\": run_model = run_strf\n",
    "    #\n",
    "    # if var_model == \"MLP\": run_model = run_mlp\n",
    "    # if var_model == \"swin\": run_model = run_mlp\n",
    "    #\n",
    "    # if var_model == \"LSTM\": run_model = run_lstm\n",
    "    # #\n",
    "    # elif var_model == \"CNN-1D\": run_model = run_cnn_1d\n",
    "    # #\n",
    "    # if var_model == \"CNN-2D\": run_model = run_cnn_2d\n",
    "    ##\n",
    "    if var_model == \"resnet\":\n",
    "        run_model = run_resnet\n",
    "    # #\n",
    "    # elif var_model == \"CLSTM\": run_model = run_cnn_lstm\n",
    "    # #\n",
    "    # elif var_model == \"ABLSTM\": run_model = run_ablstm\n",
    "    # #\n",
    "    # elif var_model == \"THAT\": run_model = run_that\n",
    "    #\n",
    "    ## run WiFi-based model\n",
    "    result = run_model(data_train_x, data_train_y,\n",
    "                       data_test_x, data_test_y, var_repeat)\n",
    "    #\n",
    "    ##\n",
    "    result[\"model\"] = var_model\n",
    "    result[\"task\"] = var_task\n",
    "    result[\"data\"] = preset[\"data\"]\n",
    "    result[\"nn\"] = preset[\"nn\"]\n",
    "    #\n",
    "    print(result)\n",
    "    #\n",
    "    ## save results\n",
    "    var_file = open(preset[\"path\"][\"save\"], 'w')\n",
    "    json.dump(result, var_file, indent = 4)\n",
    "\n",
    "#\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55d479b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-15T06:52:55.106872Z",
     "iopub.status.busy": "2025-01-15T06:52:55.106643Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-01-15T06:52:55.103014",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet\n",
      "Repeat 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/120 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/120 - Average Training Loss: 0.950170 - Average Training Accuracy: 0.397717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 1/120 [04:25<8:46:12, 265.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/120 - Average Test Loss: 0.747765 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "New best model saved with accuracy: 0.566667\n",
      "---------------------------***---------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120 - Average Training Loss: 0.738889 - Average Training Accuracy: 0.574801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 2/120 [08:49<8:40:11, 264.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120 - Average Test Loss: 0.746328 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120 - Average Training Loss: 0.737804 - Average Training Accuracy: 0.574136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▎         | 3/120 [13:13<8:35:17, 264.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/120 - Average Test Loss: 0.736420 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/120 - Average Training Loss: 0.738644 - Average Training Accuracy: 0.574579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 4/120 [17:37<8:30:45, 264.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/120 - Average Test Loss: 0.760532 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/120 - Average Training Loss: 0.735277 - Average Training Accuracy: 0.580895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 5/120 [22:01<8:26:16, 264.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/120 - Average Test Loss: 0.742894 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/120 - Average Training Loss: 0.736499 - Average Training Accuracy: 0.578457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 6/120 [26:25<8:21:45, 264.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/120 - Average Test Loss: 0.740830 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/120 - Average Training Loss: 0.737371 - Average Training Accuracy: 0.579233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▌         | 7/120 [30:49<8:17:22, 264.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/120 - Average Test Loss: 0.746724 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/120 - Average Training Loss: 0.734704 - Average Training Accuracy: 0.580785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 8/120 [35:13<8:12:56, 264.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/120 - Average Test Loss: 0.743798 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/120 - Average Training Loss: 0.735777 - Average Training Accuracy: 0.578236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 9/120 [39:37<8:08:28, 264.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/120 - Average Test Loss: 0.737576 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/120 - Average Training Loss: 0.737799 - Average Training Accuracy: 0.580009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 10/120 [44:01<8:04:03, 264.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/120 - Average Test Loss: 0.739685 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/120 - Average Training Loss: 0.733660 - Average Training Accuracy: 0.580785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 11/120 [48:25<7:59:38, 264.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/120 - Average Test Loss: 0.739993 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "Learning rate decreased to 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/120 - Average Training Loss: 0.725064 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|█         | 12/120 [52:49<7:55:15, 264.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/120 - Average Test Loss: 0.733731 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/120 - Average Training Loss: 0.724464 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 13/120 [57:13<7:50:50, 264.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/120 - Average Test Loss: 0.733814 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/120 - Average Training Loss: 0.724264 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▏        | 14/120 [1:01:37<7:46:24, 264.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/120 - Average Test Loss: 0.734600 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/120 - Average Training Loss: 0.724468 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 15/120 [1:06:01<7:41:57, 263.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/120 - Average Test Loss: 0.733981 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/120 - Average Training Loss: 0.724330 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|█▎        | 16/120 [1:10:25<7:37:35, 264.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/120 - Average Test Loss: 0.734778 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/120 - Average Training Loss: 0.724203 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 17/120 [1:14:49<7:33:11, 264.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/120 - Average Test Loss: 0.734661 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/120 - Average Training Loss: 0.724404 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▌        | 18/120 [1:19:13<7:28:45, 263.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/120 - Average Test Loss: 0.734678 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/120 - Average Training Loss: 0.724058 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 19/120 [1:23:37<7:24:19, 263.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/120 - Average Test Loss: 0.734515 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/120 - Average Training Loss: 0.723945 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 20/120 [1:28:01<7:19:54, 263.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/120 - Average Test Loss: 0.734258 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/120 - Average Training Loss: 0.724136 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 21/120 [1:32:25<7:15:37, 264.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/120 - Average Test Loss: 0.733582 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "Learning rate decreased to 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120 - Average Training Loss: 0.723619 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|█▊        | 22/120 [1:36:49<7:11:18, 264.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/120 - Average Test Loss: 0.733625 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120 - Average Training Loss: 0.723430 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 23/120 [1:41:13<7:06:52, 264.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/120 - Average Test Loss: 0.733745 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/120 - Average Training Loss: 0.723286 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 24/120 [1:45:37<7:02:25, 264.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/120 - Average Test Loss: 0.733851 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/120 - Average Training Loss: 0.723300 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|██        | 25/120 [1:50:01<6:58:01, 264.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/120 - Average Test Loss: 0.733833 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/120 - Average Training Loss: 0.723286 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 26/120 [1:54:25<6:53:35, 263.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/120 - Average Test Loss: 0.733873 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/120 - Average Training Loss: 0.723309 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▎       | 27/120 [1:58:49<6:49:10, 263.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/120 - Average Test Loss: 0.733977 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120 - Average Training Loss: 0.723244 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 28/120 [2:03:13<6:44:44, 263.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/120 - Average Test Loss: 0.733983 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/120 - Average Training Loss: 0.723269 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|██▍       | 29/120 [2:07:37<6:40:21, 263.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/120 - Average Test Loss: 0.733983 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/120 - Average Training Loss: 0.723275 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 30/120 [2:12:01<6:35:57, 263.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/120 - Average Test Loss: 0.734009 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/120 - Average Training Loss: 0.723248 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 31/120 [2:16:25<6:31:33, 263.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/120 - Average Test Loss: 0.734013 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "Learning rate decreased to 1e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120 - Average Training Loss: 0.723157 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 32/120 [2:20:49<6:27:10, 263.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/120 - Average Test Loss: 0.734011 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/120 - Average Training Loss: 0.723140 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 33/120 [2:25:13<6:22:46, 263.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/120 - Average Test Loss: 0.734011 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/120 - Average Training Loss: 0.723131 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 34/120 [2:29:37<6:18:23, 264.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/120 - Average Test Loss: 0.734011 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/120 - Average Training Loss: 0.723119 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|██▉       | 35/120 [2:34:01<6:14:02, 264.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/120 - Average Test Loss: 0.734011 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/120 - Average Training Loss: 0.723160 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███       | 36/120 [2:38:25<6:09:39, 264.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/120 - Average Test Loss: 0.734009 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/120 - Average Training Loss: 0.723211 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███       | 37/120 [2:42:49<6:05:15, 264.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/120 - Average Test Loss: 0.734009 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120 - Average Training Loss: 0.723151 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▏      | 38/120 [2:47:13<6:00:53, 264.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/120 - Average Training Loss: 0.723142 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|███▎      | 39/120 [2:51:37<5:56:34, 264.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/120 - Average Training Loss: 0.723159 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 40/120 [2:56:02<5:52:14, 264.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/120 - Average Test Loss: 0.734012 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/120 - Average Training Loss: 0.723132 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 41/120 [3:00:26<5:47:54, 264.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "Learning rate decreased to 1.0000000000000002e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/120 - Average Training Loss: 0.723127 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|███▌      | 42/120 [3:04:50<5:43:32, 264.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/120 - Average Training Loss: 0.723124 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 43/120 [3:09:15<5:39:09, 264.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120 - Average Training Loss: 0.723126 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 44/120 [3:13:39<5:34:46, 264.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/120 - Average Training Loss: 0.723130 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 45/120 [3:18:03<5:30:22, 264.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/120 - Average Training Loss: 0.723097 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 46/120 [3:22:28<5:25:59, 264.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/120 - Average Training Loss: 0.723146 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 47/120 [3:26:52<5:21:35, 264.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/120 - Average Test Loss: 0.734011 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/120 - Average Training Loss: 0.723144 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████      | 48/120 [3:31:16<5:17:11, 264.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/120 - Average Training Loss: 0.723139 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 49/120 [3:35:41<5:12:45, 264.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/120 - Average Training Loss: 0.723127 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 50/120 [3:40:05<5:08:19, 264.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/120 - Average Training Loss: 0.723150 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▎     | 51/120 [3:44:29<5:03:54, 264.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "Learning rate decreased to 1.0000000000000002e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120 - Average Training Loss: 0.723129 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|████▎     | 52/120 [3:48:53<4:59:28, 264.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/120 - Average Training Loss: 0.723124 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 53/120 [3:53:17<4:55:01, 264.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/120 - Average Training Loss: 0.723085 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 54/120 [3:57:42<4:50:35, 264.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/120 - Average Training Loss: 0.723111 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████▌     | 55/120 [4:02:06<4:46:10, 264.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/120 - Average Training Loss: 0.723123 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 56/120 [4:06:30<4:41:45, 264.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/120 - Average Training Loss: 0.723134 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 57/120 [4:10:54<4:37:21, 264.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/120 - Average Training Loss: 0.723110 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 58/120 [4:15:18<4:32:57, 264.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120 - Average Training Loss: 0.723097 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|████▉     | 59/120 [4:19:42<4:28:33, 264.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120 - Average Training Loss: 0.723092 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 60/120 [4:24:06<4:24:09, 264.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120 - Average Training Loss: 0.723150 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|█████     | 61/120 [4:28:31<4:19:46, 264.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "Learning rate decreased to 1.0000000000000004e-08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120 - Average Training Loss: 0.723120 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 62/120 [4:32:55<4:15:21, 264.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120 - Average Training Loss: 0.723127 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▎    | 63/120 [4:37:19<4:10:57, 264.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/120 - Average Training Loss: 0.723127 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 64/120 [4:41:43<4:06:32, 264.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120 - Average Training Loss: 0.723147 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|█████▍    | 65/120 [4:46:07<4:02:08, 264.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/120 - Average Training Loss: 0.723111 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▌    | 66/120 [4:50:32<3:57:46, 264.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/120 - Average Training Loss: 0.723102 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 67/120 [4:54:56<3:53:23, 264.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/120 - Average Training Loss: 0.723149 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▋    | 68/120 [4:59:20<3:48:58, 264.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/120 - Average Training Loss: 0.723143 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████▊    | 69/120 [5:03:44<3:44:33, 264.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/120 - Average Training Loss: 0.723117 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 70/120 [5:08:08<3:40:08, 264.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/120 - Average Training Loss: 0.723179 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 71/120 [5:12:32<3:35:43, 264.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n",
      "Learning rate decreased to 1.0000000000000005e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/120 - Average Training Loss: 0.723102 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████    | 72/120 [5:16:56<3:31:18, 264.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/120 - Average Training Loss: 0.723135 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 73/120 [5:21:21<3:26:56, 264.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/120 - Average Training Loss: 0.723131 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▏   | 74/120 [5:25:45<3:22:36, 264.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/120 - Average Training Loss: 0.723117 - Average Training Accuracy: 0.582225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 75/120 [5:30:10<3:18:15, 264.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/120 - Average Test Loss: 0.734010 - Average Test Accuracy: 0.566667\n",
      "---***---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/120 - Average Training Loss: 0.723183 - Average Training Accuracy: 0.582225\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4451316,
     "sourceId": 7638081,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6473291,
     "sourceId": 10456995,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-15T06:52:38.013152",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}